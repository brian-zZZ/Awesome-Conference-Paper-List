Towards Attack-tolerant Federated Learning via Critical Parameter Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Towards_Attack-tolerant_Federated_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09318)
Stochastic Segmentation with Conditional Categorical Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zbinden_Stochastic_Segmentation_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08888)
A Dynamic Dual-Processing Object Detection Framework Inspired by the Brains Recognition Mechanism | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.pdf)
Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_Hard_No-Box_Adversarial_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.05681)
GameFormer- Game-theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_GameFormer_Game-theoretic_Modeling_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05760)
Learning in Imperfect Environment- Multi-Label Classification with Long-Tailed Distribution and Partial Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.10539)
Flexible Visual Recognition by Evidential Modeling of Confusion and Ignorance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Flexible_Visual_Recognition_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07403)
Texture Generation on 3D Meshes with Point-UV Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10490)
Enhanced Soft Label for Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Enhanced_Soft_Label_ICCV_2023_supplemental.pdf)
HM-ViT- Hetero-Modal Vehicle-to-Vehicle Cooperative Perception with Vision Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_ICCV_2023_supplemental.zip)
HyperReenact- One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bounareli_HyperReenact_One-Shot_Reenactment_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.10797)
Unified Visual Relationship Detection with Vision and Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08998)
Rickrolling the Artist- Injecting Backdoors into Text Encoders for Text-to-Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Struppek_Rickrolling_the_Artist_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.02408)
LD-ZNet- A Latent Diffusion Approach for Text-Based Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/PNVR_LD-ZNet_A_Latent_ICCV_2023_supplemental.pdf)
Downstream-agnostic Adversarial Examples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.12280)
Studying How to Efficiently and Effectively Guide Models with Explanations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rao_Studying_How_to_ICCV_2023_supplemental.pdf)
SkeletonMAE- Graph-based Masked Autoencoder for Skeleton Sequence Pre-training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yan_SkeletonMAE_Graph-based_Masked_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08476)
Pose-Free Neural Radiance Fields via Implicit Pose Regularization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.15049)
Encyclopedic VQA- Visual Questions About Detailed Properties of Fine-Grained Categories | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mensink_Encyclopedic_VQA_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.09224)
Towards Understanding the Generalization of Deepfake Detectors from a Game-Theoretical View | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_Towards_Understanding_the_ICCV_2023_supplemental.pdf)
3DPPE- 3D Point Positional Encoding for Transformer-based Multi-Camera 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shu_3DPPE_3D_Point_ICCV_2023_supplemental.pdf)
VertexSerum- Poisoning Graph Neural Networks for Link Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.01469)
Deep Geometrized Cartoon Line Inbetweening | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Siyao_Deep_Geometrized_Cartoon_ICCV_2023_supplemental.zip)
MatrixCity- A Large-scale City Dataset for City-scale Neural Rendering and Beyond | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_MatrixCity_A_Large-scale_ICCV_2023_supplemental.pdf)
LinkGAN- Linking GAN Latents to Pixels for Controllable Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_LinkGAN_Linking_GAN_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.04604)
SVDiff- Compact Parameter Space for Diffusion Fine-Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_SVDiff_Compact_Parameter_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11305)
Distilling Large Vision-Language Model with Out-of-Distribution Generalizability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Distilling_Large_Vision-Language_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.03135)
What do neural networks learn in image classification- A frequency shortcut perspective | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_What_do_neural_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09829)
PromptCap- Prompt-Guided Image Captioning for VQA with GPT-3 | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_PromptCap_Prompt-Guided_Image_ICCV_2023_supplemental.pdf)
Periodically Exchange Teacher-Student for Source-Free Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.pdf)
Learning to Transform for Generalizable Instance-wise Invariance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.pdf)
Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Multiple_Instance_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15254)
Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Unsupervised_Compositional_Concepts_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.05357)
Partition-And-Debias- Agnostic Biases Mitigation via a Mixture of Biases-Specific Experts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Partition-And-Debias_Agnostic_Biases_ICCV_2023_supplemental.pdf)
Spatial Self-Distillation for Object Detection with Inaccurate Bounding Boxes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Spatial_Self-Distillation_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12101)
CC3D- Layout-Conditioned Generation of Compositional 3D Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bahmani_CC3D_Layout-Conditioned_Generation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.12074)
TextPSG- Panoptic Scene Graph Generation from Textual Descriptions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_supplemental.pdf)
Cross-modal Latent Space Alignment for Image to Avatar Translation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/de_Guevara_Cross-modal_Latent_Space_ICCV_2023_supplemental.pdf)
Inspecting the Geographical Representativeness of Images from Text-to-Image Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Basu_Inspecting_the_Geographical_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.11080)
HSR-Diff- Hyperspectral Image Super-Resolution via Conditional Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_HSR-Diff_Hyperspectral_Image_ICCV_2023_supplemental.pdf)
Advancing Example Exploitation Can Alleviate Critical Challenges in Adversarial Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_Advancing_Example_Exploitation_ICCV_2023_supplemental.pdf)
ShiftNAS- Improving One-shot NAS via Probability Shift | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_ShiftNAS_Improving_One-shot_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08300)
Adaptive Testing of Computer Vision Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Adaptive_Testing_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.02774)
Feature Proliferation -- the Cancer in StyleGAN and its Treatments | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Feature_Proliferation_--_ICCV_2023_supplemental.pdf)
Multi-Label Self-Supervised Learning with Scene Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Multi-Label_Self-Supervised_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03286)
Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware Minimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Enhancing_Fine-Tuning_Based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11823)
Deep Geometry-Aware Camera Self-Calibration from Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hagemann_Deep_Geometry-Aware_Camera_ICCV_2023_supplemental.pdf)
Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.11926)
ScanNet++- A High-Fidelity Dataset of 3D Indoor Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yeshwanth_ScanNet_A_High-Fidelity_ICCV_2023_supplemental.zip)
Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jeon_Improving_Diversity_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10554)
Vox-E- Text-Guided Voxel Editing of 3D Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sella_Vox-E_Text-Guided_Voxel_ICCV_2023_supplemental.zip)
Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation for Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Unilaterally_Aggregated_Contrastive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10155)
Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Learning_Image-Adaptive_Codebooks_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.06513)
3D Segmentation of Humans in Point Clouds with Synthetic Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Takmaz_3D_Segmentation_of_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.00786)
Mastering Spatial Graph Prediction of Road Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sotiris_Mastering_Spatial_Graph_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.00828)
Domain Generalization via Rationale Invariance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Domain_Generalization_via_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11158)
ProbVLM- Probabilistic Adapter for Frozen Vison-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Upadhyay_ProbVLM_Probabilistic_Adapter_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.00398)
Latent-OFER- Detect, Mask, and Reconstruct with Latent Vectors for Occluded Facial Expression Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Latent-OFER_Detect_Mask_ICCV_2023_supplemental.pdf)
Self-supervised Cross-view Representation Reconstruction for Change Captioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tu_Self-supervised_Cross-view_Representation_ICCV_2023_supplemental.pdf)
Unify, Align and Refine- Multi-Level Semantic Alignment for Radiology Report Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.15932)
Scene-Aware Feature Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09949)
FDViT- Improve the Hierarchical Architecture of Vision Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.pdf)
Towards Robust Model Watermark via Reducing Parametric Vulnerability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gan_Towards_Robust_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04777)
LEA2- A Lightweight Ensemble Adversarial Attack via Non-overlapping Vulnerable Frequency Regions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qian_LEA2_A_Lightweight_ICCV_2023_supplemental.pdf)
Unsupervised Domain Adaptive Detection with Network Stability Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Unsupervised_Domain_Adaptive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08182)
MeViS- A Large-scale Benchmark for Video Segmentation with Motion Expressions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.08544)
OPERA- Omni-Supervised Representation Learning with Hierarchical Supervisions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2210.05557)
GPFL- Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_GPFL_Simultaneously_Learning_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.10279)
Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Efficient_Region-Aware_Neural_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.09323)
End2End Multi-View Feature Matching with Differentiable Pose Optimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Roessle_End2End_Multi-View_Feature_ICCV_2023_supplemental.pdf)
Exploring the Benefits of Visual Prompting in Differential Privacy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.12247)
Mining bias-target Alignment from Voronoi Cells | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.03691)
The Victim and The Beneficiary- Exploiting a Poisoned Model to Train a Clean Model on Poisoned Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_The_Victim_and_ICCV_2023_supplemental.pdf)
DIFFGUARD- Semantic Mismatch-Guided Out-of-Distribution Detection Using Pre-Trained Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_DIFFGUARD_Semantic_Mismatch-Guided_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07687)
Tracking Anything with Decoupled Video Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Tracking_Anything_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03903)
Generative Gradient Inversion via Over-Parameterized Networks in Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Generative_Gradient_Inversion_ICCV_2023_supplemental.pdf)
EQ-Net- Elastic Quantization Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_EQ-Net_Elastic_Quantization_ICCV_2023_supplemental.pdf)
Exploring Open-Vocabulary Semantic Segmentation from CLIP Vision Encoder Distillation Only | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Exploring_Open-Vocabulary_Semantic_ICCV_2023_supplemental.pdf)
Parallax-Tolerant Unsupervised Deep Image Stitching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nie_Parallax-Tolerant_Unsupervised_Deep_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.08207)
M2T- Masking Transformers Twice for Faster Decoding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mentzer_M2T_Masking_Transformers_ICCV_2023_supplemental.pdf)
CoIn- Contrastive Instance Feature Mining for Outdoor 3D Object Detection with Very Limited Annotations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_CoIn_Contrastive_Instance_ICCV_2023_supplemental.pdf)
Computation and Data Efficient Backdoor Attacks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.pdf)
Decouple Before Interact- Multi-Modal Prompt Learning for Continual Visual Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qian_Decouple_Before_Interact_ICCV_2023_supplemental.pdf)
Unsupervised Manifold Linearizing and Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.01805)
MMVP- Motion-Matrix-Based Video Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhong_MMVP_Motion-Matrix-Based_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16154)
Human Preference Score- Better Aligning Text-to-Image Models with Human Preference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Human_Preference_Score_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14420)
Guided Motion Diffusion for Controllable Human Motion Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Karunratanakul_Guided_Motion_Diffusion_ICCV_2023_supplemental.zip)
DiffuMask- Synthesizing Images with Pixel-level Annotations for Semantic Segmentation Using Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.11681)
StyleDomain- Efficient and Lightweight Parameterizations of StyleGAN for One-shot and Few-shot Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Alanov_StyleDomain_Efficient_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.10229)
RankMixup- Ranking-Based Mixup Training for Network Calibration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Noh_RankMixup_Ranking-Based_Mixup_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11990)
Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Learning_to_Generate_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08157)
Erasing Concepts from Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gandikota_Erasing_Concepts_from_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.07345)
Fully Attentional Networks with Self-emerging Token Labeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.pdf)
ACTIVE- Towards Highly Transferable 3D Physical Camouflage for Universal and Robust Vehicle Evasion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Suryanto_ACTIVE_Towards_Highly_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07009)
Too Large; Data Reduction for Vision-Language Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.20087)
Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Towards_Deeply_Unified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14786)
Point-Query Quadtree for Crowd Counting, Localization, and More | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Point-Query_Quadtree_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13814)
Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Couairon_Zero-Shot_Spatial_Layout_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.13754)
SegGPT- Towards Segmenting Everything in Context | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_SegGPT_Towards_Segmenting_ICCV_2023_supplemental.pdf)
DDColor- Towards Photo-Realistic Image Colorization via Dual Decoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kang_DDColor_Towards_Photo-Realistic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.11613)
Visual Explanations via Iterated Integrated Attributions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barkan_Visual_Explanations_via_ICCV_2023_supplemental.pdf)
Pairwise Similarity Learning is SimPLE | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wen_Pairwise_Similarity_Learning_ICCV_2023_supplemental.pdf)
GO-SLAM- Global Optimization for Consistent 3D Instant Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_GO-SLAM_Global_Optimization_ICCV_2023_supplemental.pdf)
FACTS- First Amplify Correlations and Then Slice to Discover Bias | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yenamandra_FACTS_First_Amplify_ICCV_2023_supplemental.zip)
Mask-Attention-Free Transformer for 3D Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lai_Mask-Attention-Free_Transformer_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01692)
EgoLoc- Revisiting 3D Object Localization from Egocentric Videos with Visual Queries | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2212.06969)
FLatten Transformer- Vision Transformer using Focused Linear Attention | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_FLatten_Transformer_Vision_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00442)
ADNet- Lane Shape Prediction via Anchor Decomposition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiao_ADNet_Lane_Shape_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10481)
HollowNeRF- Pruning Hashgrid-Based NeRFs with Trainable Collision Mitigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10122)
A Complete Recipe for Diffusion Generative Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pandey_A_Complete_Recipe_ICCV_2023_supplemental.pdf)
The Devil is in the Crack Orientation- A New Perspective for Crack Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.pdf)
FedPD- Federated Open Set Recognition with Parameter Disentanglement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.pdf)
WaterMask- Instance Segmentation for Underwater Imagery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.pdf)
MosaiQ- Quantum Generative Adversarial Networks for Image Generation on NISQ Computers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.11096)
DVIS- Decoupled Video Instance Segmentation Framework | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_DVIS_Decoupled_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.03413)
Rethinking Amodal Video Segmentation from Learning Supervised Signals with Object-centric Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Rethinking_Amodal_Video_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.13248)
Distilled Reverse Attention Network for Open-world Compositional Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.00404)
TexFusion- Synthesizing 3D Textures with Text-Guided Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_TexFusion_Synthesizing_3D_ICCV_2023_supplemental.zip)
Shift from Texture-bias to Shape-bias- Edge Deformation-based Augmentation for Robust Object Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Shift_from_Texture-bias_ICCV_2023_supplemental.pdf)
Data-free Knowledge Distillation for Fine-grained Visual Categorization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Data-free_Knowledge_Distillation_ICCV_2023_supplemental.pdf)
EgoPCA- A New Framework for Egocentric Hand-Object Interaction Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_EgoPCA_A_New_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02423)
I Cant Believe Theres No Images! Learning Visual Tasks Using only Language Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gu_I_Cant_Believe_ICCV_2023_supplemental.pdf)
Feature Prediction Diffusion Model for Video Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf)
MasQCLIP for Open-Vocabulary Universal Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.pdf)
Self-similarity Driven Scale-invariant Learning for Weakly Supervised Person Search | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2302.12986)
Ord2Seq- Regarding Ordinal Regression as Label Sequence Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Ord2Seq_Regarding_Ordinal_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09004)
Controllable Visual-Tactile Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.03051)
Keep It SimPool- Who Said Supervised Transformers Suffer from Attention Deficit- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Psomas_Keep_It_SimPool_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.06891)
LoGoPrompt- Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.01155)
FeatEnHancer- Enhancing Hierarchical Features for Object Detection and Beyond Under Low-Light Vision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hashmi_FeatEnHancer_Enhancing_Hierarchical_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03594)
Saliency Regularization for Self-Training with Partial Annotations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_supplemental.pdf)
Stabilizing Visual Reinforcement Learning via Asymmetric Interactive Cooperation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.pdf)
Learning Hierarchical Features with Joint Latent Space Energy-Based Prior | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cui_Learning_Hierarchical_Features_ICCV_2023_supplemental.pdf)
UniFormerV2- Unlocking the Potential of Image ViTs for Video Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_UniFormerV2_Unlocking_the_ICCV_2023_supplemental.zip)
TARGET- Federated Class-Continual Learning via Exemplar-Free Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.06937)
DiffV2S- Diffusion-Based Video-to-Speech Synthesis with Vision-Guided Speaker Embedding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07787)
The Effectiveness of MAE Pre-Pretraining for Billion-Scale Pretraining | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Singh_The_Effectiveness_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13496)
GPA-3D- Geometry-aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_GPA-3D_Geometry-aware_Prototype_ICCV_2023_supplemental.pdf)
TransHuman- A Transformer-based Human Representation for Generalizable Neural Human Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_TransHuman_A_Transformer-based_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.12291)
Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Unsupervised_Surface_Anomaly_ICCV_2023_supplemental.pdf)
Simoun- Synergizing Interactive Motion-appearance Understanding for Vision-based Reinforcement Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Simoun_Synergizing_Interactive_ICCV_2023_supplemental.pdf)
Representation Disparity-aware Distillation for 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10308)
Breaking The Limits of Text-conditioned 3D Motion Synthesis with Elaborative Descriptions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.pdf)
VL-PET- Vision-and-Language Parameter-Efficient Tuning via Granularity Control | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_ICCV_2023_supplemental.pdf)
ROME- Robustifying Memory-Efficient NAS via Topology Disentanglement and Gradient Accumulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_ROME_Robustifying_Memory-Efficient_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.11233)
Toward Multi-Granularity Decision-Making- Explicit Visual Reasoning with Hierarchical Knowledge | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Toward_Multi-Granularity_Decision-Making_ICCV_2023_supplemental.pdf)
3D-aware Image Generation using 2D Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_3D-aware_Image_Generation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17905)
ICE-NeRF- Interactive Color Editing of NeRFs via Decomposition-Aware Weight Optimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.pdf)
SPANet- Frequency-balancing Token Mixer using Spectral Pooling Aggregation Modulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yun_SPANet_Frequency-balancing_Token_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11568)
ASAG- Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fu_ASAG_Building_Strong_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09242)
The Perils of Learning From Unlabeled Data- Backdoor Attacks on Semi-supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shejwalkar_The_Perils_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.00453)
StyleDiffusion- Controllable Disentangled Style Transfer via Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_StyleDiffusion_Controllable_Disentangled_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07863)
AdvDiffuser- Natural Adversarial Example Synthesis with Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf)
DarSwin- Distortion Aware Radial Swin Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.pdf)
Take-A-Photo- 3D-to-2D Generative Pre-training of Point Cloud Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Take-A-Photo_3D-to-2D_Generative_ICCV_2023_supplemental.pdf)
Open-vocabulary Panoptic Segmentation with Embedding Modulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.11324)
Beyond Single Path Integrated Gradients for Reliable Input Attribution via Randomized Path Sampling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jeon_Beyond_Single_Path_ICCV_2023_supplemental.pdf)
Foreground-Background Separation through Concept Distillation from Generative Image Foundation Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dombrowski_Foreground-Background_Separation_through_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.14306)
ENVIDR- Implicit Differentiable Renderer with Neural Environment Lighting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13022)
Not All Steps are Created Equal- Selective Diffusion Distillation for Image Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Not_All_Steps_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08448)
ALIP- Adaptive Language-Image Pre-Training with Synthetic Caption | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08428)
LaPE- Layer-adaptive Position Embedding for Vision Transformers with Independent Layer Normalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_LaPE_Layer-adaptive_Position_ICCV_2023_supplemental.pdf)
SA-BEV- Generating Semantic-Aware Birds-Eye-View Feature for Multi-view 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_SA-BEV_Generating_Semantic-Aware_ICCV_2023_supplemental.pdf)
Global Knowledge Calibration for Fast Open-Vocabulary Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Global_Knowledge_Calibration_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09181)
Compatibility of Fundamental Matrices for Complete Viewing Graphs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bratelund_Compatibility_of_Fundamental_ICCV_2023_supplemental.zip)
MAtch, eXpand and Improve- Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_MAtch_eXpand_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08914)
Space Engage- Collaborative Space Supervision for Contrastive-Based Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Space_Engage_Collaborative_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09755)
Delving into Motion-Aware Matching for Monocular 3D Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11607)
Fast Adversarial Training with Smooth Convergence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Fast_Adversarial_Training_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12857)
A-STAR- Test-time Attention Segregation and Retention for Text-to-image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Agarwal_A-STAR_Test-time_Attention_ICCV_2023_supplemental.pdf)
FaceCLIPNeRF- Text-driven 3D Face Manipulation using Deformable Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hwang_FaceCLIPNeRF_Text-driven_3D_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.11418)
Learning Shape Primitives via Implicit Convexity Regularization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_supplemental.pdf)
ITI-GEN- Inclusive Text-to-Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_ITI-GEN_Inclusive_Text-to-Image_ICCV_2023_supplemental.pdf)
Learning Neural Eigenfunctions for Unsupervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deng_Learning_Neural_Eigenfunctions_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02841)
Shape Analysis of Euclidean Curves under Frenet-Serret Framework | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chassat_Shape_Analysis_of_ICCV_2023_supplemental.zip)
Efficient Diffusion Training via Min-SNR Weighting Strategy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hang_Efficient_Diffusion_Training_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09556)
Perceptual Grouping in Contrastive Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ranasinghe_Perceptual_Grouping_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.09996)
Dynamic Perceiver for Efficient Visual Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Dynamic_Perceiver_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.11248)
Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03729)
HAL3D- Hierarchical Active Learning for Fine-Grained 3D Part Labeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_HAL3D_Hierarchical_Active_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2301.10460)
FedPerfix- Towards Partial Model Personalization of Vision Transformers in Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_FedPerfix_Towards_Partial_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09160)
Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shum_Conditional_360-degree_Image_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.09621)
SIDGAN- High-Resolution Dubbed Video Generation via Shift-Invariant Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_supplemental.pdf)
Meta-ZSDETR- Zero-shot DETR with Meta-learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Meta-ZSDETR_Zero-shot_DETR_ICCV_2023_supplemental.pdf)
STPrivacy- Spatio-Temporal Privacy-Preserving Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.03046)
Computationally-Efficient Neural Image Compression with Shallow Decoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Computationally-Efficient_Neural_Image_ICCV_2023_supplemental.pdf)
Tracing the Origin of Adversarial Attack for Forensic Investigation and Deterrence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Tracing_the_Origin_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.01218)
Scenimefy- Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Scenimefy_Learning_to_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12968)
DR-Tune- Improving Fine-tuning of Pretrained Visual Models by Distribution Regularization with Semantic Calibration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_DR-Tune_Improving_Fine-tuning_ICCV_2023_supplemental.pdf)
Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yun_Dense_2D-3D_Indoor_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.11081)
EverLight- Indoor-Outdoor Editable HDR Lighting Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.13207)
MARS- Model-agnostic Biased Object Removal without Additional Supervision for Weakly-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jo_MARS_Model-agnostic_Biased_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09913)
Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Few-Shot_Physically-Aware_Articulated_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.10898)
Single-Stage Diffusion NeRF- A Unified Approach to 3D Generation and Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Single-Stage_Diffusion_NeRF_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.06714)
One-Shot Generative Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_One-Shot_Generative_Domain_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09876)
HybridAugment++- Unified Frequency Spectra Perturbations for Model Robustness | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yucel_HybridAugment_Unified_Frequency_ICCV_2023_supplemental.pdf)
Doppelgangers- Learning to Disambiguate Images of Similar Structures | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_Doppelgangers_Learning_to_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02420)
Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Improving_Generalization_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.02533)
Understanding the Feature Norm for Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Understanding_the_Feature_ICCV_2023_supplemental.pdf)
Knowledge Proxy Intervention for Deconfounded Video Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Knowledge_Proxy_Intervention_ICCV_2023_supplemental.pdf)
DetZero- Rethinking Offboard 3D Object Detection with Long-term Sequential Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_DetZero_Rethinking_Offboard_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.06023)
Learning from Noisy Data for Semi-Supervised 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.pdf)
Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Towards_Authentic_Face_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08996)
Group DETR- Fast DETR Training with Group-Wise One-to-Many Assignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Group_DETR_Fast_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2207.13085)
DETRs with Collaborative Hybrid Assignments Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zong_DETRs_with_Collaborative_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2211.12860)
Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Multi-Modal_Neural_Radiance_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.14383)
MonoNeRD- NeRF-like Representations for Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_MonoNeRD_NeRF-like_Representations_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09421)
Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Monocular_3D_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01289)
WaveIPT- Joint Attention and Flow Alignment in the Wavelet domain for Pose Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_WaveIPT_Joint_Attention_ICCV_2023_supplemental.pdf)
PARTNER- Level up the Polar Representation for LiDAR 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.03982)
Corrupting Neuron Explanations of Deep Visual Features | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Srivastava_Corrupting_Neuron_Explanations_ICCV_2023_supplemental.pdf)
PNI - Industrial Anomaly Detection using Position and Neighborhood Information | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bae_PNI__Industrial_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.12634)
Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Bidirectionally_Deformable_Motion_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.07754)
Objects Do Not Disappear- Video Object Detection by Single-Frame Object Location Anticipation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Objects_Do_Not_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04770)
Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.11489)
Source-free Depth for Object Pop-out | [link](https://openaccess.thecvf.com/content/ICCV2023/html/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/WU_Source-free_Depth_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.05370)
Token-Label Alignment for Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiao_Token-Label_Alignment_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.06455)
Learning Gabor Texture Features for Fine-Grained Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05396)
An Embarrassingly Simple Backdoor Attack on Self-supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_An_Embarrassingly_Simple_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.07346)
Partition Speeds Up Learning Implicit Neural Representations Based on Exponential-Increase Hypothesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Partition_Speeds_Up_ICCV_2023_supplemental.pdf)
Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jing_Uncertainty_Guided_Adaptive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14071)
CGBA- Curvature-aware Geometric Black-box Attack | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Reza_CGBA_Curvature-aware_Geometric_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03163)
Unsupervised Facial Performance Editing via Vector-Quantized StyleGAN Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kicanaoglu_Unsupervised_Facial_Performance_ICCV_2023_supplemental.zip)
A Multidimensional Analysis of Social Biases in Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.01948)
PGFed- Personalize Each Clients Global Objective for Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_PGFed_Personalize_Each_ICCV_2023_supplemental.pdf)
Instance and Category Supervision are Alternate Learners for Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tian_Instance_and_Category_ICCV_2023_supplemental.pdf)
Diverse Data Augmentation with Diffusions for Effective Test-time Prompt Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.06038)
GePSAn- Generative Procedure Step Anticipation in Cooking Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Abdelsalam_GePSAn_Generative_Procedure_ICCV_2023_supplemental.pdf)
AutoDiffusion- Training-Free Optimization of Time Steps and Architectures for Automated Diffusion Model Acceleration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_AutoDiffusion_Training-Free_Optimization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10438)
DPS-Net- Deep Polarimetric Stereo Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tian_DPS-Net_Deep_Polarimetric_ICCV_2023_supplemental.pdf)
SpaceEvo- Hardware-Friendly Search Space Design for Efficient INT8 Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_SpaceEvo_Hardware-Friendly_Search_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08308)
How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_supplemental.pdf)
Convolutional Networks with Oriented 1D Kernels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kirchmeyer_Convolutional_Networks_with_ICCV_2023_supplemental.pdf)
Improving Pixel-based MIM by Reducing Wasted Modeling Capability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Improving_Pixel-based_MIM_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00261)
Towards Memory- and Time-Efficient Backpropagation for Training Spiking Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Meng_Towards_Memory-_and_ICCV_2023_supplemental.pdf)
When to Learn What- Model-Adaptive Data Augmentation Curriculum | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hou_When_to_Learn_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04747)
COPILOT- Human-Environment Collision Prediction and Localization from Egocentric Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.01781)
EGformer- Equirectangular Geometry-biased Transformer for 360 Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yun_EGformer_Equirectangular_Geometry-biased_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.07803)
Size Does Matter- Size-aware Virtual Try-on via Clothing-oriented Transformation Try-on Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Size_Does_Matter_ICCV_2023_supplemental.pdf)
Generating Realistic Images from In-the-wild Sounds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Generating_Realistic_Images_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.02405)
Candidate-aware Selective Disambiguation Based On Normalized Entropy for Instance-dependent Partial-label Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.pdf)
Open-vocabulary Video Question Answering- A New Benchmark for Evaluating the Generalizability of Video Question Answering Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ko_Open-vocabulary_Video_Question_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09363)
Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Puy_Using_a_Waffle_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.10100)
AutoReP- Automatic ReLU Replacement for Fast Private Network Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10134)
Center-Based Decoupled Point-cloud Registration for 6D Object Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf)
GAIT- Generating Aesthetic Indoor Tours with Deep Reinforcement Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_GAIT_Generating_Aesthetic_ICCV_2023_supplemental.pdf)
Rethinking Mobile Block for Efficient Attention-based Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.01146)
REAP- A Large-Scale Realistic Adversarial Patch Benchmark | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2212.05680)
StegaNeRF- Embedding Invisible Information within Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_StegaNeRF_Embedding_Invisible_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.01602)
Robust Evaluation of Diffusion-Based Adversarial Purification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Robust_Evaluation_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09051)
Hyperbolic Audio-visual Zero-shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12558)
ModelGiF- Gradient Fields for Model Functional Distance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.11013)
SIGMA- Scale-Invariant Global Sparse Shape Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_SIGMA_Scale-Invariant_Global_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08393)
VidStyleODE- Disentangled Video Editing via StyleGAN and NeuralODEs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ali_VidStyleODE_Disentangled_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06020)
LeaF- Learning Frames for 4D Point Cloud Sequence Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.pdf)
Towards Improved Input Masking for Convolutional Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Balasubramanian_Towards_Improved_Input_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2211.14646)
Gramian Attention Heads are Strong yet Efficient Vision Learners | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ryu_Gramian_Attention_Heads_ICCV_2023_supplemental.pdf)
MI-GAN- A Simple Baseline for Image Inpainting on Mobile Devices | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sargsyan_MI-GAN_A_Simple_ICCV_2023_supplemental.pdf)
A Large-Scale Outdoor Multi-Modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_A_Large-Scale_Outdoor_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2301.06782)
Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Unleashing_Vanilla_Vision_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02964)
Spatio-Temporal Crop Aggregation for Video Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2211.17042)
Zero-guidance Segmentation Using Zero Segment Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rewatbowornwong_Zero-guidance_Segmentation_Using_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13396)
Communication-efficient Federated Learning with Single-Step Synthetic Features Compressor for Faster Convergence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2302.13562)
CTVIS- Consistent Training for Online Video Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ying_CTVIS_Consistent_Training_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.12616)
Unsupervised Video Object Segmentation with Online Adversarial Self-Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.pdf)
GlobalMapper- Arbitrary-Shaped Urban Layout Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_GlobalMapper_Arbitrary-Shaped_Urban_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09693)
Unified Coarse-to-Fine Alignment for Video-Text Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Unified_Coarse-to-Fine_Alignment_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10091)
Gradient-Regulated Meta-Prompt Learning for Generalizable Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.06571)
MUter- Machine Unlearning on Adversarially Trained Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_MUter_Machine_Unlearning_ICCV_2023_supplemental.pdf)
ParCNetV2- Oversized Kernel with Enhanced Attention | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_ParCNetV2_Oversized_Kernel_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.07157)
RealGraph- A Multiview Dataset for 4D Real-world Context Graph Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_supplemental.pdf)
PivotNet- Vectorized Pivot Learning for End-to-end HD Map Construction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ding_PivotNet_Vectorized_Pivot_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16477)
Universal Domain Adaptation via Compressive Attention Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.11862)
Point2Mask- Point-supervised Panoptic Segmentation via Optimal Transport | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Point2Mask_Point-supervised_Panoptic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.01779)
RFLA- A Stealthy Reflected Light Adversarial Attack in the Physical World | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_RFLA_A_Stealthy_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07653)
Nearest Neighbor Guidance for Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Nearest_Neighbor_Guidance_ICCV_2023_supplemental.pdf)
Diffusion-SDF- Conditional Generative Modeling of Signed Distance Functions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.pdf)
Open-Vocabulary Object Detection With an Open Corpus | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Open-Vocabulary_Object_Detection_ICCV_2023_supplemental.pdf)
Spectrum-guided Multi-granularity Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Miao_Spectrum-guided_Multi-granularity_Referring_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.13537)
Sound Source Localization is All about Cross-Modal Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.10724)
BlendFace- Re-designing Identity Encoders for Face-Swapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shiohara_BlendFace_Re-designing_Identity_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10854)
Test-time Personalizable Forecasting of 3D Human Poses | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cui_Test-time_Personalizable_Forecasting_ICCV_2023_supplemental.pdf)
DreamBooth3D- Subject-Driven Text-to-3D Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.13508)
Dynamic Snake Convolution Based on Topological Geometric Constraints for Tubular Structure Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qi_Dynamic_Snake_Convolution_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08388)
Learning to Upsample by Learning to Sample | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.15085)
LayoutDiffusion- Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_LayoutDiffusion_Improving_Graphic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11589)
Efficiently Robustify Pre-Trained Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jain_Efficiently_Robustify_Pre-Trained_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07499)
XMem++- Production-level Video Segmentation From Few Annotated Frames | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bekuzarov_XMem_Production-level_Video_ICCV_2023_supplemental.zip)
End-to-End Diffusion Latent Optimization Improves Classifier Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wallace_End-to-End_Diffusion_Latent_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13703)
TRM-UAP- Enhancing the Transferability of Data-Free Universal Adversarial Perturbation via Truncated Ratio Maximization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_TRM-UAP_Enhancing_the_ICCV_2023_supplemental.pdf)
Scratching Visual Transformers Back with Uniform Attention | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hyeon-Woo_Scratching_Visual_Transformers_ICCV_2023_supplemental.pdf)
Tune-A-Video- One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_supplemental.pdf)
Anchor-Intermediate Detector- Decoupling and Coupling Bounding Boxes for Accurate Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.pdf)
Extensible and Efficient Proxy for Neural Architecture Search | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Extensible_and_Efficient_ICCV_2023_supplemental.pdf)
MAAL- Multimodality-Aware Autoencoder-Based Affordance Learning for 3D Articulated Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_ICCV_2023_supplemental.pdf)
Benchmarking and Analyzing Robust Point Cloud Recognition- Bag of Tricks for Defending Adversarial Examples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Benchmarking_and_Analyzing_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16361)
Poincare ResNet | [link](https://openaccess.thecvf.com/content/ICCV2023/html/van_Spengler_Poincare_ResNet_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/van_Spengler_Poincare_ResNet_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/van_Spengler_Poincare_ResNet_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14027)
Subclass-balancing Contrastive Learning for Long-tailed Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hou_Subclass-balancing_Contrastive_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.15925)
Dynamic Mesh-Aware Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qiao_Dynamic_Mesh-Aware_Radiance_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04581)
Learning Support and Trivial Prototypes for Interpretable Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Learning_Support_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.04011)
Decoupled DETR- Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.pdf)
GIFD- A Generative Gradient Inversion Method with Feature Domain Optimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_GIFD_A_Generative_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04699)
Generalized Sum Pooling for Metric Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gurbuz_Generalized_Sum_Pooling_ICCV_2023_supplemental.pdf)
AlignDet- Aligning Pre-training and Fine-tuning in Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11077)
Dense Text-to-Image Generation with Attention Modulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.12964)
Sentence Attention Blocks for Answer Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.11593)
Towards Fairness-aware Adversarial Network Pruning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf)
Breaking Temporal Consistency- Generating Video Universal Adversarial Perturbations Using Image Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Breaking_Temporal_Consistency_ICCV_2023_supplemental.pdf)
Smoothness Similarity Regularization for Few-Shot GAN Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sushko_Smoothness_Similarity_Regularization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09717)
Distilling Coarse-to-Fine Semantic Matching Knowledge for Weakly Supervised 3D Visual Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Distilling_Coarse-to-Fine_Semantic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09267)
zPROBE- Zero Peek Robustness Checks for Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ghodsi_zPROBE_Zero_Peek_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.12100)
Generative Prompt Model for Weakly Supervised Object Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Generative_Prompt_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09756)
ActFormer- A GAN-based Transformer towards General Action-Conditioned 3D Human Motion Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_ActFormer_A_GAN-based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07706)
Hiding Visual Information via Obfuscating Adversarial Perturbations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Su_Hiding_Visual_Information_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2209.15304)
Category-aware Allocation Transformer for Weakly Supervised Object Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Category-aware_Allocation_Transformer_ICCV_2023_supplemental.pdf)
Domain Specified Optimization for Deployment Authorization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Domain_Specified_Optimization_ICCV_2023_supplemental.pdf)
Locally Stylized Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pang_Locally_Stylized_Neural_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10684)
Confidence-aware Pseudo-label Learning for Weakly Supervised Visual Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.pdf)
Luminance-aware Color Transform for Multiple Exposure Correction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Baek_Luminance-aware_Color_Transform_ICCV_2023_supplemental.pdf)
A Simple Framework for Open-Vocabulary Segmentation and Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_A_Simple_Framework_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08131)
Alignment Before Aggregation- Trajectory Memory Retrieval Network for Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Alignment_Before_Aggregation_ICCV_2023_supplemental.pdf)
Deep Directly-Trained Spiking Neural Networks for Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Su_Deep_Directly-Trained_Spiking_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11411)
Masked Autoencoders Are Stronger Knowledge Distillers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lao_Masked_Autoencoders_Are_ICCV_2023_supplemental.pdf)
ASIC- Aligning Sparse in-the-wild Image Collections | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gupta_ASIC_Aligning_Sparse_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.16201)
Residual Pattern Learning for Pixel-Wise Out-of-Distribution Detection in Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Residual_Pattern_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.14512)
Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Hierarchical_Visual_Primitive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04016)
Segment Every Reference Object in Spatial and Temporal Spaces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Segment_Every_Reference_ICCV_2023_supplemental.pdf)
Unified Out-Of-Distribution Detection- A Model-Specific Perspective | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Averly_Unified_Out-Of-Distribution_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06813)
RankMatch- Fostering Confidence and Consistency in Learning with Noisy Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_RankMatch_Fostering_Confidence_ICCV_2023_supplemental.pdf)
MixReorg- Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_MixReorg_Cross-Modal_Mixed_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04829)
Preface- A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Buhler_Preface_A_Data-driven_ICCV_2023_supplemental.zip)
ICICLE- Interpretable Class Incremental Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rymarczyk_ICICLE_Interpretable_Class_ICCV_2023_supplemental.zip)
PointCLIP V2- Prompting CLIP and GPT for Powerful 3D Open-world Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_PointCLIP_V2_Prompting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11682)
Identification of Systematic Errors of Image Classifiers on Rare Subgroups | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Metzen_Identification_of_Systematic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05072)
Clusterformer- Cluster-based Transformer for 3D Object Detection in Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.pdf)
CDUL- CLIP-Driven Unsupervised Learning for Multi-Label Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.16634)
Your Diffusion Model is Secretly a Zero-Shot Classifier | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Your_Diffusion_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.16203)
Backpropagation Path Search On Adversarial Transferability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Backpropagation_Path_Search_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.07625)
Boosting Adversarial Transferability via Gradient Relevance Attack | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.pdf)
CLIPN for Zero-Shot OOD Detection- Teaching CLIP to Say No | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.12213)
CO-Net- Learning Multiple Point Cloud Tasks at Once with A Cohesive Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_CO-Net_Learning_Multiple_ICCV_2023_supplemental.pdf)
Quality Diversity for Visual Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chavhan_Quality_Diversity_for_ICCV_2023_supplemental.pdf)
UniDexGrasp++- Improving Dexterous Grasping Policy Learning via Geometry-Aware Curriculum and Iterative Generalist-Specialist Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wan_UniDexGrasp_Improving_Dexterous_ICCV_2023_supplemental.zip)
FerKD- Surgical Label Adaptation for Efficient Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shen_FerKD_Surgical_Label_ICCV_2023_supplemental.pdf)
Neural Fields for Structured Lighting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shandilya_Neural_Fields_for_ICCV_2023_supplemental.pdf)
ClothPose- A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf)
Unsupervised Object Localization with Representer Point Selection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Unsupervised_Object_Localization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04172)
SEMPART- Self-supervised Multi-resolution Partitioning of Image Semantics | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ravindran_SEMPART_Self-supervised_Multi-resolution_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10972)
Flatness-Aware Minimization for Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.11108)
ProtoFL- Unsupervised Federated Learning via Prototypical Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.12450)
Multi-label Affordance Mapping from Egocentric Vision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mur-Labadia_Multi-label_Affordance_Mapping_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02120)
Unified Adversarial Patch for Cross-Modal Attacks in the Physical World | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Unified_Adversarial_Patch_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07859)
Misalign, Contrast then Distill- Rethinking Misalignments in Language-Image Pre-training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.pdf)
MixPath- A Unified Approach for One-shot Neural Architecture Search | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chu_MixPath_A_Unified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2001.05887)
Enhancing NeRF akin to Enhancing LLMs- Generalizable NeRF Transformer with Mixture-of-View-Experts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cong_Enhancing_NeRF_akin_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11793)
Task-aware Adaptive Learning for Cross-domain Few-shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.pdf)
Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Revisiting_Domain-Adaptive_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07944)
Efficient Adaptive Human-Object Interaction Detection with Concept-guided Memory | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lei_Efficient_Adaptive_Human-Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03696)
Attentive Mask CLIP | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Attentive_Mask_CLIP_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.08653)
Motion-Guided Masking for Spatiotemporal Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Motion-Guided_Masking_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12962)
Urban Radiance Field Representation with Deformable Neural Mesh Primitives | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_Urban_Radiance_Field_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10776)
Adaptive Frequency Filters As Efficient Global Token Mixers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Adaptive_Frequency_Filters_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14008)
Zolly- Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Zolly_Zoom_Focal_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13796)
Beyond One-to-One- Rethinking the Referring Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_supplemental.pdf)
MoreauGrad- Sparse and Robust Interpretation of Neural Networks via Moreau Envelope | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_MoreauGrad_Sparse_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2302.05294)
Class-Incremental Grouping Network for Continual Audio-Visual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mo_Class-Incremental_Grouping_Network_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05281)
Improving Sample Quality of Diffusion Models Using Self-Attention Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_Improving_Sample_Quality_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.00939)
Evaluating Data Attribution for Text-to-Image Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Evaluating_Data_Attribution_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.09345)
Delta Denoising Score | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hertz_Delta_Denoising_Score_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hertz_Delta_Denoising_Score_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.07090)
Hierarchical Prior Mining for Non-local Multi-View Stereo | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_Hierarchical_Prior_Mining_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09758)
Generative Multiplane Neural Radiance for 3D-Aware Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kumar_Generative_Multiplane_Neural_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.01172)
Boosting Semantic Segmentation from the Perspective of Explicit Class Embeddings | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.12894)
Learning to Identify Critical States for Reinforcement Learning from Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Learning_to_Identify_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07795)
Editing Implicit Assumptions in Text-to-Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Orgad_Editing_Implicit_Assumptions_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08084)
Conceptual and Hierarchical Latent Space Decomposition for Face Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ozkan_Conceptual_and_Hierarchical_ICCV_2023_supplemental.pdf)
VL-Match- Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf)
Translating Images to Road Network- A Non-Autoregressive Sequence-to-Sequence Approach | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_Translating_Images_to_ICCV_2023_supplemental.pdf)
Generative Novel View Synthesis with 3D-Aware Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chan_Generative_Novel_View_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02602)
ALWOD- Active Learning for Weakly-Supervised Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_ALWOD_Active_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07914)
S-VolSDF- Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_S-VolSDF_Sparse_Multi-View_ICCV_2023_supplemental.zip)
TextManiA- Enriching Visual Feature by Text-driven Manifold Augmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye-Bin_TextManiA_Enriching_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14611)
Breaking Common Sense- WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bitton-Guetta_Breaking_Common_Sense_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.07274)
Consistent Depth Prediction for Transparent Object Reconstruction from RGB-D Camera | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_Consistent_Depth_Prediction_ICCV_2023_supplemental.zip)
DETR Does Not Need Multi-Scale or Locality Design | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_DETR_Does_Not_ICCV_2023_supplemental.pdf)
ClusT3- Information Invariant Test-Time Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hakim_ClusT3_Information_Invariant_ICCV_2023_supplemental.pdf)
AssetField- Assets Mining and Reconfiguration in Ground Feature Plane Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.13953)
SAGA- Spectral Adversarial Geometric Attack on 3D Meshes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Stolik_SAGA_Spectral_Adversarial_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2211.13775)
Learning Navigational Visual Representations with Semantic Map Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_Learning_Navigational_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12335)
Shortcut-V2V- Compression Framework for Video-to-Video Translation Based on Temporal Redundancy Reduction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_supplemental.pdf)
SG-Former- Self-guided Transformer with Evolving Token Reallocation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.pdf)
ProtoTransfer- Cross-Modal Prototype Transfer for Point Cloud Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_ProtoTransfer_Cross-Modal_Prototype_ICCV_2023_supplemental.pdf)
Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Niu_Deep_Image_Harmonization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00356)
VQ3D- Learning a 3D-Aware Generative Model on ImageNet | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sargent_VQ3D_Learning_a_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.06833)
2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_2D-3D_Interlaced_Transformer_ICCV_2023_supplemental.pdf)
Collecting The Puzzle Pieces- Disentangled Self-Driven Human Pose Transfer by Permuting Textures | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Collecting_The_Puzzle_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.01887)
Sound Localization from Motion- Jointly Learning Sound Direction and Camera Rotation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Sound_Localization_from_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11329)
Prompt Tuning Inversion for Text-driven Image Editing Using Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Prompt_Tuning_Inversion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.04441)
UnitedHuman- Harnessing Multi-Source Data for High-Resolution Human Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fu_UnitedHuman_Harnessing_Multi-Source_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.14335)
Neural Microfacet Fields for Inverse Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17806)
Understanding Self-attention Mechanism via Dynamical System Perspective | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Understanding_Self-attention_Mechanism_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09939)
DDG-Net- Discriminability-Driven Graph Network for Weakly-supervised Temporal Action Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_DDG-Net_Discriminability-Driven_Graph_ICCV_2023_supplemental.pdf)
Rethinking Data Distillation- Do Not Overlook Calibration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Rethinking_Data_Distillation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12463)
Building Vision Transformers with Hierarchy Aware Feature Aggregation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Building_Vision_Transformers_ICCV_2023_supplemental.pdf)
SAL-ViT- Towards Latency Efficient Private Inference on ViT using Selective Attention Search with a Learnable Softmax Approximation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.pdf)
TIJO- Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sur_TIJO_Trigger_Inversion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03906)
Improving Adversarial Robustness of Masked Autoencoders via Test-time Frequency-domain Prompting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Improving_Adversarial_Robustness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10315)
The Making and Breaking of Camouflage | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lamdouar_The_Making_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03899)
Object as Query- Lifting Any 2D Object Detector to 3D Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Object_as_Query_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.02364)
Versatile Diffusion- Text, Images and Variations All in One Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Versatile_Diffusion_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.08332)
Sat2Density- Faithful Density Learning from Satellite-Ground Image Pairs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qian_Sat2Density_Faithful_Density_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14672)
Expressive Text-to-Image Generation with Rich Text | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_Expressive_Text-to-Image_Generation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06720)
Text-Driven Generative Domain Adaptation with Spectral Consistency Regularization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.pdf)
Neural Reconstruction of Relightable Human Model from Monocular Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Neural_Reconstruction_of_ICCV_2023_supplemental.zip)
FB-BEV- BEV Representation from Forward-Backward View Transformations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_FB-BEV_BEV_Representation_ICCV_2023_supplemental.pdf)
BoxSnake- Polygonal Instance Segmentation with Box Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_BoxSnake_Polygonal_Instance_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11630)
ClimateNeRF- Extreme Weather Synthesis in Neural Radiance Field | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_ClimateNeRF_Extreme_Weather_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.13226)
Monte Carlo Linear Clustering with Single-Point Supervision is Enough for Infrared Small Target Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Monte_Carlo_Linear_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.04442)
Practical Membership Inference Attacks Against Large-Scale Multi-Modal Models- A Pilot Study | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ko_Practical_Membership_Inference_ICCV_2023_supplemental.pdf)
TCOVIS- Temporally Consistent Online Video Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.11857)
Long-Term Photometric Consistent Novel View Synthesis with Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Long-Term_Photometric_Consistent_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10700)
Benchmarking Algorithmic Bias in Face Recognition- An Experimental Approach Using Synthetic Faces and Human Evaluation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Benchmarking_Algorithmic_Bias_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05441)
Spatial-Aware Token for Weakly Supervised Object Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Spatial-Aware_Token_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10438)
Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.03869)
GraphAlign- Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.pdf)
NEMTO- Neural Environment Matting for Novel View and Relighting Synthesis of Transparent Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_NEMTO_Neural_Environment_ICCV_2023_supplemental.pdf)
USAGE- A Unified Seed Area Generation Paradigm for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_USAGE_A_Unified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.07806)
NeuS2- Fast Learning of Neural Implicit Surfaces for Multi-view Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_NeuS2_Fast_Learning_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.05231)
Gender Artifacts in Visual Datasets | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Meister_Gender_Artifacts_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.09191)
SuS-X- Training-Free Name-Only Transfer of Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Udandarao_SuS-X_Training-Free_Name-Only_ICCV_2023_supplemental.pdf)
Beating Backdoor Attack at Its Own Game | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.15539)
Do DALL-E and Flamingo Understand Each Other- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Do_DALL-E_and_ICCV_2023_supplemental.pdf)
Prototype-based Dataset Comparison | [link](https://openaccess.thecvf.com/content/ICCV2023/html/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_supplemental.pdf)
FreeCOS- Self-Supervised Learning from Fractals and Unlabeled Images for Curvilinear Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_FreeCOS_Self-Supervised_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07245)
Generating Dynamic Kernels via Transformers for Lane Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.pdf)
Boosting Long-tailed Object Detection via Step-wise Learning on Smooth-tail Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.12833)
Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Talking_Head_Generation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.04248)
Learning Cross-Modal Affinity for Referring Video Object Segmentation Targeting Limited Samples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Learning_Cross-Modal_Affinity_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02041)
Divide and Conquer- a Two-Step Method for High Quality Face De-identification with Model Explainability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.pdf)
Set-level Guidance Attack- Boosting Adversarial Transferability of Vision-Language Pre-training Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_Set-level_Guidance_Attack_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14061)
Multimodal Distillation for Egocentric Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Radevski_Multimodal_Distillation_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07483)
Perceptual Artifacts Localization for Image Synthesis Tasks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Perceptual_Artifacts_Localization_ICCV_2023_supplemental.pdf)
Better May Not Be Fairer- A Study on Subgroup Discrepancy in Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chiu_Better_May_Not_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.08649)
3D Implicit Transporter for Temporally Consistent Keypoint Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhong_3D_Implicit_Transporter_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05098)
Adaptive Rotated Convolution for Rotated Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.07820)
UniVTG- Towards Unified Video-Language Temporal Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16715)
Fast Globally Optimal Surface Normal Estimation from an Affine Correspondence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hajder_Fast_Globally_Optimal_ICCV_2023_supplemental.zip)
Frequency-aware GAN for Adversarial Manipulation Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.pdf)
Template-guided Hierarchical Feature Restoration for Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Template-guided_Hierarchical_Feature_ICCV_2023_supplemental.pdf)
PourIt!- Weakly-Supervised Liquid Perception from a Single Image for Visual Closed-Loop Robotic Pouring | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_PourIt_Weakly-Supervised_Liquid_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.11299)
A Latent Space of Stochastic Diffusion Models for Zero-Shot Image Editing and Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.pdf)
Open Set Video HOI detection from Action-Centric Chain-of-Look Prompting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xi_Open_Set_Video_ICCV_2023_supplemental.pdf)
Robust Mixture-of-Expert Training for Convolutional Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Robust_Mixture-of-Expert_Training_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10110)
UniTR- A Unified and Efficient Multi-Modal Transformer for Birds-Eye-View Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_UniTR_A_Unified_ICCV_2023_supplemental.pdf)
R3D3- Dense 3D Reconstruction of Dynamic Scenes from Multiple Cameras | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Schmied_R3D3_Dense_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14713)
Focus the Discrepancy- Intra- and Inter-Correlation Learning for Image Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_Focus_the_Discrepancy_ICCV_2023_supplemental.pdf)
Make Encoder Great Again in 3D GAN Inversion through Geometry and Occlusion-Aware Encoding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_Make_Encoder_Great_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.12326)
DLT- Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Levi_DLT_Conditioned_layout_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.03755)
Open-Vocabulary Semantic Segmentation with Decoupled One-Pass Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01198)
Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.00216)
DS-Fusion- Artistic Typography via Discriminated and Stylized Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tanveer_DS-Fusion_Artistic_Typography_ICCV_2023_supplemental.zip)
Distilling DETR with Visual-Linguistic Knowledge for Open-Vocabulary Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.pdf)
Scale-MAE- A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Reed_Scale-MAE_A_Scale-Aware_ICCV_2023_supplemental.pdf)
A Unified Framework for Robustness on Diverse Sampling Errors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jeon_A_Unified_Framework_ICCV_2023_supplemental.pdf)
LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.01686)
Scene-Aware Label Graph Learning for Multi-Label Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Scene-Aware_Label_Graph_ICCV_2023_supplemental.pdf)
Fcaformer- Forward Cross Attention in Hybrid Vision Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2211.07198)
Progressive Spatio-Temporal Prototype Matching for Text-Video Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_supplemental.pdf)
Data Augmented Flatness-aware Gradient Projection for Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Data_Augmented_Flatness-aware_ICCV_2023_supplemental.pdf)
Sample-wise Label Confidence Incorporation for Learning with Noisy Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ahn_Sample-wise_Label_Confidence_ICCV_2023_supplemental.pdf)
CLIPTrans- Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gupta_CLIPTrans_Transferring_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15226)
Ego-Only- Egocentric Action Detection without Exocentric Transferring | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Ego-Only_Egocentric_Action_ICCV_2023_supplemental.pdf)
CoinSeg- Contrast Inter- and Intra- Class Representations for Incremental Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_CoinSeg_Contrast_Inter-_ICCV_2023_supplemental.pdf)
Multi-View Active Fine-Grained Visual Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.pdf)
Variational Causal Inference Network for Explanatory Visual Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xue_Variational_Causal_Inference_ICCV_2023_supplemental.pdf)
Enhancing Generalization of Universal Adversarial Perturbation through Gradient Aggregation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Enhancing_Generalization_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06015)
Parallel Attention Interaction Network for Few-Shot Skeleton-Based Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf)
Not All Features Matter- Enhancing Few-shot CLIP with Adaptive Prior Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Not_All_Features_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01195)
EgoVLPv2- Egocentric Video-Language Pre-training with Fusion in the Backbone | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pramanick_EgoVLPv2_Egocentric_Video-Language_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.05463)
Deep Equilibrium Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Deep_Equilibrium_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09564)
SMAUG- Sparse Masked Autoencoder for Efficient Video-Language Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2211.11446)
Communication-Efficient Vertical Federated Learning with Limited Overlapping Samples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.16270)
On the Audio-visual Synchronization for Lip-to-Speech Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.00502)
BallGAN- 3D-aware Image Synthesis with a Spherical Background | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shin_BallGAN_3D-aware_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.09091)
AttT2M- Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhong_AttT2M_Text-Driven_Human_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.00796)
A Theory of Topological Derivatives for Inverse Rendering of Geometry | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09865)
Canonical Factors for Hybrid Neural Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yi_Canonical_Factors_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15461)
GET- Group Event Transformer for Event-Based Vision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_GET_Group_Event_ICCV_2023_supplemental.zip)
When Do Curricula Work in Federated Learning- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Vahidian_When_Do_Curricula_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.12712)
Audio-Visual Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11073)
Towards Viewpoint-Invariant Visual Recognition via Adversarial Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ruan_Towards_Viewpoint-Invariant_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10235)
Multi-Metrics Adaptively Identifies Backdoors in Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Multi-Metrics_Adaptively_Identifies_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.06601)
FPR- False Positive Rectification for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_supplemental.pdf)
DETRDistill- A Universal Knowledge Distillation Framework for DETR-families | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chang_DETRDistill_A_Universal_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10156)
F&F Attack- Adversarial Attack against Multiple Object Trackers by Inducing False Negatives and False Positives | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_FF_Attack_Adversarial_ICCV_2023_supplemental.pdf)
Transferable Decoding with Visual Entities for Zero-Shot Image Captioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fei_Transferable_Decoding_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16525)
ReMoDiffuse- Retrieval-Augmented Motion Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.01116)
Advancing Referring Expression Segmentation Beyond Single Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.12452)
LogicSeg- Parsing Visual Semantics with Neural Logic Learning and Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_LogicSeg_Parsing_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.13556)
Texture Learning Domain Randomization for Domain Generalized Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Texture_Learning_Domain_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11546)
Learning Concise and Descriptive Attributes for Visual Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yan_Learning_Concise_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03685)
Label-Noise Learning with Intrinsically Long-Tailed Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_Label-Noise_Learning_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.09833)
Rethinking Range View Representation for LiDAR Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.05367)
Divide and Conquer- 3D Point Cloud Instance Segmentation With Point-Wise Binarization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Divide_and_Conquer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2207.11209)
BANSAC- A Dynamic BAyesian Network for Adaptive SAmple Consensus | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Piedade_BANSAC_A_Dynamic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.08690)
ShapeScaffolder- Structure-Aware 3D Shape Generation from Text | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tian_ShapeScaffolder_Structure-Aware_3D_ICCV_2023_supplemental.pdf)
Read-only Prompt Optimization for Vision-Language Few-shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Read-only_Prompt_Optimization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14960)
COCO-O- A Benchmark for Object Detectors under Natural Distribution Shifts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mao_COCO-O_A_Benchmark_ICCV_2023_supplemental.pdf)
StageInteractor- Query-based Object Detector with Cross-stage Interaction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Teng_StageInteractor_Query-based_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.04978)
Moment Detection in Long Tutorial Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Croitoru_Moment_Detection_in_ICCV_2023_supplemental.pdf)
DFA3D- 3D Deformable Attention For 2D-to-3D Feature Lifting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DFA3D_3D_Deformable_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12972)
Rosetta Neurons- Mining the Common Units in a Model Zoo | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dravid_Rosetta_Neurons_Mining_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.09346)
Semi-Supervised Semantic Segmentation under Label Noise via Diverse Learning Groups | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Semi-Supervised_Semantic_Segmentation_ICCV_2023_supplemental.pdf)
Segment Anything | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kirillov_Segment_Anything_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02643)
Unsupervised Prompt Tuning for Text-Driven Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.pdf)
Re-ReND- Real-Time Rendering of NeRFs across Devices | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_supplemental.pdf)
Handwritten and Printed Text Segmentation- A Signature Case Study | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gholamian_Handwritten_and_Printed_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07887)
RbA- Segmenting Unknown Regions Rejected by All | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nayal_RbA_Segmenting_Unknown_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.14293)
Towards Open-Vocabulary Video Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Towards_Open-Vocabulary_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01715)
Unleashing the Power of Gradient Signal-to-Noise Ratio for Zero-Shot NAS | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Unleashing_the_Power_ICCV_2023_supplemental.pdf)
BiViT- Extremely Compressed Binary Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_BiViT_Extremely_Compressed_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.07091)
Tree-Structured Shading Decomposition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.07122)
EfficientTrain- Exploring Generalized Curriculum Learning for Training Visual Backbones | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_EfficientTrain_Exploring_Generalized_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.09703)
IntrinsicNeRF- Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_IntrinsicNeRF_Learning_Intrinsic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.00647)
Multi-Object Discovery by Low-Dimensional Object Motion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Safadoust_Multi-Object_Discovery_by_ICCV_2023_supplemental.pdf)
GACE- Geometry Aware Confidence Enhancement for Black-Box 3D Object Detectors on LiDAR-Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Schinagl_GACE_Geometry_Aware_ICCV_2023_supplemental.pdf)
ToonTalker- Cross-Domain Face Reenactment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gong_ToonTalker_Cross-Domain_Face_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.12866)
Source-free Domain Adaptive Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_Source-free_Domain_Adaptive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03202)
DOT- A Distillation-Oriented Trainer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_DOT_A_Distillation-Oriented_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08436)
Neural Collage Transfer- Artistic Reconstruction via Material Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Neural_Collage_Transfer_ICCV_2023_supplemental.zip)
Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Informative_Data_Mining_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.14241)
Householder Projector for Unsupervised Latent Semantics Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Householder_Projector_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08012)
Bayesian Optimization Meets Self-Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Bayesian_Optimization_Meets_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.12666)
No Fear of Classifier Biases- Neural Collapse Inspired Federated Learning with Synthetic and Fixed Classifier | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_No_Fear_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10058)
MemorySeg- Online LiDAR Semantic Segmentation with a Latent Memory | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_MemorySeg_Online_LiDAR_ICCV_2023_supplemental.pdf)
Hashing Neural Video Decomposition with Multiplicative Residuals in Space-Time | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chan_Hashing_Neural_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.14022)
Multimodal Variational Auto-encoder based Audio-Visual Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mao_Multimodal_Variational_Auto-encoder_ICCV_2023_supplemental.pdf)
DynaMITe- Dynamic Query Bootstrapping for Multi-object Interactive Segmentation Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rana_DynaMITe_Dynamic_Query_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.06668)
FRAug- Tackling Federated Learning with Non-IID Features via Representation Augmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_FRAug_Tackling_Federated_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.14900)
Homography Guided Temporal Fusion for Road Line and Marking Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Homography_Guided_Temporal_ICCV_2023_supplemental.pdf)
NeuRBF- A Neural Fields Representation with Adaptive Radial Basis Functions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_NeuRBF_A_Neural_ICCV_2023_supplemental.pdf)
Multi-granularity Interaction Simulation for Unsupervised Interactive Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Multi-granularity_Interaction_Simulation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13399)
RecursiveDet- End-to-End Region-Based Recursive Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_RecursiveDet_End-to-End_Region-Based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13619)
Structure Invariant Transformation for better Adversarial Transferability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Structure_Invariant_Transformation_ICCV_2023_supplemental.zip)
FULLER- Unified Multi-modality Multi-task 3D Perception via Multi-level Gradient Calibration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_FULLER_Unified_Multi-modality_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16617)
Cross-Domain Product Representation Learning for Rich-Content E-Commerce | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bai_Cross-Domain_Product_Representation_ICCV_2023_supplemental.pdf)
Detection Transformer with Stable Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Detection_Transformer_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.04742)
Be Everywhere - Hear Everything (BEE)- Audio Scene Reconstruction by Sparse Audio-Visual Samples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Be_Everywhere_-_ICCV_2023_supplemental.zip)
Story Visualization by Online Text Augmentation with Context Memory | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ahn_Story_Visualization_by_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07575)
Global Balanced Experts for Federated Long-Tailed Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zeng_Global_Balanced_Experts_ICCV_2023_supplemental.pdf)
Cascade-DETR- Delving into High-Quality Universal Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Cascade-DETR_Delving_into_ICCV_2023_supplemental.pdf)
ACLS- Adaptive and Conditional Label Smoothing for Network Calibration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_ACLS_Adaptive_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11911)
EMR-MSF- Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_EMR-MSF_Self-Supervised_Recurrent_ICCV_2023_supplemental.pdf)
Evaluation and Improvement of Interpretability for Self-Explainable Part-Prototype Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Evaluation_and_Improvement_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.05946)
Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Mitigating_Adversarial_Vulnerability_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07250)
Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Dynamic_Token_Pruning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.01045)
DiffFit- Unlocking Transferability of Large Diffusion Models via Simple Parameter-efficient Fine-Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_DiffFit_Unlocking_Transferability_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06648)
QD-BEV - Quantization-aware View-guided Distillation for Multi-view 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_QD-BEV__Quantization-aware_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.10515)
CLIPascene- Scene Sketching with Different Types and Levels of Abstraction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Vinker_CLIPascene_Scene_Sketching_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.17256)
Multi-Directional Subspace Editing in Style-Space | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Naveh_Multi-Directional_Subspace_Editing_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11825)
Adaptive Superpixel for Active Learning in Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Adaptive_Superpixel_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.16817)
Parametric Information Maximization for Generalized Category Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chiaroni_Parametric_Information_Maximization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.00334)
A Generalist Framework for Panoptic Segmentation of Images and Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_A_Generalist_Framework_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.06366)
DALL-Eval- Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_DALL-Eval_Probing_the_ICCV_2023_supplemental.pdf)
Scale-Aware Modulation Meet Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Scale-Aware_Modulation_Meet_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08579)
SUMMIT- Source-Free Adaptation of Uni-Modal Models to Multi-Modal Targets | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Simons_SUMMIT_Source-Free_Adaptation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.11880)
Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Learning_a_More_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11441)
HairNeRF- Geometry-Aware Image Synthesis for Hairstyle Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.pdf)
GETAvatar- Generative Textured Meshes for Animatable Human Avatars | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_GETAvatar_Generative_Textured_ICCV_2023_supplemental.pdf)
StylerDALLE- Language-Guided Style Transfer Using a Vector-Quantized Tokenizer of a Large-Scale Generative Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_StylerDALLE_Language-Guided_Style_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09268)
Deep Image Harmonization with Learnable Augmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Niu_Deep_Image_Harmonization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00376)
Scalable Diffusion Models with Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peebles_Scalable_Diffusion_Models_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.09748)
MMST-ViT- Climate Change-aware Crop Yield Prediction via Multi-Modal Spatial-Temporal Vision Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.pdf)
Grounded Image Text Matching with Mismatched Relation Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Grounded_Image_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.01236)
UniKD- Universal Knowledge Distillation for Mimicking Homogeneous or Heterogeneous Object Detectors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lao_UniKD_Universal_Knowledge_ICCV_2023_supplemental.pdf)
BoxDiff- Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10816)
Rapid Network Adaptation- Learning to Adapt Neural Networks Using Test-Time Feedback | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.pdf)
Theoretical and Numerical Analysis of 3D Reconstruction Using Point and Line Incidences | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rydell_Theoretical_and_Numerical_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.13593)
Explaining Adversarial Robustness of Neural Networks from Clustering Effect Perspective | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.pdf)
Leaping Into Memories- Space-Time Deep Feature Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Stergiou_Leaping_Into_Memories_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09941)
WDiscOOD- Out-of-Distribution Detection via Whitened Linear Discriminant Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_WDiscOOD_Out-of-Distribution_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.07543)
Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xing_Boosting_Few-shot_Action_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09346)
Diffusion in Style | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Everaert_Diffusion_in_Style_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Everaert_Diffusion_in_Style_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Everaert_Diffusion_in_Style_ICCV_2023_supplemental.pdf)
FunnyBirds- A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hesse_FunnyBirds_A_Synthetic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06248)
Deformable Neural Radiance Fields using RGB and Event Cameras | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Deformable_Neural_Radiance_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.08416)
BeLFusion- Latent Diffusion for Behavior-Driven Human Motion Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barquero_BeLFusion_Latent_Diffusion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.14304)
CleanCLIP- Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bansal_CleanCLIP_Mitigating_Data_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.03323)
Cumulative Spatial Knowledge Distillation for Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Cumulative_Spatial_Knowledge_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08500)
Less is More- Focus Attention for Efficient DETR | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Less_is_More_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12612)
Efficient Controllable Multi-Task Architectures | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.11744)
Lens Parameter Estimation for Realistic Depth of Field Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Piche-Meunier_Lens_Parameter_Estimation_ICCV_2023_supplemental.zip)
Semantic-Aware Implicit Template Learning via Part Deformation Consistency | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Semantic-Aware_Implicit_Template_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11916)
GRAM-HD- 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_GRAM-HD_3D-Consistent_Image_ICCV_2023_supplemental.pdf)
Small Object Detection via Coarse-to-fine Proposal Generation and Imitation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_Small_Object_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09534)
Anomaly Detection Under Distribution Shift | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Anomaly_Detection_Under_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13845)
Enhancing Privacy Preservation in Federated Learning via Learning Rate Perturbation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wan_Enhancing_Privacy_Preservation_ICCV_2023_supplemental.pdf)
ImGeoNet- Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tu_ImGeoNet_Image-induced_Geometry-aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09098)
Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_Diffusion-based_Image_Translation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12350)
Isomer- Isomerous Transformer for Zero-shot Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.06693)
X-Mesh- Towards Fast and Accurate Text-driven 3D Stylization via Dynamic Textual Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.pdf)
ViLTA- Enhancing Vision-Language Pre-training through Textual Augmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_ViLTA_Enhancing_Vision-Language_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16689)
Not Every Side Is Equal- Localization Uncertainty Estimation for Semi-Supervised 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Not_Every_Side_ICCV_2023_supplemental.pdf)
Teaching CLIP to Count to Ten | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Paiss_Teaching_CLIP_to_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2302.12066)
Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Michalkiewicz_Domain_Generalization_Guided_ICCV_2023_supplemental.pdf)
Counterfactual-based Saliency Map- Towards Visual Contrastive Explanations for Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Counterfactual-based_Saliency_Map_ICCV_2023_supplemental.pdf)
MST-compression- Compressing and Accelerating Binary Neural Networks with Minimum Spanning Tree | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Vo_MST-compression_Compressing_and_ICCV_2023_supplemental.pdf)
IIEU- Rethinking Neural Feature Activation from Decision-Making | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_IIEU_Rethinking_Neural_ICCV_2023_supplemental.pdf)
Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Integrally_Migrating_Pre-trained_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.09613)
V-FUSE- Volumetric Depth Map Fusion with Long-Range Constraints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Burgdorfer_V-FUSE_Volumetric_Depth_ICCV_2023_supplemental.pdf)
GECCO- Geometrically-Conditioned Point Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.05916)
PETRv2- A Unified Framework for 3D Perception from Multi-Camera Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2206.01256)
Out-of-Domain GAN Inversion via Invertibility Decomposition for Photo-Realistic Human Face Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Out-of-Domain_GAN_Inversion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.09262)
Learning Trajectory-Word Alignments for Video-Language Tasks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Learning_Trajectory-Word_Alignments_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2301.01953)
Geometry-guided Feature Learning and Fusion for Indoor Scene Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_supplemental.pdf)
Atmospheric Transmission and Thermal Inertia Induced Blind Road Segmentation with a Large-Scale Dataset TBRSD | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Atmospheric_Transmission_and_ICCV_2023_supplemental.zip)
Efficient-VQGAN- Towards High-Resolution Image Generation with Efficient Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf)
Towards Fair and Comprehensive Comparisons for Image-Based 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Towards_Fair_and_ICCV_2023_supplemental.pdf)
Random Boxes Are Open-world Object Detectors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Random_Boxes_Are_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08249)
DiffDreamer- Towards Consistent Unsupervised Single-view Scene Extrapolation with Conditional Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_DiffDreamer_Towards_Consistent_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2211.12131)
Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Enhancing_Adversarial_Robustness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04061)
MIMO-NeRF- Fast Neural Rendering with Multi-input Multi-output Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kaneko_MIMO-NeRF_Fast_Neural_ICCV_2023_supplemental.zip)
Instance Neural Radiance Field | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Instance_Neural_Radiance_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.04395)
One-bit Flip is All You Need- When Bit-flip Attack Meets Model Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_One-bit_Flip_is_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07934)
Improving CLIP Fine-tuning Performance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Improving_CLIP_Fine-tuning_ICCV_2023_supplemental.pdf)
The Power of Sound (TPoS)- Audio Reactive Video Generation with Stable Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jeong_The_Power_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04509)
DINAR- Diffusion Inpainting of Neural Textures for One-Shot Human Avatars | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Svitov_DINAR_Diffusion_Inpainting_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.09375)
ElasticViT- Conflict-aware Supernet Training for Deploying Fast Vision Transformer on Diverse Mobile Devices | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_ElasticViT_Conflict-aware_Supernet_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09730)
Noise-Aware Learning from Web-Crawled Image-Text Data for Image Captioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kang_Noise-Aware_Learning_from_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.13563)
Detecting Objects with Context-Likelihood Graphs and Graph Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.pdf)
Coarse-to-Fine Amodal Segmentation with Shape Prior | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Coarse-to-Fine_Amodal_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16825)
AdVerb- Visually Guided Audio Dereverberation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chowdhury_AdVerb_Visually_Guided_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12370)
Open-vocabulary Object Segmentation with Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Open-vocabulary_Object_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.05221)
With a Little Help from Your Own Past- Prototypical Memory Networks for Image Captioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barraco_With_a_Little_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12383)
PDiscoNet- Semantically consistent part discovery for fine-grained recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.03173)
How to Choose your Best Allies for a Transferable Attack- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Maho_How_to_Choose_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02312)
Self-Supervised Object Detection from Egocentric Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Akiva_Self-Supervised_Object_Detection_ICCV_2023_supplemental.pdf)
Cross Contrasting Feature Perturbation for Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Cross_Contrasting_Feature_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12502)
DiffusionRet- Generative Text-Video Retrieval with Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jin_DiffusionRet_Generative_Text-Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09867)
Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Suzuki_Adversarial_Finetuning_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16454)
MULLER- Multilayer Laplacian Resizer for Vision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02859)
X-VoE- Measuring eXplanatory Violation of Expectation in Physical Events | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dai_X-VoE_Measuring_eXplanatory_ICCV_2023_supplemental.zip)
COOP- Decoupling and Coupling of Whole-Body Grasping Pose Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.pdf)
Model Calibration in Dense Classification with Adaptive Label Perturbation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Model_Calibration_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13539)
Semantic Information in Contrastive Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Quan_Semantic_Information_in_ICCV_2023_supplemental.pdf)
Structure and Content-Guided Video Synthesis with Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Esser_Structure_and_Content-Guided_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2302.03011)
Beyond Skin Tone- A Multidimensional Measure of Apparent Skin Color | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Thong_Beyond_Skin_Tone_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05148)
NeILF++- Inter-Reflectable Light Fields for Geometry and Material Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_NeILF_Inter-Reflectable_Light_ICCV_2023_supplemental.zip)
MAGI- Multi-Annotated Explanation-Guided Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.pdf)
Adaptive Positional Encoding for Bundle-Adjusting Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.pdf)
Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Inducing_Neural_Collapse_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.05689)
Factorized Inverse Path Tracing for Efficient and Accurate Material-Lighting Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Factorized_Inverse_Path_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.05669)
Overwriting Pretrained Bias with Finetuning Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.06167)
Anti-DreamBooth- Protecting Users from Personalized Text-to-image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Van_Le_Anti-DreamBooth_Protecting_Users_ICCV_2023_supplemental.zip)
Contrastive Continuity on Augmentation Stability Rehearsal for Continual Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Contrastive_Continuity_on_ICCV_2023_supplemental.pdf)
Treating Pseudo-labels Generation as Image Matting for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Treating_Pseudo-labels_Generation_ICCV_2023_supplemental.pdf)
UMFuse- Unified Multi View Fusion for Human Editing Applications | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jain_UMFuse_Unified_Multi_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10157)
CROSSFIRE- Camera Relocalization On Self-Supervised Features from an Implicit Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Moreau_CROSSFIRE_Camera_Relocalization_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.04869)
Unmasking Anomalies in Road-Scene Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nandan_Unmasking_Anomalies_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13316)
Self-Calibrated Cross Attention Network for Few-Shot Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Self-Calibrated_Cross_Attention_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09294)
Learning Global-aware Kernel for Image Harmonization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.11676)
Chordal Averaging on Flag Manifolds and Its Applications | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13501)
Towards Building More Robust Models with Frequency Bias | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.09763)
PolicyCleanse- Backdoor Detection and Mitigation for Competitive Reinforcement Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_PolicyCleanse_Backdoor_Detection_ICCV_2023_supplemental.zip)
Ref-NeuS- Ambiguity-Reduced Neural Implicit Surface Learning for Multi-View Reconstruction with Reflection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_ICCV_2023_supplemental.pdf)
Class-incremental Continual Learning for Instance Segmentation with Image-level Weak Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hsieh_Class-incremental_Continual_Learning_ICCV_2023_supplemental.pdf)
When Prompt-based Incremental Learning Does Not Meet Strong Pretraining | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_When_Prompt-based_Incremental_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10445)
Exploring Transformers for Open-world Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Exploring_Transformers_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04206)
SSF- Accelerating Training of Spiking Neural Networks with Stabilized Spiking Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_SSF_Accelerating_Training_ICCV_2023_supplemental.pdf)
Manipulate by Seeing- Creating Manipulation Controllers from Pre-Trained Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Manipulate_by_Seeing_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08135)
Learning Human-Human Interactions in Images from Weak Textual Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Alper_Learning_Human-Human_Interactions_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.14104)
Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation for Non-Exemplar Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Prototype_Reminiscence_and_ICCV_2023_supplemental.pdf)
Exemplar-Free Continual Transformer with Convolutions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Roy_Exemplar-Free_Continual_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11357)
Efficient Decision-based Black-box Patch Attacks on Video Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11917)
MetaGCD- Learning to Continually Learn in Generalized Category Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_MetaGCD_Learning_to_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11063)
Strip-MLP- Efficient Token Interaction for Vision MLP | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.pdf)
SAFARI- Versatile and Efficient Evaluations for Robustness of Interpretability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_SAFARI_Versatile_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.09418)
Combating Noisy Labels with Sample Selection by Mining High-Discrepancy Examples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_Combating_Noisy_Labels_ICCV_2023_supplemental.pdf)
What can Discriminator do- Towards Box-free Ownership Verification of Generative Adversarial Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_What_can_Discriminator_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15860)
An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.02897)
3D-VisTA- Pre-trained Transformer for 3D Vision and Text Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_3D-VisTA_Pre-trained_Transformer_ICCV_2023_supplemental.zip)
SparseDet- Improving Sparsely Annotated Object Detection with Pseudo-positive Mining | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Suri_SparseDet_Improving_Sparsely_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04620)
Among Us- Adversarially Robust Collaborative Perception by Consensus | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.09495)
BUS- Efficient and Effective Vision-Language Pre-Training with Bottom-Up Patch Summarization. | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_BUS_Efficient_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08504)
SegPrompt- Boosting Open-World Segmentation via Category-Level Prompt Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_SegPrompt_Boosting_Open-World_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06531)
CL-MVSNet- Unsupervised Multi-View Stereo with Dual-Level Contrastive Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_supplemental.pdf)
TF-ICON- Diffusion-Based Training-Free Cross-Domain Image Composition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_TF-ICON_Diffusion-Based_Training-Free_ICCV_2023_supplemental.pdf)
Landscape Learning for Neural Network Inversion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2206.09027)
PPR- Physically Plausible Reconstruction from Monocular Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_PPR_Physically_Plausible_ICCV_2023_supplemental.pdf)
Robust Heterogeneous Federated Learning under Data Corruption | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Robust_Heterogeneous_Federated_ICCV_2023_supplemental.pdf)
Cyclic-Bootstrap Labeling for Weakly Supervised Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_Cyclic-Bootstrap_Labeling_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05991)
Tangent Sampson Error- Fast Approximate Two-view Reprojection Error for Central Camera Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Terekhov_Tangent_Sampson_Error_ICCV_2023_supplemental.pdf)
MPCViT- Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zeng_MPCViT_Searching_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.13955)
Masked Spiking Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Masked_Spiking_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.01208)
Joint Implicit Neural Representation for High-fidelity and Compact Vector Fonts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Joint_Implicit_Neural_ICCV_2023_supplemental.pdf)
Neural Characteristic Function Learning for Conditional Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Neural_Characteristic_Function_ICCV_2023_supplemental.pdf)
Holistic Label Correction for Noisy Multi-Label Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_Holistic_Label_Correction_ICCV_2023_supplemental.pdf)
Unified Data-Free Compression- Pruning and Quantization without Fine-Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bai_Unified_Data-Free_Compression_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07209)
Temporal Enhanced Training of Multi-view 3D Object Detector via Historical Object Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.00967)
PARIS- Part-level Reconstruction and Motion Analysis for Articulated Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_PARIS_Part-level_Reconstruction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07391)
OnlineRefer- A Simple Online Baseline for Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_OnlineRefer_A_Simple_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09356)
Environment Agnostic Representation for Visual Reinforcement Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choi_Environment_Agnostic_Representation_ICCV_2023_supplemental.pdf)
Mimic3D- Thriving 3D-Aware GANs via 3D-to-2D Imitation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Mimic3D_Thriving_3D-Aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09036)
Does Physical Adversarial Example Really Matter to Autonomous Driving- Towards System-Level Effect of Adversarial Object Evasion Attack | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.11894)
Generalizable Neural Fields as Partially Observed Neural Processes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.06660)
Adding Conditional Control to Text-to-Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Adding_Conditional_Control_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.05543)
3D Instance Segmentation via Enhanced Spatial and Semantic Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.pdf)
Unleashing Text-to-Image Diffusion Models for Visual Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.02153)
Transferable Adversarial Attack for Both Vision Transformers and Convolutional Networks via Momentum Integrated Gradients | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Transferable_Adversarial_Attack_ICCV_2023_supplemental.pdf)
Adaptive Image Anonymization in the Context of Image Classification with Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.pdf)
Efficient Neural Supersampling on a Novel Gaming Dataset | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mercier_Efficient_Neural_Supersampling_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.01483)
Walking Your LiDOG- A Journey Through Multiple Domains for LiDAR Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Saltori_Walking_Your_LiDOG_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11705)
Explore and Tell- Embodied Visual Captioning in 3D Environments | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Explore_and_Tell_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10447)
FastViT- A Fast Hybrid Vision Transformer Using Structural Reparameterization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Vasu_FastViT_A_Fast_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14189)
OFVL-MS- Once for Visual Localization across Multiple Indoor Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_OFVL-MS_Once_for_ICCV_2023_supplemental.pdf)
Inter-Realization Channels- Unsupervised Anomaly Detection Beyond One-Class Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/McIntosh_Inter-Realization_Channels_Unsupervised_ICCV_2023_supplemental.pdf)
High Quality Entity Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qi_High_Quality_Entity_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.05776)
CoTDet- Affordance Knowledge Prompting for Task Driven Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.01093)
Rendering Humans from Object-Occluded Monocular Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_Rendering_Humans_from_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04622)
Out-of-Distribution Detection for Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hornauer_Out-of-Distribution_Detection_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06072)
LLM-Planner- Few-Shot Grounded Planning for Embodied Agents with Large Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_LLM-Planner_Few-Shot_Grounded_ICCV_2023_supplemental.pdf)
Exploring Model Transferability through the Lens of Potential Energy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Exploring_Model_Transferability_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15074)
Diff-Retinex- Rethinking Low-light Image Enhancement with A Generative Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.pdf)
Birds-Eye-View Scene Graph for Vision-Language Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Birds-Eye-View_Scene_Graph_ICCV_2023_supplemental.pdf)
PVT++- A Simple End-to-End Latency-Aware Visual Tracking Framework | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_PVT_A_Simple_ICCV_2023_supplemental.pdf)
Supervised Homography Learning with Realistic Dataset Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.15353)
E2E-LOAD- End-to-End Long-form Online Action Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_E2E-LOAD_End-to-End_Long-form_ICCV_2023_supplemental.pdf)
Self-supervised Monocular Depth Estimation- Lets Talk About The Weather | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Saunders_Self-supervised_Monocular_Depth_ICCV_2023_supplemental.pdf)
Fast Neural Scene Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Fast_Neural_Scene_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09121)
ExposureDiffusion- Learning to Expose for Low-light Image Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_ExposureDiffusion_Learning_to_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07710)
RefEgo- Referring Expression Comprehension Dataset from First-Person Perception of Ego4D | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kurita_RefEgo_Referring_Expression_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12035)
Exploring Temporal Frequency Spectrum in Deep Video Deblurring | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.pdf)
Occ^2Net- Robust Image Matching Based on 3D Occupancy Estimation for Occluded Regions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf)
Make-An-Animation- Large-Scale Text-conditional 3D Human Motion Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.pdf)
AerialVLN- Vision-and-Language Navigation for UAVs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_AerialVLN_Vision-and-Language_Navigation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06735)
On the Robustness of Open-World Test-Time Training- Self-Training with Dynamic Prototype Expansion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_On_the_Robustness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09942)
Self-supervised Learning to Bring Dual Reversed Rolling Shutter Images Alive | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.19862)
Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.05605)
Few-Shot Common Action Localization via Cross-Attentional Fusion of Context and Temporal Dynamics | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.pdf)
Physically-Plausible Illumination Distribution Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.pdf)
Revisiting Foreground and Background Separation in Weakly-supervised Temporal Action Localization- A Clustering-based Approach | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Revisiting_Foreground_and_ICCV_2023_supplemental.pdf)
3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_3D-Aware_Neural_Body_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10123)
Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01083)
Exploiting Proximity-Aware Tasks for Embodied Social Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2212.00767)
Hierarchical Contrastive Learning for Pattern-Generalizable Image Corruption Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Hierarchical_Contrastive_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14061)
Learning Optical Flow from Event Camera with Rendered Dataset | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.11011)
EPiC- Ensemble of Partial Point Clouds for Robust Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Levi_EPiC_Ensemble_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11419)
Cross-Modal Learning with 3D Deformable Attention for Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Cross-Modal_Learning_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.05638)
Tracking by 3D Model Estimation of Unknown Objects in Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rozumnyi_Tracking_by_3D_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.06419)
Sigmoid Loss for Language Image Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_Sigmoid_Loss_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15343)
Neural Video Depth Stabilizer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Neural_Video_Depth_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08695)
Learning Symmetry-Aware Geometry Correspondences for 6D Object Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf)
TrackFlow- Multi-Object tracking with Normalizing Flows | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.11513)
Generating Instance-level Prompts for Rehearsal-free Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jung_Generating_Instance-level_Prompts_ICCV_2023_supplemental.pdf)
HSE- Hybrid Species Embedding for Deep Metric Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.pdf)
Online Continual Learning on Hierarchical Label Expansion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Online_Continual_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14374)
3D Motion Magnification- Visualizing Subtle Motions from Time-Varying Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.pdf)
Learning Spatial-context-aware Global Visual Feature Representation for Instance Image Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Learning_Spatial-context-aware_Global_ICCV_2023_supplemental.pdf)
Space-time Prompting for Video Class-incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_supplemental.pdf)
Sparse Sampling Transformer with Uncertainty-Driven Ranking for Unified Removal of Raindrops and Rain Streaks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Sparse_Sampling_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14153)
LexLIP- Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Sparse Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_ICCV_2023_supplemental.pdf)
LFS-GAN- Lifelong Few-Shot Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Seo_LFS-GAN_Lifelong_Few-Shot_ICCV_2023_supplemental.pdf)
MixCycle- Mixup Assisted Semi-Supervised 3D Single Object Tracking with Cycle Consistency | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_MixCycle_Mixup_Assisted_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09219)
DiffFacto- Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakayama_DiffFacto_Controllable_Part-Based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.01921)
Spatio-temporal Prompting Network for Robust Video Feature Extraction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Spatio-temporal_Prompting_Network_ICCV_2023_supplemental.pdf)
A Simple Vision Transformer for Weakly Semi-supervised 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_A_Simple_Vision_ICCV_2023_supplemental.pdf)
Open-domain Visual Entity Recognition- Towards Recognizing Millions of Wikipedia Entities | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Open-domain_Visual_Entity_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.11154)
A Soft Nearest-Neighbor Framework for Continual Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.05102)
Minimal Solutions to Uncalibrated Two-view Geometry with Known Epipoles | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.pdf)
Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Context-Aware_Planning_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.07241)
Passive Ultra-Wideband Single-Photon Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Passive_Ultra-Wideband_Single-Photon_ICCV_2023_supplemental.zip)
Deep Video Demoireing via Compact Invertible Dyadic Decomposition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Quan_Deep_Video_Demoireing_ICCV_2023_supplemental.pdf)
Scene Graph Contrastive Learning for Embodied Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Singh_Scene_Graph_Contrastive_ICCV_2023_supplemental.zip)
Preparing the Future for Continual Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.pdf)
Synthesizing Diverse Human Motions in 3D Indoor Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Synthesizing_Diverse_Human_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.12411)
Deep Optics for Video Snapshot Compressive Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Deep_Optics_for_ICCV_2023_supplemental.zip)
Joint Demosaicing and Deghosting of Time-Varying Exposures for Single-Shot HDR Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Joint_Demosaicing_and_ICCV_2023_supplemental.zip)
Tuning Pre-trained Model via Moment Probing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Tuning_Pre-trained_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11342), [](http://arxiv.org/abs/2307.11342)
Task Agnostic Restoration of Natural Video Dynamics | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ali_Task_Agnostic_Restoration_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2206.03753)
TMR- Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Petrovich_TMR_Text-to-Motion_Retrieval_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.00976)
SINC- Self-Supervised In-Context Learning for Vision-Language Tasks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_SINC_Self-Supervised_In-Context_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07742)
Learning a Room with the Occ-SDF Hybrid- Signed Distance Function Mingled with Occupancy Aids Scene Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lyu_Learning_a_Room_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09152)
Cloth2Body- Generating 3D Human Body Mesh from 2D Clothing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.pdf)
Spatially and Spectrally Consistent Deep Functional Maps | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Spatially_and_Spectrally_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08871)
Sparse Point Guided 3D Lane Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_Sparse_Point_Guided_ICCV_2023_supplemental.pdf)
Event-based Temporally Dense Optical Flow Estimation with Sequential Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ponghiran_Event-based_Temporally_Dense_ICCV_2023_supplemental.zip)
Continual Zero-Shot Learning through Semantically Guided Generative Random Walks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Continual_Zero-Shot_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12366)
Foreground-Background Distribution Modeling Transformer for Visual Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Foreground-Background_Distribution_Modeling_ICCV_2023_supplemental.pdf)
Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.08220)
Both Diverse and Realism Matter- Physical Attribute and Style Alignment for Rainy Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Both_Diverse_and_ICCV_2023_supplemental.zip)
Single Image Reflection Separation via Component Synergy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Single_Image_Reflection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10027)
SFHarmony- Source Free Domain Adaptation for Distributed Neuroimaging Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dinsdale_SFHarmony_Source_Free_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.15965)
3D Human Mesh Recovery with Sequentially Global Rotation Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.pdf)
DREAMWALKER- Mental Planning for Continuous Vision-Language Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.07498)
LAN-HDR- Luminance-based Alignment Network for High Dynamic Range Video Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.pdf)
Dancing in the Dark- A Benchmark towards General Low-light Video Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.pdf)
RED-PSM- Regularization by Denoising of Partially Separable Models for Dynamic Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Iskender_RED-PSM_Regularization_by_ICCV_2023_supplemental.pdf)
D-IF- Uncertainty-aware Human Digitization via Implicit Distribution Field | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf)
AffordPose- A Large-Scale Dataset of Hand-Object Interactions with Affordance-Driven Hand Pose | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jian_AffordPose_A_Large-Scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.08942)
Locomotion-Action-Manipulation- Synthesizing Human-Scene Interactions in Complex 3D Environments | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_ICCV_2023_supplemental.zip)
NDDepth- Normal-Distance Assisted Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_NDDepth_Normal-Distance_Assisted_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10592)
Sequential Texts Driven Cohesive Motions Synthesis with Natural Transitions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Sequential_Texts_Driven_ICCV_2023_supplemental.pdf)
Efficient Converted Spiking Neural Network for 3D and 2D Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.pdf)
Eulerian Single-Photon Vision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_supplemental.pdf)
NSF- Neural Surface Fields for Human Modeling from Monocular Depth | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xue_NSF_Neural_Surface_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14847)
Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code Diffusion using Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Corona-Figueroa_Unaligned_2D_to_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.14152)
DMNet- Delaunay Meshing Network for 3D Shape Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_DMNet_Delaunay_Meshing_ICCV_2023_supplemental.zip)
Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Body_Knowledge_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00799)
Equivariant Similarity for Vision-Language Foundation Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14465)
ReST- A Reconfigurable Spatial-Temporal Graph Model for Multi-Camera Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_ReST_A_Reconfigurable_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13229)
DiffTAD- Temporal Action Detection with Proposal Denoising Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nag_DiffTAD_Temporal_Action_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14863)
Heterogeneous Diversity Driven Active Learning for Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Heterogeneous_Diversity_Driven_ICCV_2023_supplemental.pdf)
Dual Aggregation Transformer for Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Dual_Aggregation_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03364)
Semantify- Simplifying the Control of 3D Morphable Models Using CLIP | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gralnik_Semantify_Simplifying_the_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.07415)
From Sky to the Ground- A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_From_Sky_to_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.03867)
JOTR- 3D Joint Contrastive Learning with Transformers for Occluded Human Mesh Recovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_JOTR_3D_Joint_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16377)
NIR-assisted Video Enhancement via Unpaired 24-hour Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Niu_NIR-assisted_Video_Enhancement_ICCV_2023_supplemental.pdf)
VeRi3D- Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_VeRi3D_Generative_Vertex-based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04800)
SHIFT3D- Synthesizing Hard Inputs For Tricking 3D Detectors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_SHIFT3D_Synthesizing_Hard_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05810)
Coordinate Transformer- Achieving Single-stage Multi-person Mesh Recovery from Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Coordinate_Transformer_Achieving_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10334)
Boosting Positive Segments for Weakly-Supervised Audio-Visual Video Parsing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rachavarapu_Boosting_Positive_Segments_ICCV_2023_supplemental.pdf)
Sign Language Translation with Iterative Prototype | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.12191)
Humans in 4D- Reconstructing and Tracking Humans with Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Goel_Humans_in_4D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.20091)
Perpetual Humanoid Control for Real-time Simulated Avatars | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_Perpetual_Humanoid_Control_ICCV_2023_supplemental.zip)
Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Score_Priors_Guided_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04682)
Improving Transformer-based Image Matching by Cascaded Capturing Spatially Informative Keypoints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Improving_Transformer-based_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.02885)
Boundary-Aware Divide and Conquer- A Diffusion-Based Solution for Unsupervised Shadow Removal | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Boundary-Aware_Divide_and_ICCV_2023_supplemental.pdf)
Towards Nonlinear-Motion-Aware and Occlusion-Robust Rolling Shutter Correction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qu_Towards_Nonlinear-Motion-Aware_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.18125)
GraphEcho- Graph-Driven Unsupervised Domain Adaptation for Echocardiogram Video Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_GraphEcho_Graph-Driven_Unsupervised_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.11145)
Augmented Box Replay- Overcoming Foreground Shift for Incremental Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Augmented_Box_Replay_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12427)
Lighting Every Darkness in Two Pairs- A Calibration-Free Pipeline for RAW Denoising | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jin_Lighting_Every_Darkness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03448)
MotionBERT- A Unified Perspective on Learning Human Motion Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2210.06551)
Metric3D- Towards Zero-shot Metric 3D Prediction from A Single Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_Metric3D_Towards_Zero-shot_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10984)
Lightweight Image Super-Resolution with Superpixel Token Interaction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.pdf)
Iterative Denoiser and Noise Estimator for Self-Supervised Image Denoising | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.pdf)
Memory-and-Anticipation Transformer for Online Action Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07893)
Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Realistic_Full-Body_Tracking_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.08855)
MetaF2N- Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_MetaF2N_Blind_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.08113)
Lighting up NeRF via Unsupervised Decomposition and Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.10664)
ViM- Vision Middleware for Unified Downstream Transferring | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.06911)
Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/You_Co-Evolution_of_Pose_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10305)
Viewset Diffusion- (0-)Image-Conditioned 3D Generative Models from 2D Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_ICCV_2023_supplemental.pdf)
SIRA-PCR- Sim-to-Real Adaptation for 3D Point Cloud Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_SIRA-PCR_Sim-to-Real_Adaptation_ICCV_2023_supplemental.pdf)
SOAR- Scene-debiasing Open-set Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_SOAR_Scene-debiasing_Open-set_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01265)
Discovering Spatio-Temporal Rationales for Video Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.12058)
Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09650)
G2L- Semantically Aligned and Uniform Video Grounding via Geodesic and Game Theory | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_G2L_Semantically_Aligned_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14277)
FashionNTM- Multi-turn Fashion Image Retrieval via Cascaded Memory | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pal_FashionNTM_Multi-turn_Fashion_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.10170)
Towards Zero Domain Gap- A Comprehensive Study of Realistic LiDAR Simulation for Autonomy Testing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Manivasagam_Towards_Zero_Domain_ICCV_2023_supplemental.pdf)
Random Sub-Samples Generation for Self-Supervised Real Image Denoising | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Random_Sub-Samples_Generation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16825)
Waffling Around for Performance- Visual Classification with Random Words and Broad Concepts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Roth_Waffling_Around_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.07282)
AutoAD II- The Sequel - Who, When, and What in Movie Audio Description | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_AutoAD_II_The_ICCV_2023_supplemental.pdf)
Hyperbolic Chamfer Distance for Point Cloud Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.pdf)
AG3D- Learning to Generate 3D Avatars from 2D Image Collections | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_AG3D_Learning_to_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.02312)
Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-spectral Image Fusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.16083)
NCHO- Unsupervised Learning for Neural 3D Composition of Humans and Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_NCHO_Unsupervised_Learning_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2305.14345)
Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Learning_Non-Local_Spatial-Angular_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.08058)
MGMAE- Motion Guided Masking for Video Masked Autoencoding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10794)
ViewRefer- Grasp the Multi-view Knowledge for 3D Visual Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.16894)
CaPhy- Capturing Physical Properties for Animatable Human Avatars | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Su_CaPhy_Capturing_Physical_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.05925)
Fine-grained Unsupervised Domain Adaptation for Gait Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.pdf)
Instance-aware Dynamic Prompt Tuning for Pre-trained Point Cloud Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zha_Instance-aware_Dynamic_Prompt_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.07221)
GeoUDF- Surface Reconstruction from 3D Point Clouds via Geometry-guided Distance Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_GeoUDF_Surface_Reconstruction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.16762)
MeMOTR- Long-Term Memory-Augmented Transformer for Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_MeMOTR_Long-Term_Memory-Augmented_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15700)
RawHDR- High Dynamic Range Image Reconstruction from a Single Raw Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.02020)
Robust Object Modeling for Visual Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.05140)
FSI- Frequency and Spatial Interactive Learning for Image Restoration in Under-Display Cameras | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_supplemental.pdf)
Temporal Collection and Distribution for Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.03473)
Variational Degeneration to Structural Refinement- A Unified Framework for Superimposed Image Decomposition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.pdf)
Focal Network for Image Restoration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cui_Focal_Network_for_ICCV_2023_supplemental.pdf)
Indoor Depth Recovery Based on Deep Unfolding with Non-Local Prior | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.pdf)
GAFlow- Incorporating Gaussian Attention into Optical Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf)
SoDaCam- Software-defined Cameras via Single-Photon Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sundar_SoDaCam_Software-defined_Cameras_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.00066)
Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_Decoupled_Iterative_Refinement_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2302.02410)
Who Are You Referring To- Coreference Resolution In Image Narrations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Goel_Who_Are_You_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.14563)
Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Leng_Dynamic_Hyperbolic_Attention_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02965)
LivePose- Online 3D Reconstruction from Monocular Video with Dynamic Camera Poses | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.00054)
Feature Modulation Transformer- Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Feature_Modulation_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05022)
MPI-Flow- Learning Realistic Optical Flow with Multiplane Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.pdf)
Learning Depth Estimation for Transparent and Mirror Surfaces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Costanzino_Learning_Depth_Estimation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15052)
Towards Zero-Shot Scale-Aware Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guizilini_Towards_Zero-Shot_Scale-Aware_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.17253)
PromptStyler- Prompt-driven Style Generation for Source-free Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_PromptStyler_Prompt-driven_Style_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15199)
SVQNet- Sparse Voxel-Adjacent Query Network for 4D Spatio-Temporal LiDAR Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.13323)
MEFLUT- Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.11847)
The Unreasonable Effectiveness of Large Language-Vision Models for Source-Free Video Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zara_The_Unreasonable_Effectiveness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09139)
Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Sketch_and_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.02874)
Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.06810)
Adversarial Bayesian Augmentation for Single-Source Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Adversarial_Bayesian_Augmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09520)
Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Robust_Geometry-Preserving_Depth_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.09724)
Self-regulating Prompts- Foundational Model Adaptation without Forgetting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Khattak_Self-regulating_Prompts_Foundational_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.06948)
Improving Lens Flare Removal with General-Purpose Pipeline and Multiple Light Sources Recovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.16460)
DCPB- Deformable Convolution Based on the Poincare Ball for Top-view Fisheye Cameras | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.pdf)
Integrating Boxes and Masks- A Multi-Object Framework for Unified Visual Tracking and Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Integrating_Boxes_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.13266)
3DMOTFormer- Graph Transformer for Online 3D Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ding_3DMOTFormer_Graph_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06635)
ReGen- A good Generative Zero-Shot Video Classifier Should be Rewarded | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bulat_ReGen_A_good_ICCV_2023_supplemental.pdf)
Complementary Domain Adaptation and Generalization for Unsupervised Continual Domain Shift Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_Complementary_Domain_Adaptation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15833)
Ordered Atomic Activity for Fine-grained Interactive Traffic Scenario Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Agarwal_Ordered_Atomic_Activity_ICCV_2023_supplemental.pdf)
BEV-DG- Cross-Modal Learning under Birds-Eye View for Domain Generalization of 3D Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_BEV-DG_Cross-Modal_Learning_ICCV_2023_supplemental.pdf)
Grounded Entity-Landmark Adaptive Pre-Training for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cui_Grounded_Entity-Landmark_Adaptive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12587)
Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Lip_Reading_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09311)
HopFIR- Hop-wise GraphFormer with Intragroup Joint Refinement for 3D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_HopFIR_Hop-wise_GraphFormer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.14581)
Minimal Solutions to Generalized Three-View Relative Pose Problem | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ding_Minimal_Solutions_to_ICCV_2023_supplemental.pdf)
Trajectory Unified Transformer for Pedestrian Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Trajectory_Unified_Transformer_ICCV_2023_supplemental.pdf)
MHEntropy- Entropy Meets Multiple Hypotheses for Pose and Shape Recovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_MHEntropy_Entropy_Meets_ICCV_2023_supplemental.pdf)
Modeling the Relative Visual Tempo for Self-supervised Skeleton-based Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf)
ImbSAM- A Closer Look at Sharpness-Aware Minimization in Class-Imbalanced Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.07815)
MonoDETR- Depth-guided Transformer for Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_MonoDETR_Depth-guided_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13310)
Contrastive Feature Masking Open-Vocabulary Vision Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Contrastive_Feature_Masking_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.00775)
OccFormer- Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.05316)
Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Probabilistic_Triangulation_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04756)
TORE- Token Reduction for Efficient Human Mesh Recovery with Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dou_TORE_Token_Reduction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10705)
D3G- Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_D3G_Exploring_Gaussian_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04197)
GEDepth- Ground Embedding for Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_GEDepth_Ground_Embedding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.09975)
Animal3D- A Comprehensive Dataset of 3D Animal Pose and Shape | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Animal3D_A_Comprehensive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11737)
Rethinking Video Frame Interpolation from Shutter Mode Induced Degradation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Rethinking_Video_Frame_ICCV_2023_supplemental.pdf)
Semantic-Aware Dynamic Parameter for Video Inpainting Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Semantic-Aware_Dynamic_Parameter_ICCV_2023_supplemental.zip)
SKED- Sketch-guided Text-based 3D Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mikaeili_SKED_Sketch-guided_Text-based_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.10735)
MBPTrack- Improving 3D Point Cloud Tracking with Memory Networks and Box Priors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_MBPTrack_Improving_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05071)
Novel-View Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qu_Novel-View_Synthesis_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.11198)
Distilling from Similar Tasks for Transfer Learning on a Budget | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Borup_Distilling_from_Similar_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.12314)
Self-Supervised Burst Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_supplemental.pdf)
PC-Adapter- Topology-Aware Adapter for Efficient Domain Adaption on Point Clouds with Rectified Pseudo-label | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_PC-Adapter_Topology-Aware_Adapter_ICCV_2023_supplemental.pdf)
Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nam_Cyclic_Test-Time_Adaptation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.06554)
2D3D-MATR- 2D-3D Matching Transformer for Detection-Free Registration Between Images and Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_2D3D-MATR_2D-3D_Matching_ICCV_2023_supplemental.pdf)
Group Pose- A Simple Baseline for End-to-End Multi-Person Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Group_Pose_A_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07313)
SkeleTR- Towards Skeleton-based Action Recognition in the Wild | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.pdf)
Weakly-Supervised Action Localization by Hierarchically-Structured Latent Attention Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Weakly-Supervised_Action_Localization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09946)
Get3DHuman- Lifting StyleGAN-Human into a 3D Generative Model Using Pixel-Aligned Reconstruction Priors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.01162)
Query6DoF- Learning Sparse Queries as Implicit Shape Prior for Category-Level 6DoF Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.pdf)
Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.06302)
Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Najibi_Unsupervised_3D_Perception_ICCV_2023_supplemental.pdf)
Towards Grand Unified Representation Learning for Unsupervised Visible-Infrared Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Towards_Grand_Unified_ICCV_2023_supplemental.pdf)
ReFit- Recurrent Fitting Network for 3D Human Recovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_ReFit_Recurrent_Fitting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11184)
Verbs in Action- Improving Verb Understanding in Video-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Momeni_Verbs_in_Action_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06708)
Zero-Shot Point Cloud Segmentation by Semantic-Visual Aware Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Zero-Shot_Point_Cloud_ICCV_2023_supplemental.pdf)
Exploring Predicate Visual Context in Detecting of Human-Object Interactions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Exploring_Predicate_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06202)
Towards Saner Deep Image Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Duan_Towards_Saner_Deep_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09696)
Interaction-aware Joint Attention Estimation Using People Attributes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakatani_Interaction-aware_Joint_Attention_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05382)
Non-Coaxial Event-Guided Motion Deblurring with Spatial Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_Non-Coaxial_Event-Guided_Motion_ICCV_2023_supplemental.zip)
Fingerprinting Deep Image Restoration Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Quan_Fingerprinting_Deep_Image_ICCV_2023_supplemental.pdf)
SportsMOT- A Large Multi-Object Tracking Dataset in Multiple Sports Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.05170)
Localizing Moments in Long Video Via Multimodal Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barrios_Localizing_Moments_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.13372)
Towards Universal Image Embeddings- A Large-Scale Dataset and Challenge for Generic Image Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ypsilantis_Towards_Universal_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01858)
SemARFlow- Injecting Semantics into Unsupervised Optical Flow Estimation for Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_SemARFlow_Injecting_Semantics_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.06209)
Uncertainty-aware Unsupervised Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Uncertainty-aware_Unsupervised_Multi-Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15409)
Designing Phase Masks for Under-Display Cameras | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Designing_Phase_Masks_ICCV_2023_supplemental.pdf)
Can Language Models Learn to Listen- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10897)
SurfsUP- Learning Fluid Simulation for Novel Surfaces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mani_SurfsUP_Learning_Fluid_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.06197)
Regularized Mask Tuning- Uncovering Hidden Knowledge in Pre-Trained Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Regularized_Mask_Tuning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15049)
Skill Transformer- A Monolithic Policy for Mobile Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Skill_Transformer_A_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.09873)
Adaptive and Background-Aware Vision Transformer for Real-Time UAV Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Adaptive_and_Background-Aware_ICCV_2023_supplemental.zip)
Persistent-Transient Duality- A Multi-Mechanism Approach for Modeling Human-Object Interaction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tran_Persistent-Transient_Duality_A_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.12729)
DDS2M- Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Miao_DDS2M_Self-Supervised_Denoising_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.06682)
MotionLM- Multi-Agent Motion Forecasting as Language Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Seff_MotionLM_Multi-Agent_Motion_ICCV_2023_supplemental.zip)
Black Box Few-Shot Adaptation for Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ouali_Black_Box_Few-Shot_ICCV_2023_supplemental.pdf)
Zero-1-to-3- Zero-shot One Image to 3D Object | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Zero-1-to-3_Zero-shot_One_ICCV_2023_supplemental.zip)
3D Distillation- Improving Self-Supervised Monocular Depth Estimation on Reflective Surfaces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_3D_Distillation_Improving_ICCV_2023_supplemental.zip)
Low-Light Image Enhancement with Multi-Stage Residue Quantization and Brightness-Aware Attention | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Low-Light_Image_Enhancement_ICCV_2023_supplemental.pdf)
Hierarchically Decomposed Graph Convolutional Networks for Skeleton-Based Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Hierarchically_Decomposed_Graph_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.10741)
LIST- Learning Implicitly from Spatial Transformers for Single-View 3D Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Arshad_LIST_Learning_Implicitly_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12194)
LRRU- Long-short Range Recurrent Updating Networks for Depth Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.pdf)
MetaBEV- Solving Sensor Failures for 3D Detection and Map Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_MetaBEV_Solving_Sensor_ICCV_2023_supplemental.pdf)
Exploring Temporal Concurrency for Video-Language Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Exploring_Temporal_Concurrency_ICCV_2023_supplemental.pdf)
DynamicISP- Dynamically Controlled Image Signal Processor for Image Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yoshimura_DynamicISP_Dynamically_Controlled_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.01146)
R-Pred- Two-Stage Motion Prediction Via Tube-Query Attention-Based Trajectory Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choi_R-Pred_Two-Stage_Motion_ICCV_2023_supplemental.pdf)
Aggregating Feature Point Cloud for Depth Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Aggregating_Feature_Point_ICCV_2023_supplemental.pdf)
Reconstructed Convolution Module Based Look-Up Tables for Efficient Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.08544)
Action Sensitivity Learning for Temporal Action Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Action_Sensitivity_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.15701)
PEANUT- Predicting and Navigating to Unseen Targets | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_PEANUT_Predicting_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.02497)
PoseDiffusion- Solving Pose Estimation via Diffusion-aided Bundle Adjustment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_PoseDiffusion_Solving_Pose_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.15667)
CORE- Cooperative Reconstruction for Multi-Agent Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.11514)
SEFD- Learning to Distill Complex Pose and Occlusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_SEFD_Learning_to_ICCV_2023_supplemental.pdf)
CiT- Curation in Training for Effective Vision-Language Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_CiT_Curation_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.02241)
SparseNeRF- Distilling Depth Ranking for Few-shot Novel View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.16196)
ProPainter- Improving Propagation and Transformer for Video Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_ProPainter_Improving_Propagation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03897)
Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Root_Pose_Decomposition_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10089)
GLA-GCN- Global-local Adaptive Graph Convolutional Network for 3D Human Pose Estimation from Monocular Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.pdf)
Snow Removal in Video- A New Dataset and A Novel Method | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Snow_Removal_in_ICCV_2023_supplemental.zip)
Degradation-Resistant Unfolding Network for Heterogeneous Image Fusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Degradation-Resistant_Unfolding_Network_ICCV_2023_supplemental.pdf)
Priority-Centric Human Motion Generation in Discrete Latent Space | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.14480)
3DHacker- Spectrum-based Decision Boundary Generation for Hard-label 3D Point Cloud Attack | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tao_3DHacker_Spectrum-based_Decision_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07546)
Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.06904)
MiniROAD- Minimal RNN Framework for Online Action Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_supplemental.pdf)
NDC-Scene- Boost Monocular 3D Semantic Scene Completion in Normalized Device Coordinates Space | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_NDC-Scene_Boost_Monocular_ICCV_2023_supplemental.pdf)
SVDFormer- Complementing Point Cloud via Self-view Augmentation and Self-structure Dual-generator | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_SVDFormer_Complementing_Point_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08492)
E3Sym- Leveraging E(3) Invariance for Unsupervised 3D Planar Reflective Symmetry Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_E3Sym_Leveraging_E3_ICCV_2023_supplemental.pdf)
Zero-Shot Composed Image Retrieval with Textual Inversion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Baldrati_Zero-Shot_Composed_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15247)
BiFF- Bi-level Future Fusion with Polyline-based Coordinate for Interactive Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_BiFF_Bi-level_Future_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.14161)
COOL-CHIC- Coordinate-based Low Complexity Hierarchical Image Codec | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.pdf)
Normalizing Flows for Human Pose Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hirschorn_Normalizing_Flows_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10946)
Reconstructing Groups of People with Hypergraph Relational Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Reconstructing_Groups_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15844)
What Does a Platypus Look Like- Generating Customized Prompts for Zero-Shot Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pratt_What_Does_a_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2209.03320)
Scene as Occupancy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tong_Scene_as_Occupancy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tong_Scene_as_Occupancy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tong_Scene_as_Occupancy_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.02851)
U-RED- Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Di_U-RED_Unsupervised_3D_ICCV_2023_supplemental.pdf)
PatchCT- Aligning Patch Set and Label Set with Conditional Transport for Multi-Label Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.09066)
VI-Net- Boosting Category-level 6D Object Pose Estimation via Learning Decoupled Rotations on the Spherical Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_VI-Net_Boosting_Category-level_ICCV_2023_supplemental.pdf)
Long-range Multimodal Pretraining for Movie Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09775)
Adverse Weather Removal with Codebook Priors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Adverse_Weather_Removal_ICCV_2023_supplemental.pdf)
MAP- Towards Balanced Generalization of IID and OOD through Model-Agnostic Adapters | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_MAP_Towards_Balanced_ICCV_2023_supplemental.pdf)
Exploring Group Video Captioning with Efficient Relational Approximation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Exploring_Group_Video_ICCV_2023_supplemental.pdf)
ADAPT- Efficient Multi-Agent Trajectory Prediction with Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Aydemir_ADAPT_Efficient_Multi-Agent_ICCV_2023_supplemental.pdf)
MAPConNet- Self-supervised 3D Pose Transfer with Mesh and Point Contrastive Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_MAPConNet_Self-supervised_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.13819)
DARTH- Holistic Test-time Adaptation for Multiple Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Segu_DARTH_Holistic_Test-time_ICCV_2023_supplemental.pdf)
Multi-interactive Feature Learning and a Full-time Multi-modality Benchmark for Image Fusion and Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Multi-interactive_Feature_Learning_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.02097)
BaRe-ESA- A Riemannian Framework for Unregistered Human Body Shapes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hartman_BaRe-ESA_A_Riemannian_ICCV_2023_supplemental.zip)
Skip-Plan- Procedure Planning in Instructional Videos via Condensed Action Space Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Skip-Plan_Procedure_Planning_ICCV_2023_supplemental.pdf)
Sparse Instance Conditioned Multimodal Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.pdf)
NAPA-VQ- Neighborhood-Aware Prototype Augmentation with Vector Quantization for Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_ICCV_2023_supplemental.pdf)
Unsupervised Open-Vocabulary Object Localization in Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Unsupervised_Open-Vocabulary_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.09858)
Unsupervised Video Deraining with An Event Camera | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Unsupervised_Video_Deraining_ICCV_2023_supplemental.pdf)
DIME-FM - DIstilling Multimodal and Efficient Foundation Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_supplemental.pdf)
Boosting Single Image Super-Resolution via Partial Channel Shifting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Boosting_Single_Image_ICCV_2023_supplemental.pdf)
Distracting Downpour- Adversarial Weather Attacks for Motion Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Schmalfuss_Distracting_Downpour_Adversarial_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.06716)
Unfolding Framework with Prior of Convolution-Transformer Mixture and Uncertainty Estimation for Video Snapshot Compressive Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Unfolding_Framework_with_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.11316)
Non-Semantics Suppressed Mask Learning for Unsupervised Video Semantic Compression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.pdf)
Inverse Compositional Learning for Weakly-supervised Relation Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.pdf)
Navigating to Objects Specified by Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Krantz_Navigating_to_Objects_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01192)
LATR- 3D Lane Detection from Monocular Images with Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_LATR_3D_Lane_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04583)
Environment-Invariant Curriculum Relation Learning for Fine-Grained Scene Graph Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.03282)
Generalizable Decision Boundaries- Dualistic Meta-Learning for Open Set Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09391)
SimFIR- A Simple Framework for Fisheye Image Rectification with Self-supervised Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_SimFIR_A_Simple_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09040)
Generalized Lightness Adaptation with Channel Selective Normalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_Generalized_Lightness_Adaptation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13783)
Omnidirectional Information Gathering for Knowledge Transfer-Based Audio-Visual Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Omnidirectional_Information_Gathering_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10306)
Multi-Scale Bidirectional Recurrent Network with Hybrid Correlation for Point Cloud Based Scene Flow Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.pdf)
VLN-PETL- Parameter-Efficient Transfer Learning for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qiao_VLN-PETL_Parameter-Efficient_Transfer_ICCV_2023_supplemental.pdf)
Learning Continuous Exposure Value Representations for Single-Image HDR Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Learning_Continuous_Exposure_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.03900)
MixSynthFormer- A Transformer Encoder-like Structure with Mixed Synthetic Self-attention for Efficient Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_MixSynthFormer_A_Transformer_ICCV_2023_supplemental.zip)
HumanMAC- Masked Motion Completion for Human Motion Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_HumanMAC_Masked_Motion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.03665)
Prompt Switch- Efficient CLIP Adaptation for Text-Video Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.07648)
Video Action Recognition with Attentive Semantic Units | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.09756)
Scanning Only Once- An End-to-end Framework for Fast Temporal Grounding in Long Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Scanning_Only_Once_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08345)
VoroMesh- Learning Watertight Surface Meshes with Voronoi Diagrams | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Maruani_VoroMesh_Learning_Watertight_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14616)
What does CLIP know about a red circle- Visual prompt engineering for VLMs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shtedritski_What_does_CLIP_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06712)
LoLep- Single-View View Synthesis with Locally-Learned Planes and Self-Attention Occlusion Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_LoLep_Single-View_View_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.12217)
Exploring Positional Characteristics of Dual-Pixel Data for Camera Autofocus | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choi_Exploring_Positional_Characteristics_ICCV_2023_supplemental.pdf)
Heterogeneous Forgetting Compensation for Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Heterogeneous_Forgetting_Compensation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03374)
FemtoDet- An Object Detection Baseline for Energy Versus Performance Tradeoffs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.06719)
Iterative Prompt Learning for Unsupervised Backlit Image Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17569)
UATVR- Uncertainty-Adaptive Text-Video Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_UATVR_Uncertainty-Adaptive_Text-Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.06309)
SALAD- Part-Level Latent Diffusion for 3D Shape Generation and Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Koo_SALAD_Part-Level_Latent_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.12236)
COMPASS- High-Efficiency Deep Image Compression with Arbitrary-scale Spatial Scalability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_COMPASS_High-Efficiency_Deep_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07926)
Score-Based Diffusion Models as Principled Priors for Inverse Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Score-Based_Diffusion_Models_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11751)
Multiscale Structure Guided Diffusion for Image Deblurring | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_Multiscale_Structure_Guided_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.01789)
CheckerPose- Progressive Dense Keypoint Localization for Object Pose Estimation with Graph Neural Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lian_CheckerPose_Progressive_Dense_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.16874)
Event Camera Data Pre-training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.01928)
One-shot Implicit Animatable Avatars with Model-based Priors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_One-shot_Implicit_Animatable_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.02469)
Unsupervised Feature Representation Learning for Domain-generalized Cross-domain Image Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Unsupervised_Feature_Representation_ICCV_2023_supplemental.pdf)
Dec-Adapter- Exploring Efficient Decoder-Side Adapter for Bridging Screen Content and Natural Image Compression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shen_Dec-Adapter_Exploring_Efficient_ICCV_2023_supplemental.pdf)
Under-Display Camera Image Restoration with Scattering Effect | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Under-Display_Camera_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04163)
VideoFlow- Exploiting Temporal Cues for Multi-frame Optical Flow Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08340)
3DMiner- Discovering Shapes from Large-Scale Unannotated Image Datasets | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.pdf)
Order-Prompted Tag Sequence Generation for Video Tagging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Order-Prompted_Tag_Sequence_ICCV_2023_supplemental.pdf)
XVO- Generalized Visual Odometry via Cross-Modal Self-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.pdf)
HMD-NeMo- Online 3D Avatar Motion Generation From Sparse Observations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Aliakbarian_HMD-NeMo_Online_3D_ICCV_2023_supplemental.pdf)
Adaptive Illumination Mapping for Shadow Detection in Raw Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.pdf)
Multi-Scale Residual Low-Pass Filter Network for Image Deblurring | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Multi-Scale_Residual_Low-Pass_ICCV_2023_supplemental.pdf)
PhaseMP- Robust 3D Pose Estimation via Phase-conditioned Human Motion Prior | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_PhaseMP_Robust_3D_ICCV_2023_supplemental.zip)
NLOS-NeuS- Non-line-of-sight Neural Implicit Surface | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_ICCV_2023_supplemental.pdf)
Augmenting and Aligning Snippets for Few-Shot Video Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Augmenting_and_Aligning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10451)
Towards Real-World Burst Image Super-Resolution- Benchmark and Method | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Towards_Real-World_Burst_ICCV_2023_supplemental.pdf)
SYENet- A Simple Yet Effective Network for Multiple Low-Level Vision Tasks with Real-Time Performance on Mobile Device | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gou_SYENet_A_Simple_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08137)
EdaDet- Open-Vocabulary Object Detection Using Early Dense Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.01151)
DOLCE- A Model-Based Probabilistic Diffusion Framework for Limited-Angle CT Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_DOLCE_A_Model-Based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.12340)
Beyond Image Borders- Learning Feature Extrapolation for Unbounded Image Composition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Beyond_Image_Borders_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12042)
DeepChange- A Long-Term Person Re-Identification Benchmark with Clothes Change | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_DeepChange_A_Long-Term_ICCV_2023_supplemental.pdf)
Discrepant and Multi-Instance Proxies for Unsupervised Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zou_Discrepant_and_Multi-Instance_ICCV_2023_supplemental.pdf)
Joint-Relation Transformer for Multi-Person Motion Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Joint-Relation_Transformer_for_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.04808)
TMA- Temporal Motion Aggregation for Event-based Optical Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_TMA_Temporal_Motion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11629)
Building a Winning Team- Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach | [link](https://openaccess.thecvf.com/content/ICCV2023/html/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/B_Building_a_Winning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02429)
Plausible Uncertainties for Human Pose Regression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bramlage_Plausible_Uncertainties_for_ICCV_2023_supplemental.pdf)
DiffIR- Efficient Diffusion Model for Image Restoration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_DiffIR_Efficient_Diffusion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09472)
Simple Baselines for Interactive Video Retrieval with Questions and Answers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Simple_Baselines_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10402)
Going Denser with Open-Vocabulary Part Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.11173)
OCHID-Fi- Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.pdf)
Reconstructing Interacting Hands with Interaction Prior from Monocular Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zuo_Reconstructing_Interacting_Hands_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14082)
Towards Realistic Evaluation of Industrial Continual Learning Scenarios with an Emphasis on Energy Consumption and Computational Footprint | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chavan_Towards_Realistic_Evaluation_ICCV_2023_supplemental.pdf)
How Much Temporal Long-Term Context is Needed for Action Segmentation- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bahrami_How_Much_Temporal_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11358)
3D VR Sketch Guided 3D Shape Prototyping and Exploration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.10830)
MDCS- More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_MDCS_More_Diverse_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09922)
Similarity Min-Max- Zero-Shot Day-Night Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_Similarity_Min-Max_Zero-Shot_ICCV_2023_supplemental.pdf)
Dark Side Augmentation- Generating Diverse Night Examples for Metric Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mohwald_Dark_Side_Augmentation_ICCV_2023_supplemental.pdf)
LVOS- A Benchmark for Long-term Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_LVOS_A_Benchmark_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10181)
CHAMPAGNE- Learning Real-world Conversation from Large-Scale Web Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_CHAMPAGNE_Learning_Real-world_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09713)
DeformToon3D- Deformable Neural Radiance Fields for 3D Toonification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_DeformToon3D_Deformable_Neural_ICCV_2023_supplemental.zip)
Empowering Low-Light Image Enhancer through Customized Learnable Priors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Empowering_Low-Light_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01958)
Guiding Image Captioning Models Toward More Specific Captions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kornblith_Guiding_Image_Captioning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16686)
Towards Effective Instance Discrimination Contrastive Loss for Unsupervised Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf)
FrozenRecon- Pose-free 3D Scene Reconstruction with Frozen Depth Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_FrozenRecon_Pose-free_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05733)
Affective Image Filter- Reflecting Emotions from Text to Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_supplemental.pdf)
Content-Aware Local GAN for Photo-Realistic Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Content-Aware_Local_GAN_ICCV_2023_supplemental.pdf)
Structure-Aware Surface Reconstruction via Primitive Assembly | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.pdf)
FineDance- A Fine-grained Choreography Dataset for 3D Full Body Dance Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_FineDance_A_Fine-grained_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.03741)
Improving Online Lane Graph Extraction by Object-Lane Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.10947)
Video Background Music Generation- Dataset, Method and Evaluation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2211.11248)
Markov Game Video Augmentation for Action Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Aziere_Markov_Game_Video_ICCV_2023_supplemental.pdf)
RegFormer- An Efficient Projection-Aware Transformer Network for Large-Scale Point Cloud Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_RegFormer_An_Efficient_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.12384)
Graphics2RAW- Mapping Computer Graphics Images to Sensor RAW Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Seo_Graphics2RAW_Mapping_Computer_ICCV_2023_supplemental.pdf)
VAD- Vectorized Scene Representation for Efficient Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.12077)
Batch-based Model Registration for Fast 3D Sherd Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Batch-based_Model_Registration_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.06897)
HiFace- High-Fidelity 3D Face Reconstruction by Learning Static and Dynamic Details | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chai_HiFace_High-Fidelity_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11225)
Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.05986)
Algebraically Rigorous Quaternion Framework for the Neural Network Pose Estimation Problem | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.pdf)
CVSformer- Cross-View Synthesis Transformer for Semantic Scene Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_CVSformer_Cross-View_Synthesis_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07938)
UrbanGIRAFFE- Representing Urban Scenes as Compositional Generative Neural Feature Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_UrbanGIRAFFE_Representing_Urban_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.14167)
Active Neural Mapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Active_Neural_Mapping_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Active_Neural_Mapping_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.16246)
RecRecNet- Rectangling Rectified Wide-Angle Images by Thin-Plate Spline Model and DoF-based Curriculum Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liao_RecRecNet_Rectangling_Rectified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.01661)
Learning Versatile 3D Shape Generation with Improved Auto-regressive Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_Learning_Versatile_3D_ICCV_2023_supplemental.pdf)
DETA- Denoised Task Adaptation for Few-Shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.06315)
Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Delattre_Robust_Frame-to-Frame_Camera_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.08588)
Bayesian Prompt Learning for Image-Language Model Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Derakhshani_Bayesian_Prompt_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.02390)
DiLiGenT-Pi- Photometric Stereo for Planar Surfaces with Rich Details - Benchmark Dataset and Beyond | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_DiLiGenT-Pi_Photometric_Stereo_ICCV_2023_supplemental.pdf)
Accurate and Fast Compressed Video Captioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.12867)
Visible-Infrared Person Re-Identification via Semantic Alignment and Affinity Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Visible-Infrared_Person_Re-Identification_ICCV_2023_supplemental.pdf)
DG3D- Generating High Quality 3D Textured Shapes by Learning to Discriminate Multi-Modal Diffusion-Renderings | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zuo_DG3D_Generating_High_ICCV_2023_supplemental.zip)
VLSlice- Interactive Vision-and-Language Slice Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Slyman_VLSlice_Interactive_Vision-and-Language_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.06703)
Learning to Ground Instructional Articles in Videos through Narrations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mavroudi_Learning_to_Ground_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.03802)
MAMo- Leveraging Memory and Attention for Monocular Video Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yasarla_MAMo_Leveraging_Memory_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14336)
HDG-ODE- A Hierarchical Continuous-Time Model for Human Pose Forecasting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.pdf)
Self-supervised Monocular Underwater Depth Recovery, Image Restoration, and a Real-sea Video Dataset | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Varghese_Self-supervised_Monocular_Underwater_ICCV_2023_supplemental.pdf)
Geometrized Transformer for Self-Supervised Homography Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Geometrized_Transformer_for_ICCV_2023_supplemental.pdf)
TiDy-PSFs- Computational Imaging with Time-Averaged Dynamic Point-Spread-Functions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shah_TiDy-PSFs_Computational_Imaging_ICCV_2023_supplemental.pdf)
Learning Fine-Grained Features for Pixel-Wise Video Correspondences | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Learning_Fine-Grained_Features_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03040)
FS-DETR- Few-Shot DEtection TRansformer with Prompting and without Re-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bulat_FS-DETR_Few-Shot_DEtection_ICCV_2023_supplemental.pdf)
Learning to Learn- How to Continuously Teach Humans and Machines | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Singh_Learning_to_Learn_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.15470)
A 5-Point Minimal Solver for Event Camera Relative Motion Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.pdf)
TM2D- Bimodality Driven 3D Dance Generation via Music-Text Integration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gong_TM2D_Bimodality_Driven_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.02419)
Bootstrap Motion Forecasting With Self-Consistent Constraints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Bootstrap_Motion_Forecasting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05859)
CDAC- Cross-domain Attention Consistency in Transformer for Domain Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_CDAC_Cross-domain_Attention_ICCV_2023_supplemental.pdf)
Confidence-based Visual Dispersal for Few-shot Unsupervised Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_supplemental.pdf)
Event-Guided Procedure Planning from Instructional Videos with Text Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Event-Guided_Procedure_Planning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08885)
Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Flaborea_Multimodal_Motion_Conditioned_ICCV_2023_supplemental.pdf)
CDFSL-V- Cross-Domain Few-Shot Learning for Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_ICCV_2023_supplemental.pdf)
Towards Viewpoint Robustness in Birds Eye View Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Klinghoffer_Towards_Viewpoint_Robustness_ICCV_2023_supplemental.pdf)
What Can a Cook in Italy Teach a Mechanic in India- Action Recognition Generalisation Over Scenarios and Locations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Plizzari_What_Can_a_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.08713)
EMDB- The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kaufmann_EMDB_The_Electromagnetic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16894)
Weakly-Supervised Action Segmentation and Unseen Error Detection in Anomalous Instructional Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ghoddoosian_Weakly-Supervised_Action_Segmentation_ICCV_2023_supplemental.zip)
Mesh2Tex- Generating Mesh Textures from Image Queries | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bokhovkin_Mesh2Tex_Generating_Mesh_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.05868)
Deep Feature Deblurring Diffusion for Detecting Out-of-Distribution Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Deep_Feature_Deblurring_ICCV_2023_supplemental.pdf)
Introducing Language Guidance in Prompt-based Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15827)
Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yi_Invariant_Training_2D-3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09694)
EigenPlaces- Training Viewpoint Robust Models for Visual Place Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Berton_EigenPlaces_Training_Viewpoint_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10832)
CIRI- Curricular Inactivation for Residue-aware One-shot Video Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_CIRI_Curricular_Inactivation_ICCV_2023_supplemental.zip)
RSFNet- A White-Box Image Retouching Approach using Region-Specific Color Filters | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ouyang_RSFNet_A_White-Box_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.08682)
Tem-Adapter- Adapting Image-Text Pretraining for Video Question Answer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_supplemental.pdf)
Unleashing the Potential of Spiking Neural Networks with Dynamic Confidence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Unleashing_the_Potential_ICCV_2023_supplemental.pdf)
TeD-SPAD- Temporal Distinctiveness for Self-Supervised Privacy-Preservation for Video Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fioresi_TeD-SPAD_Temporal_Distinctiveness_ICCV_2023_supplemental.zip)
HiTeA- Hierarchical Temporal-Aware Video-Language Pre-training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_HiTeA_Hierarchical_Temporal-Aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.14546)
VAPCNet- Viewpoint-Aware 3D Point Cloud Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.pdf)
AutoSynth- Learning to Generate 3D Training Data for Object Point Cloud Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.11170)
Self-supervised Learning of Implicit Shape Representation with Dense Correspondence for Deformable Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Self-supervised_Learning_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12590)
Scaling Data Generation in Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Scaling_Data_Generation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15644)
Dual Learning with Dynamic Knowledge Distillation for Partially Relevant Video Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Dual_Learning_with_ICCV_2023_supplemental.pdf)
Disposable Transfer Learning for Selective Source Task Unlearning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Koh_Disposable_Transfer_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09971)
Grounding 3D Object Affordance from 2D Interactions in Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Grounding_3D_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10437)
Tube-Link- A Flexible Cross Tube Framework for Universal Video Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Tube-Link_A_Flexible_ICCV_2023_supplemental.pdf)
Hybrid Spectral Denoising Transformer with Guided Attention | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lai_Hybrid_Spectral_Denoising_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09040)
HiVLP- Hierarchical Interactive Video-Language Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_HiVLP_Hierarchical_Interactive_ICCV_2023_supplemental.pdf)
Learning Concordant Attention via Target-aware Alignment for Visible-Infrared Person Re-identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.pdf)
Masked Motion Predictors are Strong 3D Action Representation Learners | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.07092)
RIGID- Recurrent GAN Inversion and Editing of Real Face Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06097)
CSDA- Learning Category-Scale Joint Feature for Domain Adaptive Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_supplemental.pdf)
Single Image Defocus Deblurring via Implicit Neural Inverse Kernels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Quan_Single_Image_Defocus_ICCV_2023_supplemental.pdf)
AvatarCraft- Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_AvatarCraft_Transforming_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17606)
Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Why_Is_Prompt_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11978)
Unified Pre-Training with Pseudo Texts for Text-To-Image Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Unified_Pre-Training_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01420)
Traj-MAE- Masked Autoencoders for Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Traj-MAE_Masked_Autoencoders_ICCV_2023_supplemental.pdf)
UniFusion- Unified Multi-View Fusion Transformer for Spatial-Temporal Representation in Birds-Eye-View | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qin_UniFusion_Unified_Multi-View_ICCV_2023_supplemental.zip)
Sample-adaptive Augmentation for Point Cloud Recognition Against Real-world Corruptions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Sample-adaptive_Augmentation_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10431)
Modality Unifying Network for Visible-Infrared Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Modality_Unifying_Network_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.06262)
Taming Contrast Maximization for Learning Sequential, Low-latency, Event-based Optical Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Paredes-Valles_Taming_Contrast_Maximization_ICCV_2023_supplemental.pdf)
CASSPR- Cross Attention Single Scan Place Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_CASSPR_Cross_Attention_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.12542)
DDFM- Denoising Diffusion Model for Multi-Modality Image Fusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_DDFM_Denoising_Diffusion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.06840)
A Unified Continual Learning Framework with General Parameter-Efficient Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10070)
Hierarchical Generation of Human-Object Interactions with Diffusion Probabilistic Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf)
Learning Data-Driven Vector-Quantized Degradation Model for Animation Video Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tuo_Learning_Data-Driven_Vector-Quantized_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09826)
Calibrating Panoramic Depth Estimation for Practical Localization and Mapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14005)
DiffDis- Empowering Generative Diffusion Model with Cross-Modal Discrimination Capability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_DiffDis_Empowering_Generative_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09306)
View Consistent Purification for Accurate Cross-View Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_View_Consistent_Purification_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08110)
Efficient Video Action Detection with Token Dropout and Context Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Efficient_Video_Action_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.08451)
Explicit Motion Disentangling for Efficient Optical Flow Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.pdf)
From Chaos Comes Order- Ordering Event Representations for Object Recognition and Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zubic_From_Chaos_Comes_ICCV_2023_supplemental.pdf)
Identity-Consistent Aggregation for Video Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.07737)
Relightify- Relightable 3D Faces from a Single Image via Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Papantoniou_Relightify_Relightable_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.06077)
Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Leveraging_Spatio-Temporal_Dependency_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04761)
Camera-Driven Representation Learning for Unsupervised Domain Adaptive Person Re-identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Camera-Driven_Representation_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11901)
Name Your Colour For the Task- Artificially Discover Colour Naming via Colour Quantisation Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Su_Name_Your_Colour_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.03434)
FSAR- Federated Skeleton-based Action Recognition with Adaptive Topology Structure and Knowledge Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_FSAR_Federated_Skeleton-based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.11046)
Video Adverse-Weather-Component Suppression Network via Weather Messenger and Adversarial Backpropagation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Video_Adverse-Weather-Component_Suppression_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.13700)
Part-Aware Transformer for Generalizable Person Re-identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.03322)
Blending-NeRF- Text-Driven Localized Editing in Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Blending-NeRF_Text-Driven_Localized_ICCV_2023_supplemental.pdf)
Panoramas from Photons | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jungerman_Panoramas_from_Photons_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.03811)
Global Adaptation Meets Local Generalization- Unsupervised Domain Adaptation for 3D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chai_Global_Adaptation_Meets_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.16456)
DeFormer- Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_DeFormer_Integrating_Transformers_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12594)
Cross-view Semantic Alignment for Livestreaming Product Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Cross-view_Semantic_Alignment_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04912)
Continuously Masked Transformer for Image Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_supplemental.pdf)
Vanishing Point Estimation in Uncalibrated Images with Prior Gravity Direction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pautrat_Vanishing_Point_Estimation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10694)
Learn TAROT with MENTOR- A Meta-Learned Self-Supervised Approach for Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pourkeshavarz_Learn_TAROT_with_ICCV_2023_supplemental.pdf)
MatrixVT- Efficient Multi-Camera to BEV Transformation for 3D Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2211.10593)
Local and Global Logit Adjustments for Long-Tailed Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.pdf)
Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Sensitivity-Aware_Visual_Parameter-Efficient_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08566)
Weakly-supervised 3D Pose Transfer with Keypoints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Weakly-supervised_3D_Pose_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13459)
On the Effectiveness of Spectral Discriminators for Perceptual Quality Improvement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_On_the_Effectiveness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12027)
Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11579)
RPEFlow- Multimodal Fusion of RGB-PointCloud-Event for Joint Optical Flow and Scene Flow Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wan_RPEFlow_Multimodal_Fusion_ICCV_2023_supplemental.pdf)
DyGait- Exploiting Dynamic Representations for High-performance Gait Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.14953)
Helping Hands- An Object-Aware Ego-Centric Video Recognition Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Helping_Hands_An_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07918)
SpinCam- High-Speed Imaging via a Rotating Point-Spread Function | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chan_SpinCam_High-Speed_Imaging_ICCV_2023_supplemental.zip)
GlueStick- Robust Image Matching by Sticking Points and Lines Together | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pautrat_GlueStick_Robust_Image_ICCV_2023_supplemental.pdf)
Computational 3D Imaging with Position Sensors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Klotz_Computational_3D_Imaging_ICCV_2023_supplemental.zip)
Towards Multi-Layered 3D Garments Animation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Towards_Multi-Layered_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.10418)
Learning Image Harmonization in the Linear Color Space | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.pdf)
Chasing Clouds- Differentiable Volumetric Rasterisation of Point Clouds as a Highly Efficient and Accurate Loss for Large-Scale Deformable 3D Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Heinrich_Chasing_Clouds_Differentiable_ICCV_2023_supplemental.pdf)
The Devil is in the Upsampling- Architectural Decisions Made Simpler for Denoising with Deep Image Prior | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_The_Devil_is_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11409)
Video Object Segmentation-aware Video Frame Interpolation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yoo_Video_Object_Segmentation-aware_ICCV_2023_supplemental.pdf)
Coherent Event Guided Low-Light Video Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Coherent_Event_Guided_ICCV_2023_supplemental.pdf)
FCCNs- Fully Complex-valued Convolutional Networks using Complex-valued Color Model and Loss Function | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yadav_FCCNs_Fully_Complex-valued_ICCV_2023_supplemental.pdf)
S-TREK- Sequential Translation and Rotation Equivariant Keypoints for Local Feature Extraction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Santellani_S-TREK_Sequential_Translation_ICCV_2023_supplemental.pdf)
E2NeRF- Event Enhanced Neural Radiance Fields from Blurry Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qi_E2NeRF_Event_Enhanced_ICCV_2023_supplemental.pdf)
EgoTV- Egocentric Task Verification from Natural Language Task Descriptions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hazra_EgoTV_Egocentric_Task_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.16975)
LMR- A Large-Scale Multi-Reference Dataset for Reference-Based Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_LMR_A_Large-Scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.04970)
Neural Implicit Surface Evolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Novello_Neural_Implicit_Surface_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2201.09636)
Distribution-Aligned Diffusion for Human Mesh Recovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Foo_Distribution-Aligned_Diffusion_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13369)
Diffuse3D- Wide-Angle 3D Photography via Bilateral Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Diffuse3D_Wide-Angle_3D_ICCV_2023_supplemental.zip)
Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Thoker_Tubelet-Contrastive_Self-Supervision_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11003)
Generalizing Event-Based Motion Deblurring in Real-World Scenarios | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Generalizing_Event-Based_Motion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05932)
RCA-NOC- Relative Contrastive Alignment for Novel Object Captioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.pdf)
What Can Simple Arithmetic Operations Do for Temporal Modeling- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_What_Can_Simple_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08908)
Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Pixel_Adaptive_Deep_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10820)
Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bai_Dynamic_PlenOctree_for_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.15333)
Scene Matters- Model-based Deep Video Compression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.04557)
A Good Student is Cooperative and Reliable- CNN-Transformer Collaborative Learning for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_A_Good_Student_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12574)
Fan-Beam Binarization Difference Projection (FB-BDP)- A Novel Local Object Descriptor for Fine-Grained Leaf Image Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.pdf)
InterDiff- Generating 3D Human-Object Interactions with Physics-Informed Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_InterDiff_Generating_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.16905)
IST-Net- Prior-Free Category-Level Pose Estimation with Implicit Space Transformation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_IST-Net_Prior-Free_Category-Level_ICCV_2023_supplemental.pdf)
Curvature-Aware Training for Coordinate Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Saratchandran_Curvature-Aware_Training_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.08552)
Learning Rain Location Prior for Nighttime Deraining | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Learning_Rain_Location_ICCV_2023_supplemental.pdf)
FBLNet- FeedBack Loop Network for Driver Attention Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2212.02096)
Video Anomaly Detection via Sequentially Learning Multiple Pretext Tasks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_supplemental.pdf)
SlaBins- Fisheye Depth Estimation using Slanted Bins on Road Environments | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_SlaBins_Fisheye_Depth_ICCV_2023_supplemental.pdf)
March in Chat- Interactive Prompting for Remote Embodied Referring Expression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qiao_March_in_Chat_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10141)
Efficient Unified Demosaicing for Bayer and Non-Bayer Patterned Image Sensors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Efficient_Unified_Demosaicing_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10667)
Spatially-Adaptive Feature Modulation for Efficient Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Spatially-Adaptive_Feature_Modulation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.13800)
Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Unsupervised_Image_Denoising_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06776)
Self-supervised Image Denoising with Downsampled Invariance Loss and Conditional Blind-Spot Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jang_Self-supervised_Image_Denoising_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09507)
Generative Action Description Prompts for Skeleton-based Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_Generative_Action_Description_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.05318)
Transparent Shape from a Single View Polarization Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06331)
DriveAdapter- Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jia_DriveAdapter_Breaking_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00398)
General Planar Motion from a Pair of 3D Correspondences | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dibene_General_Planar_Motion_ICCV_2023_supplemental.pdf)
Single Depth-image 3D Reflection Symmetry and Shape Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Single_Depth-image_3D_ICCV_2023_supplemental.pdf)
Downscaled Representation Matters- Improving Image Rescaling with Collaborative Downscaled Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Downscaled_Representation_Matters_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10643)
Attention Discriminant Sampling for Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_Attention_Discriminant_Sampling_ICCV_2023_supplemental.pdf)
IHNet- Iterative Hierarchical Network Guided by High-Resolution Estimated Information for Scene Flow Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.pdf)
SimNP- Learning Self-Similarity Priors Between Neural Points | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wewer_SimNP_Learning_Self-Similarity_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03809)
Beyond the Limitation of Monocular 3D Detector via Knowledge Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.pdf)
Temporal-Coded Spiking Neural Networks with Dynamic Firing Threshold- Learning with Event-Driven Backpropagation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.pdf)
NeO 360- Neural Fields for Sparse View Synthesis of Outdoor Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Irshad_NeO_360_Neural_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12967)
UnLoc- A Unified Framework for Video Localization Tasks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.11062)
Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Maeda_Fast_Inference_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08824)
Adaptive Spiral Layers for Efficient 3D Representation Learning on Meshes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Babiloni_Adaptive_Spiral_Layers_ICCV_2023_supplemental.pdf)
Convex Decomposition of Indoor Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Vavilala_Convex_Decomposition_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.04246)
Toward Unsupervised Realistic Visual Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Toward_Unsupervised_Realistic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05068)
Video OWL-ViT- Temporally-consistent Open-world Localization in Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Heigold_Video_OWL-ViT_Temporally-consistent_ICCV_2023_supplemental.zip)
Physics-Driven Turbulence Image Restoration with Stochastic Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.10603)
Enhancing Non-line-of-sight Imaging via Learnable Inverse Kernel and Attention Mechanisms | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.pdf)
DECO- Dense Estimation of 3D Human-Scene Contact In The Wild | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tripathi_DECO_Dense_Estimation_ICCV_2023_supplemental.pdf)
PlaneRecTR- Unified Query Learning for 3D Plane Recovery from a Single View | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_PlaneRecTR_Unified_Query_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13756)
EigenTrajectory- Low-Rank Descriptors for Multi-Modal Trajectory Forecasting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.09306)
Video-FocalNets- Spatio-Temporal Focal Modulation for Video Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.pdf)
Hidden Biases of End-to-End Driving Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jaeger_Hidden_Biases_of_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.07957)
PIDRo- Parallel Isomeric Attention with Dynamic Routing for Text-Video Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guan_PIDRo_Parallel_Isomeric_ICCV_2023_supplemental.pdf)
RFD-ECNet- Extreme Underwater Image Compression with Reference to Feature Dictionary | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_RFD-ECNet_Extreme_Underwater_ICCV_2023_supplemental.pdf)
High-Resolution Document Shadow Removal via A Large-Scale Real-World Dataset and A Frequency-Aware Shadow Erasing Net | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_High-Resolution_Document_Shadow_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14221)
SILT- Shadow-Aware Iterative Label Tuning for Learning to Detect Shadows from Noisy Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_SILT_Shadow-Aware_Iterative_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12064)
Implicit Autoencoder for Point-Cloud Self-Supervised Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yan_Implicit_Autoencoder_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.00785)
Speech4Mesh- Speech-Assisted Monocular 3D Facial Reconstruction for Speech-Driven 3D Facial Animation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Speech4Mesh_Speech-Assisted_Monocular_ICCV_2023_supplemental.zip)
Generalizing Neural Human Fitting to Unseen Poses With Articulated SE(3) Equivariance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Generalizing_Neural_Human_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10528)
Learning from Noisy Pseudo Labels for Semi-Supervised Temporal Action Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_supplemental.pdf)
Activate and Reject- Towards Safe Domain Generalization under Category Shift | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.pdf)
Dynamic Mesh Recovery from Partial Point Cloud Sequence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jang_Dynamic_Mesh_Recovery_ICCV_2023_supplemental.zip)
Neural Deformable Models for 3D Bi-Ventricular Heart Shape Reconstruction and Modeling from 2D Sparse Cardiac Magnetic Resonance Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Neural_Deformable_Models_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07693)
Nonrigid Object Contact Estimation With Regional Unwrapping Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.14074)
Semi-supervised Semantics-guided Adversarial Training for Robust Trajectory Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiao_Semi-supervised_Semantics-guided_Adversarial_ICCV_2023_supplemental.pdf)
Linear-Covariance Loss for End-to-End Learning of 6D Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Linear-Covariance_Loss_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11516)
RLSAC- Reinforcement Learning Enhanced Sample Consensus for End-to-End Robust Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nie_RLSAC_Reinforcement_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05318)
Multi-Frequency Representation Enhancement with Privilege Information for Video Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Multi-Frequency_Representation_Enhancement_ICCV_2023_supplemental.pdf)
Self-supervised Pre-training for Mirror Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.pdf)
GlowGAN- Unsupervised Learning of HDR Images from LDR Images in the Wild | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_GlowGAN_Unsupervised_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.12352)
Dual Pseudo-Labels Interactive Self-Training for Semi-Supervised Visible-Infrared Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Dual_Pseudo-Labels_Interactive_ICCV_2023_supplemental.pdf)
Learned Compressive Representations for Single-Photon 3D Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gutierrez-Barragan_Learned_Compressive_Representations_ICCV_2023_supplemental.zip)
Alignment-free HDR Deghosting with Semantics Consistent Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tel_Alignment-free_HDR_Deghosting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.18135)
Multi3DRefer- Grounding Text Description to Multiple 3D Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Multi3DRefer_Grounding_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05251)
Examining Autoexposure for Challenging Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tedla_Examining_Autoexposure_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04542)
Improved Visual Fine-tuning with Natural Language Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Improved_Visual_Fine-tuning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01489)
Person Re-Identification without Identification via Event anonymization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.04402)
Self-Feedback DETR for Temporal Action Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Self-Feedback_DETR_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10570)
UMC- A Unified Bandwidth-efficient and Multi-resolution based Collaborative Perception Framework | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_UMC_A_Unified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.12400)
Viewing Graph Solvability in Practice | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.pdf)
SATR- Zero-Shot Semantic Segmentation of 3D Shapes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Abdelreheem_SATR_Zero-Shot_Semantic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.04909)
Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10016)
Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Probabilistic_Human_Mesh_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.06024)
SceneRF- Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_SceneRF_Self-Supervised_Monocular_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.02501)
INT2- Interactive Trajectory Prediction at Intersections | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.pdf)
MapPrior- Birds-Eye View Map Layout Estimation with Generative Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_MapPrior_Birds-Eye_View_ICCV_2023_supplemental.zip)
Conditional Cross Attention Network for Multi-Space Embedding without Entanglement in Only a SINGLE Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Conditional_Cross_Attention_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13254)
MB-TaylorFormer- Multi-Branch Efficient Transformer Expanded by Taylor Formula for Image Dehazing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_ICCV_2023_supplemental.pdf)
FocalFormer3D- Focusing on Hard Instance for 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04556)
TEMPO- Efficient Multi-View Pose Estimation, Tracking, and Forecasting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choudhury_TEMPO_Efficient_Multi-View_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07910)
DiffPose- SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.16687)
IntentQA- Context-aware Video Intent Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_IntentQA_Context-aware_Video_ICCV_2023_supplemental.pdf)
Robust Monocular Depth Estimation under Challenging Conditions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gasperini_Robust_Monocular_Depth_Estimation_under_Challenging_Conditions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Robust_Monocular_Depth_Estimation_under_Challenging_Conditions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gasperini_Robust_Monocular_Depth_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09711)
Parametric Depth Based Feature Representation Learning for Object Detection and Segmentation in Birds-Eye View | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.pdf)
Global Features are All You Need for Image Retrieval and Reranking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Global_Features_are_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06954)
DPF-Net- Combining Explicit Shape Priors in Deformable Primitive Field for Unsupervised Structural Reconstruction of 3D Objects | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shuai_DPF-Net_Combining_Explicit_ICCV_2023_supplemental.pdf)
CORE- Co-planarity Regularized Monocular Geometry Estimation with Weak Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_supplemental.pdf)
A Sentence Speaks a Thousand Images- Domain Generalization through Distilling CLIP with Language Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.pdf)
Yes, we CANN- Constrained Approximate Nearest Neighbors for Local Feature-Based Visual Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Aiger_Yes_we_CANN_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.09012)
Multi-Object Navigation with Dynamically Learned Neural Implicit Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Marza_Multi-Object_Navigation_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.05129)
NPC- Neural Point Characters from Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Su_NPC_Neural_Point_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02013)
CrossLoc3D- Aerial-Ground Cross-Source 3D Place Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17778)
Recursive Video Lane Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jin_Recursive_Video_Lane_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.11106)
Unsupervised Self-Driving Attention Prediction via Uncertainty Mining and Knowledge Embedding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.09706)
DLGSANet- Lightweight Dynamic Local and Global Self-Attention Networks for Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DLGSANet_Lightweight_Dynamic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.02031)
Black-Box Unsupervised Domain Adaptation with Bi-Directional Atkinson-Shiffrin Memory | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Black-Box_Unsupervised_Domain_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13236)
Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qing_Disentangling_Spatial_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07911)
Coarse-to-Fine- Learning Compact Discriminative Representation for Single-Stage Image Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.pdf)
Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints Voting for Robust 6D Object Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Deep_Fusion_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05438)
BT^2- Backward-compatible Training with Basis Transformation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_BT2_Backward-compatible_Training_ICCV_2023_supplemental.pdf)
ViperGPT- Visual Inference via Python Execution for Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Suris_ViperGPT_Visual_Inference_ICCV_2023_supplemental.pdf)
Fine-grained Visible Watermark Removal | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.pdf)
GridMM- Grid Memory Map for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_GridMM_Grid_Memory_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12907)
LAC - Latent Action Composition for Skeleton-based Action Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_LAC_-_Latent_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14500)
Learning Vision-and-Language Navigation from YouTube Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Learning_Vision-and-Language_Navigation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11984)
Uncertainty-aware State Space Transformer for Egocentric 3D Hand Trajectory Forecasting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bao_Uncertainty-aware_State_Space_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08243)
Pretrained Language Models as Visual Planners for Human Assistance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Patel_Pretrained_Language_Models_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09179)
Dynamic Point Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Prokudin_Dynamic_Point_Fields_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02626)
Lip2Vec- Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Djilali_Lip2Vec_Efficient_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06112)
Spectral Graphormer- Spectral Graph-Based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tse_Spectral_Graphormer_Spectral_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11015)
Recovering a Molecules 3D Dynamics from Liquid-phase Electron Microscopy Movies | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_supplemental.pdf)
SOCS- Semantically-Aware Object Coordinate Space for Category-Level 6D Object Pose Estimation under Large Shape Variations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wan_SOCS_Semantically-Aware_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10346)
NeRF-LOAM- Neural Implicit Representation for Large-Scale Incremental LiDAR Odometry and Mapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deng_NeRF-LOAM_Neural_Implicit_ICCV_2023_supplemental.zip)
OmniLabel- A Challenging Benchmark for Language-Based Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Schulter_OmniLabel_A_Challenging_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11463)
Divide&Classify- Fine-Grained Classification for City-Wide Visual Geo-Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Trivigno_DivideClassify_Fine-Grained_Classification_ICCV_2023_supplemental.pdf)
3D Semantic Subspace Traverser- Empowering 3D Generative Model with Shape Editing Capability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_3D_Semantic_Subspace_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14051)
Text2Room- Extracting Textured 3D Meshes from 2D Text-to-Image Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hollein_Text2Room_Extracting_Textured_ICCV_2023_supplemental.pdf)
On the Robustness of Normalizing Flows for Inverse Problems in Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_On_the_Robustness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04319)
DistillBEV- Boosting Multi-Camera 3D Object Detection with Cross-Modal Knowledge Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_DistillBEV_Boosting_Multi-Camera_ICCV_2023_supplemental.pdf)
PoseFix- Correcting 3D Human Poses with Natural Language | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Delmas_PoseFix_Correcting_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.08480)
TAPIR- Tracking Any Point with Per-Frame Initialization and Temporal Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.08637)
SwinLSTM- Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09891)
DEDRIFT- Robust Similarity Search under Content Drift | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.02752)
Audio-Enhanced Text-to-Video Retrieval using Text-Conditioned Feature Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12964)
Prior-guided Source-free Domain Adaptation for Human Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Raychaudhuri_Prior-guided_Source-free_Domain_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13954)
Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Auxiliary_Tasks_Benefit_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08942)
Measuring Asymmetric Gradient Discrepancy in Parallel Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_supplemental.pdf)
HyperDiffusion- Generating Implicit Neural Fields with Weight-Space Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Erkoc_HyperDiffusion_Generating_Implicit_ICCV_2023_supplemental.pdf)
Retinexformer- One-stage Retinex-based Transformer for Low-light Image Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.06705)
Linear Spaces of Meanings- Compositional Structures in Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Trager_Linear_Spaces_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.14383)
Tracking by Natural Language Specification with Long Short-term Context Decoupling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf)
Pyramid Dual Domain Injection Network for Pan-sharpening | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.pdf)
NeSS-ST- Detecting Good and Stable Keypoints with a Neural Stability Score and the Shi-Tomasi detector | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pakulev_NeSS-ST_Detecting_Good_ICCV_2023_supplemental.pdf)
Video Action Segmentation via Contextually Refined Temporal Keypoints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Video_Action_Segmentation_ICCV_2023_supplemental.pdf)
Shatter and Gather- Learning Referring Image Segmentation with Text Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15512)
Two-in-One Depth- Bridging the Gap Between Monocular and Binocular Self-Supervised Depth Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Two-in-One_Depth_Bridging_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.00933)
Rethinking Pose Estimation in Crowds- Overcoming the Detection Information Bottleneck and Ambiguity | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Rethinking_Pose_Estimation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.07879)
Social Diffusion- Long-term Multiple Human Motion Anticipation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tanke_Social_Diffusion_Long-term_ICCV_2023_supplemental.pdf)
Synchronize Feature Extracting and Matching- A Single Branch Framework for 3D Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Synchronize_Feature_Extracting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12549)
Leveraging Intrinsic Properties for Non-Rigid Garment Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Leveraging_Intrinsic_Properties_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.09519)
P2C- Self-Supervised Point Cloud Completion from Single Partial Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cui_P2C_Self-Supervised_Point_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14726)
A Game of Bundle Adjustment - Learning Efficient Convergence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.pdf)
Learning Correction Filter via Degradation-Adaptive Regression for Blind Single Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Learning_Correction_Filter_ICCV_2023_supplemental.pdf)
SINC- Spatial Composition of 3D Human Motions for Simultaneous Action Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10417)
MV-DeepSDF- Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_MV-DeepSDF_Implicit_Modeling_ICCV_2023_supplemental.pdf)
CHORD- Category-level Hand-held Object Reconstruction via Shape Deformation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_CHORD_Category-level_Hand-held_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10574)
Towards Universal LiDAR-Based 3D Object Detection by Multi-Domain Knowledge Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.pdf)
Towards High-Fidelity Text-Guided 3D Face Generation and Manipulation Using only Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Towards_High-Fidelity_Text-Guided_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.16758)
ENTL- Embodied Navigation Trajectory Learner | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kotar_ENTL_Embodied_Navigation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02639)
AGG-Net- Attention Guided Gated-Convolutional Network for Depth Image Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_supplemental.pdf)
Real-Time Neural Rasterization for Large Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Real-Time_Neural_Rasterization_ICCV_2023_supplemental.zip)
MixSpeech- Cross-Modality Self-Learning with Audio-Visual Stream Mixup for Visual Speech Translation and Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_MixSpeech_Cross-Modality_Self-Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05309)
Innovating Real Fisheye Image Correction with Dual Diffusion Architecture | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Innovating_Real_Fisheye_ICCV_2023_supplemental.pdf)
Global Perception Based Autoregressive Neural Processes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.pdf)
VQA Therapy- Exploring Answer Differences by Visually Grounding Answers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_VQA_Therapy_Exploring_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11662)
Energy-based Self-Training and Normalization for Unsupervised Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Herath_Energy-based_Self-Training_and_ICCV_2023_supplemental.pdf)
Collaborative Tracking Learning for Frame-Rate-Insensitive Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.05911)
Prompt-aligned Gradient for Prompt Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Prompt-aligned_Gradient_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.14865)
Aperture Diffraction for Compact Snapshot Spectral Imaging | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lv_Aperture_Diffraction_for_ICCV_2023_supplemental.pdf)
Diffusion Action Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Diffusion_Action_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17959)
Scalable Video Object Segmentation with Simplified Framework | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Scalable_Video_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09903)
Rehearsal-Free Domain Continual Face Anti-Spoofing- Generalize More and Forget Less | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_Rehearsal-Free_Domain_Continual_ICCV_2023_supplemental.pdf)
Towards General Low-Light Raw Noise Synthesis and Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Towards_General_Low-Light_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16508)
Beyond the Pixel- a Photometrically Calibrated HDR Dataset for Luminance and Color Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bolduc_Beyond_the_Pixel_ICCV_2023_supplemental.pdf)
Prototypical Mixing and Retrieval-Based Refinement for Label Noise-Resistant Image Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Prototypical_Mixing_and_ICCV_2023_supplemental.pdf)
AccFlow- Backward Accumulation for Long-Range Optical Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_AccFlow_Backward_Accumulation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13133)
Contrastive Model Adaptation for Cross-Condition Robustness in Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_supplemental.pdf)
Creative Birds- Self-Supervised Single-View 3D Style Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Creative_Birds_Self-Supervised_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14127)
Boosting Novel Category Discovery Over Domains with Soft Contrastive Learning and All in One Classifier | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11262)
Search for or Navigate to- Dual Adaptive Thinking for Object Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2208.00553)
OmniZoomer- Learning to Move and Zoom in on Sphere at High-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_OmniZoomer_Learning_to_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.08114)
Knowing Where to Focus- Event-aware Transformer for Video Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jang_Knowing_Where_to_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06947)
Movement Enhancement toward Multi-Scale Video Feature Representation for Temporal Action Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.pdf)
Single Image Deblurring with Row-dependent Blur Magnitude | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Single_Image_Deblurring_ICCV_2023_supplemental.pdf)
Deep Active Contours for Real-time 6-DoF Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.pdf)
Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Improving_3D_Imaging_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08440)
Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Moon_Online_Class_Incremental_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09303)
SCANet- Scene Complexity Aware Network for Weakly-Supervised Video Moment Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yoon_SCANet_Scene_Complexity_ICCV_2023_supplemental.pdf)
Neural Interactive Keypoint Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Neural_Interactive_Keypoint_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10174)
Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kan_Knowledge-Aware_Prompt_Tuning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11186)
Leveraging Inpainting for Single-Image Shadow Removal | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2302.05361)
Accurate 3D Face Reconstruction with Facial Component Tokens | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Accurate_3D_Face_ICCV_2023_supplemental.zip)
Implicit Neural Representation for Cooperative Low-light Image Enhancement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Implicit_Neural_Representation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11722)
ReLeaPS - Reinforcement Learning-based Illumination Planning for Generalized Photometric Stereo | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chan_ReLeaPS__Reinforcement_ICCV_2023_supplemental.zip)
Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Learning_Foresightful_Dense_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.11057)
CiteTracker- Correlating Image and Text for Visual Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_CiteTracker_Correlating_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11322)
PHRIT- Parametric Hand Representation with Implicit Template | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_PHRIT_Parametric_Hand_ICCV_2023_supplemental.pdf)
BEVPlace- Learning LiDAR-based Place Recognition using Birds Eye View Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_BEVPlace_Learning_LiDAR-based_ICCV_2023_supplemental.pdf)
TrajPAC- Towards Robustness Verification of Pedestrian Trajectory Prediction Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_TrajPAC_Towards_Robustness_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.05985)
Learning Point Cloud Completion without Complete Point Clouds- A Pose-Aware Approach | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Learning_Point_Cloud_ICCV_2023_supplemental.pdf)
Frequency Guidance Matters in Few-Shot Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_supplemental.pdf)
Spherical Space Feature Decomposition for Guided Depth Map Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08942)
Tiled Multiplane Images for Practical 3D Photography | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.14291)
HTML- Hybrid Temporal-scale Multimodal Learning Framework for Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_HTML_Hybrid_Temporal-scale_ICCV_2023_supplemental.pdf)
PointDC- Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-Modal Distillation and Super-Voxel Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_PointDC_Unsupervised_Semantic_ICCV_2023_supplemental.pdf)
MV-Map- Offboard HD-Map Generation with Multi-view Consistency | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_MV-Map_Offboard_HD-Map_ICCV_2023_supplemental.pdf)
Multi-view Self-supervised Disentanglement for General Image Denoising | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Multi-view_Self-supervised_Disentanglement_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05049)
SHERF- Generalizable Human NeRF from a Single Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_SHERF_Generalizable_Human_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.12791)
MVPSNet- Fast Generalizable Multi-view Photometric Stereo | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_MVPSNet_Fast_Generalizable_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.11167)
Human from Blur- Human Pose Tracking from Blurry Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Human_from_Blur_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.17209)
Uni-3D- A Universal Model for Panoptic 3D Scene Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.pdf)
Full-Body Articulated Human-Object Interaction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Full-Body_Articulated_Human-Object_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.10621)
FeatureNeRF- Learning Generalizable NeRFs by Distilling Foundation Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_FeatureNeRF_Learning_Generalizable_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.12786)
SRFormer- Permuted Self-Attention for Single Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.09735)
Deep Homography Mixture for Single Image Rolling Shutter Correction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.pdf)
Audio-Visual Glance Network for Efficient Video Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nugroho_Audio-Visual_Glance_Network_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.09322)
STEPs- Self-Supervised Key Step Extraction and Localization from Unlabeled Procedural Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shah_STEPs_Self-Supervised_Key_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.00794)
Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular Videos in the Wild | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Towards_Robust_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.08644)
Clustering based Point Cloud Representation Learning for 3D Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Clustering_based_Point_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14605)
Forecast-MAE- Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Forecast-MAE_Self-supervised_Pre-training_ICCV_2023_supplemental.pdf)
Efficient Transformer-based 3D Object Detection with Dynamic Token Halting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Efficient_Transformer-based_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05078)
Video Task Decathlon- Unifying Image and Video Tasks in Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Video_Task_Decathlon_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04422)
PreSTU- Pre-Training for Scene-Text Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kil_PreSTU_Pre-Training_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2209.05534)
Towards Better Robustness against Common Corruptions for Unsupervised Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Towards_Better_Robustness_ICCV_2023_supplemental.pdf)
TALL- Thumbnail Layout for Deepfake Video Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.07494)
Bidirectional Alignment for Domain Adaptive Detection with Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_supplemental.pdf)
CAME- Contrastive Automated Model Evaluation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_CAME_Contrastive_Automated_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11111)
Order-preserving Consistency Regularization for Domain Adaptation and Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jing_Order-preserving_Consistency_Regularization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.13258)
Workie-Talkie- Accelerating Federated Learning by Overlapping Computing and Communications via Contrastive Regularization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Workie-Talkie_Accelerating_Federated_ICCV_2023_supplemental.pdf)
Late Stopping- Avoiding Confidently Learning from Mislabeled Examples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_Late_Stopping_Avoiding_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.13862)
Most Important Person-Guided Dual-Branch Cross-Patch Attention for Group Affect Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.pdf)
Achievement-Based Training Progress Balancing for Multi-Task Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yun_Achievement-Based_Training_Progress_ICCV_2023_supplemental.pdf)
Logic-induced Diagnostic Reasoning for Semi-supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12595)
NeRF-Det- Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_NeRF-Det_Learning_Geometry-Aware_ICCV_2023_supplemental.pdf)
Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.13929)
LPFF- A Portrait Dataset for Face Generators Across Large Poses | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_LPFF_A_Portrait_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14407)
Pseudo-label Alignment for Semi-supervised Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.05359)
MixBag- Bag-Level Data Augmentation for Learning from Label Proportions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Asanomi_MixBag_Bag-Level_Data_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08822)
Effective Real Image Editing with Accelerated Iterative Diffusion Inversion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Effective_Real_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04907)
UniFace- Unified Cross-Entropy Loss for Deep Face Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_UniFace_Unified_Cross-Entropy_ICCV_2023_supplemental.pdf)
Jumping through Local Minima- Quantization in the Loss Landscape of Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Frumkin_Jumping_through_Local_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10814)
ScatterNeRF- Seeing Through Fog with Physically-Based Inverse Neural Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ramazzina_ScatterNeRF_Seeing_Through_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.02103)
Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_Towards_Generic_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01246)
PARF- Primitive-Aware Radiance Fusion for Indoor Scene Novel View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ying_PARF_Primitive-Aware_Radiance_ICCV_2023_supplemental.zip)
DeePoint- Visual Pointing Recognition and Direction Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakamura_DeePoint_Visual_Pointing_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.06977)
Deformer- Dynamic Fusion Transformer for Robust Hand Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fu_Deformer_Dynamic_Fusion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.04991)
iDAG- Invariant DAG Searching for Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_iDAG_Invariant_DAG_ICCV_2023_supplemental.pdf)
Spacetime Surface Regularization for Neural Dynamic Scene Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choe_Spacetime_Surface_Regularization_ICCV_2023_supplemental.zip)
GasMono- Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_GasMono_Geometry-Aided_Self-Supervised_ICCV_2023_supplemental.pdf)
Audio-Visual Deception Detection- DOLOS Dataset and Parameter-Efficient Crossmodal Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Audio-Visual_Deception_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.12745)
Alleviating Catastrophic Forgetting of Incremental Object Detection via Within-Class and Between-Class Knowledge Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kang_Alleviating_Catastrophic_Forgetting_ICCV_2023_supplemental.pdf)
Revisiting the Parameter Efficiency of Adapters from the Perspective of Precision Redundancy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jie_Revisiting_the_Parameter_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16867)
EMQ- Evolving Training-free Proxies for Automated Mixed Precision Quantization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_EMQ_Evolving_Training-free_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10554)
Face Clustering via Graph Convolutional Networks with Confidence Edges | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.pdf)
Multimodal Garment Designer- Human-Centric Latent Diffusion Models for Fashion Image Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Baldrati_Multimodal_Garment_Designer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02051)
Time-to-Contact Map by Joint Estimation of Up-to-Scale Inverse Depth and Global Motion using a Single Event Camera | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nunes_Time-to-Contact_Map_by_ICCV_2023_supplemental.pdf)
A Benchmark for Chinese-English Scene Text Image Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_A_Benchmark_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.03262)
Replay- Multi-modal Multi-view Acted Videos for Casual Holography | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shapovalov_Replay_Multi-modal_Multi-view_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12067)
Affine-Consistent Transformer for Multi-Class Cell Nuclei Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Affine-Consistent_Transformer_for_ICCV_2023_supplemental.pdf)
Removing Anomalies as Noises for Industrial Defect Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.pdf)
GPGait- Generalized Pose-based Gait Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fu_GPGait_Generalized_Pose-based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05234)
Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Stable_and_Causal_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08321)
Semantic Attention Flow Fields for Monocular Dynamic Scene Decomposition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Semantic_Attention_Flow_ICCV_2023_supplemental.pdf)
A Fast Unified System for 3D Object Detection and Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Heitzinger_A_Fast_Unified_ICCV_2023_supplemental.pdf)
AIDE- A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for Assistive Driving Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_AIDE_A_Vision-Driven_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13933)
Self-Supervised Character-to-Character Distillation for Text Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2211.00288)
Domain Adaptive Few-Shot Open-Set Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12814)
Interactive Class-Agnostic Object Counting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Interactive_Class-Agnostic_Object_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.05277)
Estimator Meets Equilibrium Perspective- A Rectified Straight Through Estimator for Binary Neural Networks Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Estimator_Meets_Equilibrium_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06689)
MedKLIP- Medical Knowledge Enhanced Language-Image Pre-Training for X-ray Diagnosis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_MedKLIP_Medical_Knowledge_ICCV_2023_supplemental.pdf)
Automated Knowledge Distillation via Monte Carlo Tree Search | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Automated_Knowledge_Distillation_ICCV_2023_supplemental.pdf)
EmoTalk- Speech-Driven Emotional Disentanglement for 3D Face Animation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_EmoTalk_Speech-Driven_Emotional_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.11089)
Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Text-Conditioned_Sampling_Framework_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01515)
Inverse Problem Regularization with Hierarchical Variational Autoencoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Prost_Inverse_Problem_Regularization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11217)
Unpaired Multi-domain Attribute Translation of 3D Facial Shapes with a Square and Symmetric Geometric Map | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Unpaired_Multi-domain_Attribute_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13245)
Template Inversion Attack against Face Recognition Systems using 3D Face Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shahreza_Template_Inversion_Attack_ICCV_2023_supplemental.pdf)
ETran- Energy-Based Transferability Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gholami_ETran_Energy-Based_Transferability_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.02027)
Predict to Detect- Prediction-guided 3D Object Detection using Sequential Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Predict_to_Detect_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.08528)
IDiff-Face- Synthetic-based Face Recognition through Fizzy Identity-Conditioned Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.pdf)
Rethinking Multi-Contrast MRI Super-Resolution- Rectangle-Window Cross-Attention Transformer and Arbitrary-Scale Upsampling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.pdf)
Towards Open-Set Test-Time Adaptation Utilizing the Wisdom of Crowds in Entropy Minimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Towards_Open-Set_Test-Time_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06879)
Long-Range Grouping Transformer for Multi-View 3D Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08724)
DenseShift- Towards Accurate and Efficient Low-Bit Power-of-Two Quantization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DenseShift_Towards_Accurate_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.09708)
Efficient Computation Sharing for Multi-Task Visual Scene Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shoouri_Efficient_Computation_Sharing_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09663)
DDIT- Semantic Scene Completion via Deformable Deep Implicit Templates | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DDIT_Semantic_Scene_ICCV_2023_supplemental.pdf)
Attention Where It Matters- Rethinking Visual Document Understanding with Selective Region Concentration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01131)
3D Neural Embedding Likelihood- Probabilistic Inverse Graphics for Robust 6D Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_3D_Neural_Embedding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.03744)
SupFusion- Supervised LiDAR-Camera Fusion for 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qin_SupFusion_Supervised_LiDAR-Camera_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07084)
EMMN- Emotional Motion Memory Network for Audio-driven Emotional Talking Face Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tan_EMMN_Emotional_Motion_ICCV_2023_supplemental.zip)
Rethinking Vision Transformers for MobileNet Size and Speed | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Rethinking_Vision_Transformers_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.08059)
Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_Implicit_Identity_Representation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09906)
Chupa- Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Chupa_Carving_3D_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2305.11870)
Going Beyond Nouns With Vision & Language Models Using Synthetic Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cascante-Bonilla_Going_Beyond_Nouns_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17590)
Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Zero-Shot_Contrastive_Loss_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08622)
Identity-Seeking Self-Supervised Representation Learning for Generalizable Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dou_Identity-Seeking_Self-Supervised_Representation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.08887)
3D-Aware Generative Model for Improved Side-View Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jo_3D-Aware_Generative_Model_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.10388)
OxfordTVG-HIC- Can Machine Make Humorous Captions from Images- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_OxfordTVG-HIC_Can_Machine_ICCV_2023_supplemental.pdf)
EDAPS- Enhanced Domain-Adaptive Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Saha_EDAPS_Enhanced_Domain-Adaptive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.14291)
Scratch Each Others Back- Incomplete Multi-Modal Brain Tumor Segmentation via Category Aware Group Self-Support Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.pdf)
Agglomerative Transformer for Human-Object Interaction Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.08370)
Rethinking Fast Fourier Convolution in Image Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chu_Rethinking_Fast_Fourier_ICCV_2023_supplemental.pdf)
Learning Robust Representations with Information Bottleneck and Memory Network for RGB-D-based Gesture Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Learning_Robust_Representations_ICCV_2023_supplemental.pdf)
P1AC- Revisiting Absolute Pose From a Single Affine Correspondence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ventura_P1AC_Revisiting_Absolute_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.08790)
Lossy and Lossless (L2) Post-training Model Size Compression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Lossy_and_Lossless_ICCV_2023_supplemental.pdf)
C2ST- Cross-Modal Contextualized Sequence Transduction for Continuous Sign Language Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf)
ObjectFusion- Multi-modal 3D Object Detection with Object-Centric Fusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_ObjectFusion_Multi-modal_3D_ICCV_2023_supplemental.pdf)
Adaptive Calibrator Ensemble- Navigating Test Set Difficulty in Out-of-Distribution Scenarios | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zou_Adaptive_Calibrator_Ensemble_ICCV_2023_supplemental.pdf)
Contrastive Learning Relies More on Spatial Inductive Bias Than Supervised Learning- An Empirical Study | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhong_Contrastive_Learning_Relies_ICCV_2023_supplemental.pdf)
Randomized Quantization- A Generic Augmentation for Data Agnostic Self-supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Randomized_Quantization_A_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.08663)
Neural Radiance Field with LiDAR maps | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chang_Neural_Radiance_Field_ICCV_2023_supplemental.pdf)
AREA- Adaptive Reweighting via Effective Area for Long-Tailed Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_AREA_Adaptive_Reweighting_ICCV_2023_supplemental.pdf)
Learning Adaptive Neighborhoods for Graph Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Saha_Learning_Adaptive_Neighborhoods_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09065)
Make-It-3D- High-fidelity 3D Creation from A Single Image with Diffusion Prior | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Make-It-3D_High-fidelity_3D_ICCV_2023_supplemental.zip)
Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via Optimization Trajectory Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Taxonomy_Adaptive_Cross-Domain_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14709)
Ray Conditioning- Trading Photo-consistency for Photo-realism in Multi-view Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Ray_Conditioning_Trading_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.13681)
SCOB- Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_SCOB_Universal_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12382)
Domain Generalization of 3D Semantic Segmentation in Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sanchez_Domain_Generalization_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04245)
HaMuCo- Hand Pose Estimation via Multiview Collaborative Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_HaMuCo_Hand_Pose_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2302.00988)
Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Efficient_Model_Personalization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15367)
Knowledge Restore and Transfer for Multi-Label Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Knowledge_Restore_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.13334)
PanFlowNet- A Flow-Based Deep Network for Pan-Sharpening | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.07774)
Domain Generalization via Balancing Training Difficulty and Model Capability | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Domain_Generalization_via_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.00844)
CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_CLIP-Driven_Universal_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.00785)
Anchor Structure Regularization Induced Multi-view Subspace Clustering via Enhanced Tensor Rank Minimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Anchor_Structure_Regularization_ICCV_2023_supplemental.pdf)
MOSE- A New Dataset for Video Object Segmentation in Complex Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2302.01872)
BoMD- Bag of Multi-label Descriptors for Noisy Chest X-ray Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_BoMD_Bag_of_ICCV_2023_supplemental.pdf)
Q-Diffusion- Quantizing Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Q-Diffusion_Quantizing_Diffusion_ICCV_2023_supplemental.pdf)
Robustifying Token Attention for Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Robustifying_Token_Attention_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11126)
UniSeg- A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_UniSeg_A_Unified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05573)
Pixel-Wise Contrastive Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.00218)
Efficient Deep Space Filling Curve | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Efficient_Deep_Space_ICCV_2023_supplemental.pdf)
GlueGen- Plug and Play Multi-modal Encoders for X-to-image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qin_GlueGen_Plug_and_ICCV_2023_supplemental.pdf)
Ponder- Point Cloud Pre-training via Neural Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Ponder_Point_Cloud_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.00157)
L-DAWA- Layer-wise Divergence Aware Weight Aggregation in Federated Self-Supervised Visual Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rehman_L-DAWA_Layer-wise_Divergence_ICCV_2023_supplemental.pdf)
Controllable Guide-Space for Generalizable Face Forgery Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Controllable_Guide-Space_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14039)
Calibrating Uncertainty for Semi-Supervised Crowd Counting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/LI_Calibrating_Uncertainty_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09887)
Segmentation of Tubular Structures Using Iterative Training with Tailored Samples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.08727)
Surface Extraction from Neural Unsigned Distance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Surface_Extraction_from_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.08878)
CBA- Improving Online Continual Learning via Continual Bias Adaptor | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_CBA_Improving_Online_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06925)
Multi-view Spectral Polarization Propagation for Video Glass Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qiao_Multi-view_Spectral_Polarization_ICCV_2023_supplemental.zip)
DandelionNet- Domain Composition with Instance Adaptive Classification for Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_DandelionNet_Domain_Composition_ICCV_2023_supplemental.pdf)
PASTA- Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chattopadhyay_PASTA_Proportional_Amplitude_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.00979)
RANA- Relightable Articulated Neural Avatars | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Iqbal_RANA_Relightable_Articulated_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.03237)
MODA- Mapping-Once Audio-driven Portrait Animation with Dual Attentions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_MODA_Mapping-Once_Audio-driven_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.10008)
DIRE for Diffusion-Generated Image Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.09295)
Bring Clipart to Life | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Bring_Clipart_to_ICCV_2023_supplemental.pdf)
Noise2Info- Noisy Image to Information of Noise for Self-Supervised Image Denoising | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Noise2Info_Noisy_Image_ICCV_2023_supplemental.zip)
SynBody- Synthetic Dataset with Layered Human Models for 3D Human Perception and Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17368)
EP2P-Loc- End-to-End 3D Point to 2D Pixel Localization for Large-Scale Visual Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_EP2P-Loc_End-to-End_3D_ICCV_2023_supplemental.pdf)
Physics-Augmented Autoencoder for 3D Skeleton-Based Gait Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Physics-Augmented_Autoencoder_for_ICCV_2023_supplemental.pdf)
Regularized Primitive Graph Learning for Unified Vector Mapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Regularized_Primitive_Graph_ICCV_2023_supplemental.pdf)
FlipNeRF- Flipped Reflection Rays for Few-shot Novel View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Seo_FlipNeRF_Flipped_Reflection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.17723)
MolGrapher- Graph-based Visual Recognition of Chemical Structures | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Morin_MolGrapher_Graph-based_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12234)
SAMPLING- Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_SAMPLING_Scene-adaptive_Hierarchical_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.06323)
PointOdyssey- A Large-Scale Synthetic Dataset for Long-Term Point Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_PointOdyssey_A_Large-Scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15055)
LNPL-MIL- Learning from Noisy Pseudo Labels for Promoting Multiple Instance Learning in Whole Slide Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_LNPL-MIL_Learning_from_ICCV_2023_supplemental.pdf)
Few-Shot Dataset Distillation via Translative Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_supplemental.pdf)
TinyCLIP- CLIP Distillation via Affinity Mimicking and Weight Inheritance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_TinyCLIP_CLIP_Distillation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12314)
Democratising 2D Sketch to 3D Shape Retrieval Through Pivoting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chowdhury_Democratising_2D_Sketch_ICCV_2023_supplemental.pdf)
KECOR- Kernel Coding Rate Maximization for Active 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_KECOR_Kernel_Coding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07942)
Locating Noise is Halfway Denoising for Semi-Supervised Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Locating_Noise_is_ICCV_2023_supplemental.pdf)
SSB- Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_SSB_Simple_but_ICCV_2023_supplemental.pdf)
Cross-Modal Orthogonal High-Rank Augmentation for RGB-Event Transformer-Trackers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Cross-Modal_Orthogonal_High-Rank_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.04129)
How to Boost Face Recognition with StyleGAN- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sevastopolskiy_How_to_Boost_ICCV_2023_supplemental.zip)
Text2Tex- Text-driven Texture Synthesis via Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Text2Tex_Text-driven_Texture_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.11396)
MUVA- A New Large-Scale Benchmark for Multi-View Amodal Instance Segmentation in the Shopping Scenario | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_MUVA_A_New_ICCV_2023_supplemental.pdf)
SeiT- Storage-Efficient Vision Training with Tokens Using 1% of Pixel Storage | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_SeiT_Storage-Efficient_Vision_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11114)
CLIP2Point- Transfer CLIP to Point Cloud Classification with Image-Depth Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_CLIP2Point_Transfer_CLIP_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.01055)
Parametric Classification for Generalized Category Discovery- A Baseline Study | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wen_Parametric_Classification_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11727)
Denoising Diffusion Autoencoders are Unified Self-supervised Learners | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_Denoising_Diffusion_Autoencoders_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09769)
Cross-view Topology Based Consistent and Complementary Information for Deep Multi-view Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.pdf)
Distribution-Consistent Modal Recovering for Incomplete Multimodal Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Distribution-Consistent_Modal_Recovering_ICCV_2023_supplemental.pdf)
ContactGen- Generative Contact Modeling for Grasp Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_ContactGen_Generative_Contact_ICCV_2023_supplemental.pdf)
Ego-Humans- An Ego-Centric 3D Multi-Human Benchmark | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_supplemental.pdf)
Reference-guided Controllable Inpainting of Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mirzaei_Reference-guided_Controllable_Inpainting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09677)
Diffusion-Guided Reconstruction of Everyday Hand-Object Interaction Clips | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Diffusion-Guided_Reconstruction_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05663)
DVGaze- Dual-View Gaze Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10310)
Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Efficient_Joint_Optimization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10438)
Exploring the Sim2Real Gap Using Digital Twins | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sudhakar_Exploring_the_Sim2Real_ICCV_2023_supplemental.pdf)
Re-PolyWorld - A Graph Neural Network for Polygonal Scene Parsing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zorzi_RePolyWorld_-_A_ICCV_2023_supplemental.pdf)
Video State-Changing Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Video_State-Changing_Object_ICCV_2023_supplemental.zip)
MonoNeRF- Learning a Generalizable Dynamic Radiance Field from Monocular Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tian_MonoNeRF_Learning_a_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.13056)
PG-RCNN- Semantic Surface Point Generation for 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Koo_PG-RCNN_Semantic_Surface_ICCV_2023_supplemental.pdf)
Representation Uncertainty in Self-Supervised Learning as Variational Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakamura_Representation_Uncertainty_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11437)
Bridging Vision and Language Encoders- Parameter-Efficient Tuning for Referring Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Bridging_Vision_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11545)
ATT3D- Amortized Text-to-3D Object Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lorraine_ATT3D_Amortized_Text-to-3D_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.07349)
Virtual Try-On with Pose-Garment Keypoints Guided Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Virtual_Try-On_with_ICCV_2023_supplemental.pdf)
Learning by Sorting- Self-supervised Learning with Group Ordering Constraints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shvetsova_Learning_by_Sorting_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.02009)
Cross Modal Transformer- Towards Fast and Robust 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.01283)
MoTIF- Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_MoTIF_Learning_Motion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07988)
CRN- Camera Radar Net for Accurate, Robust, Efficient 3D Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_CRN_Camera_Radar_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.00670)
GaPro- Box-Supervised 3D Point Cloud Instance Segmentation Using Gaussian Processes as Pseudo Labelers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ngo_GaPro_Box-Supervised_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13251)
Get the Best of Both Worlds- Improving Accuracy and Transferability by Grassmann Class Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Get_the_Best_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.01547)
ObjectSDF++- Improved Object-Compositional Neural Implicit Surfaces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_ObjectSDF_Improved_Object-Compositional_ICCV_2023_supplemental.pdf)
Towards Unsupervised Domain Generalization for Face Anti-Spoofing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Towards_Unsupervised_Domain_ICCV_2023_supplemental.pdf)
MotionDeltaCNN- Sparse CNN Inference of Frame Differences in Moving Camera Videos with Spherical Buffers and Padded Convolutions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Parger_MotionDeltaCNN_Sparse_CNN_ICCV_2023_supplemental.zip)
General Image-to-Image Translation with One-Shot Image Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_General_Image-to-Image_Translation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14352)
ASM- Adaptive Skinning Model for High-Quality 3D Face Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_ASM_Adaptive_Skinning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09423)
CAFA- Class-Aware Feature Alignment for Test-Time Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jung_CAFA_Class-Aware_Feature_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.00205)
Learning Clothing and Pose Invariant 3D Shape Representation for Long-Term Person Re-Identification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10658)
Agile Modeling- From Concept to Classifier in Minutes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Stretcu_Agile_Modeling_From_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.12948)
FACET- Fairness in Computer Vision Evaluation Benchmark | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gustafson_FACET_Fairness_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.00035)
Prototypes-oriented Transductive Few-shot Learning with Conditional Transport | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.03047)
SparseFusion- Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.14340)
DetermiNet- A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_DetermiNet_A_Large-Scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03483)
RICO- Regularizing the Unobservable for Indoor Compositional Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_RICO_Regularizing_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08605)
CO-PILOT- Dynamic Top-Down Point Cloud with Conditional Neighborhood Aggregation for Multi-Gigapixel Histopathology Image Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakhli_CO-PILOT_Dynamic_Top-Down_ICCV_2023_supplemental.pdf)
Troubleshooting Ethnic Quality Bias with Curriculum Domain Adaptation for Face Image Quality Assessment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.pdf)
CLR- Channel-wise Lightweight Reprogramming for Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_CLR_Channel-wise_Lightweight_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11386)
IOMatch- Simplifying Open-Set Semi-Supervised Learning with Joint Inliers and Outliers Utilization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_IOMatch_Simplifying_Open-Set_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13168)
Hierarchical Point-based Active Learning for Semi-supervised Point Cloud Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Hierarchical_Point-based_Active_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11166)
Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Le_Quality-Agnostic_Deepfake_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.05911)
Object-Centric Multiple Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.00233)
Point-TTA- Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hatem_Point-TTA_Test-Time_Adaptation_ICCV_2023_supplemental.pdf)
uSplit- Image Decomposition for Fluorescence Microscopy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ashesh_uSplit_Image_Decomposition_ICCV_2023_supplemental.pdf)
LightGlue- Local Feature Matching at Light Speed | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lindenberger_LightGlue_Local_Feature_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.13643)
Masked Autoencoders are Efficient Class Incremental Learners | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.12510)
Towards Semi-supervised Learning with Non-random Missing Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Duan_Towards_Semi-supervised_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08872)
NeRFrac- Neural Radiance Fields through Refractive Surface | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhan_NeRFrac_Neural_Radiance_ICCV_2023_supplemental.zip)
LivelySpeaker- Towards Semantic-Aware Co-Speech Gesture Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhi_LivelySpeaker_Towards_Semantic-Aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.09294)
Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.06628)
Personalized Image Generation for Color Vision Deficiency Population | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Personalized_Image_Generation_ICCV_2023_supplemental.pdf)
EGC- Image Generation and Classification via a Diffusion Energy-Based Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.02012)
Joint Metrics Matter- A Better Standard for Trajectory Forecasting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Weng_Joint_Metrics_Matter_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.06292)
Test Time Adaptation for Blind Image Quality Assessment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Roy_Test_Time_Adaptation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14735)
GeT- Generative Target Structure Debiasing for Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10205)
Point-SLAM- Dense Neural Point Cloud-based SLAM | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sandstrom_Point-SLAM_Dense_Neural_ICCV_2023_supplemental.zip)
TrajectoryFormer- 3D Object Tracking Transformer with Predictive Trajectory Hypotheses | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_TrajectoryFormer_3D_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.05888)
See More and Know More- Zero-shot Point Cloud Segmentation via Multi-modal Visual Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10782)
Editable Image Geometric Abstraction via Neural Primitive Assembly | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.pdf)
Homeomorphism Alignment for Unsupervised Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Homeomorphism_Alignment_for_ICCV_2023_supplemental.pdf)
EmoSet- A Large-scale Visual Emotion Dataset with Rich Attributes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_EmoSet_A_Large-scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07961)
Class-relation Knowledge Distillation for Novel Class Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gu_Class-relation_Knowledge_Distillation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09158)
Data-Free Class-Incremental Hand Gesture Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Aich_Data-Free_Class-Incremental_Hand_ICCV_2023_supplemental.pdf)
Mixed Neural Voxels for Fast Multi-view Video Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Mixed_Neural_Voxels_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.00190)
Harvard Glaucoma Detection and Progression- A Multimodal Multitask Dataset and Generalization-Reinforced Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_Harvard_Glaucoma_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13411)
Tracking Everything Everywhere All at Once | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Tracking_Everything_Everywhere_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.05422)
CauSSL- Causality-inspired Semi-supervised Learning for Medical Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_supplemental.pdf)
ChartReader- A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.02173)
Neural LiDAR Fields for Novel View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Neural_LiDAR_Fields_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.01643)
Understanding 3D Object Interaction from a Single Image | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.09664)
Cross-Modal Translation and Alignment for Survival Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Cross-Modal_Translation_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12855)
Chaotic World- A Large and Challenging Benchmark for Human Behavior Understanding in Chaotic Events | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ong_Chaotic_World_A_ICCV_2023_supplemental.pdf)
Active Stereo Without Pattern Projector | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bartolomei_Active_Stereo_Without_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.12315)
Towards Instance-adaptive Inference for Federated Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.06051)
Online Clustered Codebook | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Online_Clustered_Codebook_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15139)
Robo3D- Towards Robust and Reliable 3D Perception against Corruptions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.17597)
Gradient-based Sampling for Class Imbalanced Semi-supervised Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Gradient-based_Sampling_for_ICCV_2023_supplemental.pdf)
SLCA- Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_SLCA_Slow_Learner_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.05118)
Implicit Temporal Modeling with Learnable Alignment for Video Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tu_Implicit_Temporal_Modeling_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10465)
Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_Pixel-Aligned_Recurrent_Queries_ICCV_2023_supplemental.pdf)
TiDAL- Learning Training Dynamics for Active Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kye_TiDAL_Learning_Training_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2210.06788)
DiffPose- Multi-hypothesis Human Pose Estimation using Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Holmquist_DiffPose_Multi-hypothesis_Human_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.16487)
AesPA-Net- Aesthetic Pattern-Aware Style Transfer Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hong_AesPA-Net_Aesthetic_Pattern-Aware_ICCV_2023_supplemental.pdf)
Self-Ordering Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Self-Ordering_Point_Clouds_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.00961)
Continual Segment- Towards a Single, Unified and Non-forgetting Continual Segmentation Model of 143 Whole-body Organs in CT Scans | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Continual_Segment_Towards_ICCV_2023_supplemental.pdf)
Enhancing Modality-Agnostic Representations via Meta-Learning for Brain Tumor Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Konwer_Enhancing_Modality-Agnostic_Representations_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.04308)
DNA-Rendering- A Diverse Neural Actor Repository for High-Fidelity Human-Centric Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_DNA-Rendering_A_Diverse_ICCV_2023_supplemental.zip)
A step towards understanding why classification helps regression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pintea_A_step_towards_understanding_why_classification_helps_regression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pintea_A_step_towards_understanding_why_classification_helps_regression_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pintea_A_step_towards_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10603)
CTP-Towards Vision-Language Continual Pretraining via Compatible Momentum Contrast and Topology Preservation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_CTPTowards_Vision-Language_Continual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07146)
FLIP- Cross-domain Face Anti-spoofing with Language Guidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Srivatsan_FLIP_Cross-domain_Face_ICCV_2023_supplemental.pdf)
Distribution Shift Matters for Knowledge Distillation with Webly Collected Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Distribution_Shift_Matters_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11469)
Gram-based Attentive Neural Ordinary Differential Equations Network for Video Nystagmography Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.pdf)
Pluralistic Aging Diffusion Autoencoder | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Pluralistic_Aging_Diffusion_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11086)
TIFA- Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_TIFA_Accurate_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11897)
Towards Models that Can See and Read | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ganz_Towards_Models_that_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.07389)
Query Refinement Transformer for 3D Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf)
3DHumanGAN- 3D-Aware Human Image Generation with 3D Pose Mapping | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_3DHumanGAN_3D-Aware_Human_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.07378)
Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sanyal_Domain-Specificity_Inducing_Transformers_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14023)
Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gan_Efficient_Emotional_Adaptation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.04946)
Object-aware Gaze Target Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tonini_Object-aware_Gaze_Target_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09662)
VADER- Video Alignment Differencing and Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Black_VADER_Video_Alignment_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.13193)
HiLo- Exploiting High Low Frequency Relations for Unbiased Panoptic Scene Graph Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_HiLo_Exploiting_High_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15994)
Chop & Learn- Recognizing and Generating Object-State Compositions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Saini_Chop__Learn_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.14339)
Automatic Animation of Hair Blowing in Still Portrait Photos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.14207)
4D Panoptic Segmentation as Invariant and Equivariant Field Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_4D_Panoptic_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15651)
Zip-NeRF- Anti-Aliased Grid-Based Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_ICCV_2023_supplemental.pdf)
Neural-PBIR Reconstruction of Shape, Material, and Illumination | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Neural-PBIR_Reconstruction_of_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.13445)
Fg-T2M- Fine-Grained Text-Driven Human Motion Generation via Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Fg-T2M_Fine-Grained_Text-Driven_ICCV_2023_supplemental.pdf)
BlindHarmony- Blind Harmonization for MR Images via Flow Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jeong_BlindHarmony_Blind_Harmonization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.10732)
Efficient LiDAR Point Cloud Oversegmentation Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hui_Efficient_LiDAR_Point_ICCV_2023_supplemental.pdf)
Few-Shot Video Classification via Representation Fusion and Promotion Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.pdf)
Hallucination Improves the Performance of Unsupervised Visual Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Hallucination_Improves_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12168)
S3IM- Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_S3IM_Stochastic_Structural_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07032)
Membrane Potential Batch Normalization for Spiking Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.08359)
Enhancing Sample Utilization through Sample Adaptive Augmentation in Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.03598)
Imitator- Personalized Speech-driven 3D Facial Animation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Thambiraja_Imitator_Personalized_Speech-driven_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.00023)
Seeing Beyond the Patch- Scale-Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery based on Reinforcement Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.pdf)
WALDO- Future Video Synthesis Using Object Layer Decomposition and Parametric Flow Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Le_Moing_WALDO_Future_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.14308)
Contactless Pulse Estimation Leveraging Pseudo Labels and Self-Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.pdf)
Instruct-NeRF2NeRF- Editing 3D Scenes with Instructions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Haque_Instruct-NeRF2NeRF_Editing_3D_ICCV_2023_supplemental.pdf)
Multi-Task Learning with Knowledge Distillation for Dense Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf)
ICD-Face- Intra-class Compactness Distillation for Face Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.pdf)
MRM- Masked Relation Modeling for Medical Image Pre-Training with Genetics | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_MRM_Masked_Relation_ICCV_2023_supplemental.pdf)
TaskExpert- Dynamically Assembling Multi-Task Representations with Memorial Mixture-of-Experts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_TaskExpert_Dynamically_Assembling_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15324)
Meta OOD Learning For Continuously Adaptive OOD Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Meta_OOD_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.11705)
Few-shot Continual Infomax Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gu_Few-shot_Continual_Infomax_ICCV_2023_supplemental.pdf)
A Parse-Then-Place Approach for Generating Graphic Layouts from Textual Descriptions | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_A_Parse-Then-Place_Approach_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12700)
A Retrospect to Multi-prompt Learning across Vision and Language | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_A_Retrospect_to_ICCV_2023_supplemental.pdf)
Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Label_Shift_Adapter_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08810)
Dataset Quantization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Dataset_Quantization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Dataset_Quantization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Dataset_Quantization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10524)
Overcoming Forgetting Catastrophe in Quantization-Aware Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Overcoming_Forgetting_Catastrophe_ICCV_2023_supplemental.pdf)
Efficient Video Prediction via Sparsely Conditioned Flow Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Davtyan_Efficient_Video_Prediction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.14575)
Surface Normal Clustering for Implicit Representation of Manhattan Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Popovic_Surface_Normal_Clustering_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.01331)
Adaptive Similarity Bootstrapping for Self-Distillation Based Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lebailly_Adaptive_Similarity_Bootstrapping_ICCV_2023_supplemental.pdf)
Generalized Differentiable RANSAC | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2212.13185)
ResQ- Residual Quantization for Video Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Abati_ResQ_Residual_Quantization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09511)
MHCN- A Hyperbolic Neural Network Model for Multi-view Hierarchical Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_MHCN_A_Hyperbolic_ICCV_2023_supplemental.pdf)
FineRecon- Depth-aware Feed-forward Network for Detailed 3D Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Stier_FineRecon_Depth-aware_Feed-forward_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.01480)
Zenseact Open Dataset- A Large-Scale and Diverse Multimodal Dataset for Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Alibeigi_Zenseact_Open_Dataset_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.02008)
Weakly Supervised Referring Image Segmentation with Intra-Chunk and Inter-Chunk Consistency | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Weakly_Supervised_Referring_ICCV_2023_supplemental.pdf)
Parameterized Cost Volume for Stereo Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_supplemental.pdf)
SAFE- Sensitivity-Aware Features for Out-of-Distribution Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wilson_SAFE_Sensitivity-Aware_Features_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.13930)
DREAM- Efficient Dataset Distillation by Representative Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_DREAM_Efficient_Dataset_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.14416)
Focus on Your Target- A Dual Teacher-Student Framework for Domain-Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09083)
Enhanced Meta Label Correction for Coping with Label Corruption | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Taraday_Enhanced_Meta_Label_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.12961)
Will Large-scale Generative Models Corrupt Future Datasets- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hataya_Will_Large-scale_Generative_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.08095)
SHACIRA- Scalable HAsh-grid Compression for Implicit Neural Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Girish_SHACIRA_Scalable_HAsh-grid_ICCV_2023_supplemental.pdf)
A Low-Shot Object Counting Network With Iterative Prototype Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.pdf)
MEGA- Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sadoughi_MEGA_Multimodal_Alignment_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11185)
DiffRate - Differentiable Compression Rate for Efficient Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.17997)
Multi-Modal Continual Test-Time Adaptation for 3D Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Multi-Modal_Continual_Test-Time_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.10457)
UMIFormer- Mining the Correlations between Similar Tokens for Multi-View 3D Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_UMIFormer_Mining_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.13987)
Improved Knowledge Transfer for Semi-Supervised Domain Adaptation via Trico Training Strategy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ngo_Improved_Knowledge_Transfer_ICCV_2023_supplemental.pdf)
InterFormer- Real-time Interactive Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_InterFormer_Real-time_Interactive_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.02942)
Online Prototype Learning for Online Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Online_Prototype_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.00301)
Robust e-NeRF- NeRF from Sparse & Noisy Events under Non-Uniform Motion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Low_Robust_e-NeRF_NeRF_ICCV_2023_supplemental.pdf)
ActorsNeRF- Animatable Few-shot Human Rendering with Generalizable NeRFs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mu_ActorsNeRF_Animatable_Few-shot_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.14401)
Multiple Planar Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.pdf)
Label-Guided Knowledge Distillation for Continual Semantic Segmentation on 2D Images and 3D Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Label-Guided_Knowledge_Distillation_ICCV_2023_supplemental.pdf)
PRANC- Pseudo RAndom Networks for Compacting Deep Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nooralinejad_PRANC_Pseudo_RAndom_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.08464)
Clutter Detection and Removal in 3D Scenes with View-Consistent Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Clutter_Detection_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.03763)
Hierarchical Spatio-Temporal Representation Learning for Gait Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Hierarchical_Spatio-Temporal_Representation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09856)
Weakly Supervised Learning of Semantic Correspondence through Cascaded Online Correspondence Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Weakly_Supervised_Learning_ICCV_2023_supplemental.pdf)
NaviNeRF- NeRF-based 3D Representation Disentanglement by Latent Semantic Navigation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_NaviNeRF_NeRF-based_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11342)
Image-Free Classifier Injection for Zero-Shot Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Christensen_Image-Free_Classifier_Injection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10599)
Semantically Structured Image Compression via Irregular Group-Based Decoupling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Semantically_Structured_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.02586)
Self-Organizing Pathway Expansion for Non-Exemplar Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.pdf)
Preserving Tumor Volumes for Unsupervised Medical Image Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Preserving_Tumor_Volumes_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.10153)
Unsupervised Accuracy Estimation of Deep Visual Models using Domain-Adaptive Adversarial Perturbation without Source Samples | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Unsupervised_Accuracy_Estimation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10062)
MATE- Masked Autoencoders are Online 3D Test-Time Learners | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mirza_MATE_Masked_Autoencoders_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11432)
Two Birds, One Stone- A Unified Framework for Joint Learning of Image and Video Style Transfers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gu_Two_Birds_One_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.11335)
Task-Oriented Multi-Modal Mutual Leaning for Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.17169)
NeMF- Inverse Volume Rendering with Neural Microflake Field | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2304.00782)
MasaCtrl- Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_MasaCtrl_Tuning-Free_Mutual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.08465)
Understanding Hessian Alignment for Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hemati_Understanding_Hessian_Alignment_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11778)
Preserve Your Own Correlation- A Noise Prior for Video Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_Preserve_Your_Own_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.10474)
Revisiting Vision Transformer from the View of Path Ensemble | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chang_Revisiting_Vision_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06548)
Tetra-NeRF- Representing Neural Radiance Fields Using Tetrahedra | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kulhanek_Tetra-NeRF_Representing_Neural_ICCV_2023_supplemental.pdf)
Ablating Concepts in Text-to-Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.13516)
MapFormer- Boosting Change Detection by Using Pre-change Information | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bernhard_MapFormer_Boosting_Change_ICCV_2023_supplemental.pdf)
Masked Diffusion Transformer is a Strong Image Synthesizer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Masked_Diffusion_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.14389)
LightDepth- Single-View Depth Self-Supervision from Illumination Decline | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rodriguez-Puigvert_LightDepth_Single-View_Depth_ICCV_2023_supplemental.zip)
Referring Image Segmentation Using Text Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Referring_Image_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14575)
Once Detected, Never Lost- Surpassing Human Performance in Offline LiDAR based 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Once_Detected_Never_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.12315)
Eventful Transformers- Leveraging Temporal Redundancy in Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dutson_Eventful_Transformers_Leveraging_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13494)
Robust Referring Video Object Segmentation with Cyclic Structural Consensus | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.pdf)
Building Bridge Across the Time- Disruption and Restoration of Murals In the Wild | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Building_Bridge_Across_ICCV_2023_supplemental.pdf)
Neural Haircut- Prior-Guided Strand-Based Hair Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sklyarova_Neural_Haircut_Prior-Guided_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.05872)
DG-Recon- Depth-Guided Neural 3D Scene Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ju_DG-Recon_Depth-Guided_Neural_ICCV_2023_supplemental.pdf)
The Stable Signature- Rooting Watermarks in Latent Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fernandez_The_Stable_Signature_ICCV_2023_supplemental.pdf)
Seal-3D- Interactive Pixel-Level Editing for Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Seal-3D_Interactive_Pixel-Level_ICCV_2023_supplemental.zip)
NeRF-MS- Neural Radiance Fields with Multi-Sequence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_NeRF-MS_Neural_Radiance_ICCV_2023_supplemental.pdf)
Diffusion Model as Representation Learner | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10916)
Nerfbusters- Removing Ghostly Artifacts from Casually Captured NeRFs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Warburg_Nerfbusters_Removing_Ghostly_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10532)
Document Understanding Dataset and Evaluation (DUDE) | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Van_Landeghem_Document_Understanding_Dataset_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.08455)
Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04952)
Simple and Effective Out-of-Distribution Detection via Cosine-based Softmax Loss | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Noh_Simple_and_Effective_ICCV_2023_supplemental.pdf)
CFCG- Semi-Supervised Semantic Segmentation via Cross-Fusion and Contour Guidance Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_CFCG_Semi-Supervised_Semantic_ICCV_2023_supplemental.pdf)
SLAN- Self-Locator Aided Network for Vision-Language Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.pdf)
Anomaly Detection using Score-based Perturbation Resilience | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shin_Anomaly_Detection_using_ICCV_2023_supplemental.pdf)
Generating Visual Scenes from Touch | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Generating_Visual_Scenes_ICCV_2023_supplemental.pdf)
SatlasPretrain- A Large-Scale Dataset for Remote Sensing Image Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bastani_SatlasPretrain_A_Large-Scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.15660)
DReg-NeRF- Deep Registration for Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_DReg-NeRF_Deep_Registration_ICCV_2023_supplemental.pdf)
All in Tokens- Unifying Output Space of Visual Tasks via Soft Token | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2301.02229)
LDL- Line Distance Functions for Panoramic Localization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_LDL_Line_Distance_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.13989)
TransTIC- Transferring Transformer-based Image Compression from Human Perception to Machine Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.05085)
CHORUS - Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_CHORUS__Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12288)
ViLLA- Fine-Grained Vision-Language Representation Learning from Real-World Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Varma_ViLLA_Fine-Grained_Vision-Language_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11194)
Towards Unifying Medical Vision-and-Language Pre-Training via Soft Prompts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2302.08958)
A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deng_A_Large-scale_Study_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13505)
HoloFusion- Towards Photo-realistic 3D Generative Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Karnewar_HoloFusion_Towards_Photo-realistic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14244)
Improving Continuous Sign Language Recognition with Cross-Lingual Signs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Improving_Continuous_Sign_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10809)
TransIFF- An Instance-Level Feature Fusion Framework for Vehicle-Infrastructure Cooperative 3D Detection with Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_TransIFF_An_Instance-Level_ICCV_2023_supplemental.pdf)
Masked Retraining Teacher-Student Framework for Domain Adaptive Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Masked_Retraining_Teacher-Student_ICCV_2023_supplemental.pdf)
Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ding_Prune_Spatio-temporal_Tokens_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04549)
Growing a Brain with Sparsity-Inducing Generation for Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf)
Cross-Ray Neural Radiance Fields for Novel-View Synthesis from Unconstrained Image Collections | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Cross-Ray_Neural_Radiance_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2307.08093)
SPACE- Speech-driven Portrait Animation with Controllable Expression | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gururani_SPACE_Speech-driven_Portrait_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2211.09809)
End-to-end 3D Tracking with Decoupled Queries | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.pdf)
Deformable Model-Driven Neural Rendering for High-Fidelity 3D Reconstruction of Human Heads Under Low-View Settings | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Deformable_Model-Driven_Neural_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.13855)
Density-invariant Features for Distant Point Cloud Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Density-invariant_Features_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09788)
UniverSeg- Universal Medical Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Butoi_UniverSeg_Universal_Medical_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06131)
Diffusion Models as Masked Autoencoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Diffusion_Models_as_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.03283)
One-Shot Recognition of Any Material Anywhere Using Contrastive Learning with Physics-Based Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Drehwald_One-Shot_Recognition_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.00648)
HairCLIPv2- Unifying Hair Editing via Proxy Feature Blending | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_HairCLIPv2_Unifying_Hair_ICCV_2023_supplemental.pdf)
DocTr- Document Transformer for Structured Information Extraction in Documents | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liao_DocTr_Document_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07929)
Role-Aware Interaction Generation from Textual Description | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tanaka_Role-Aware_Interaction_Generation_ICCV_2023_supplemental.pdf)
Continual Learning for Personalized Co-speech Gesture Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ahuja_Continual_Learning_for_ICCV_2023_supplemental.pdf)
DreamTeacher- Pretraining Image Backbones with Deep Generative Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DreamTeacher_Pretraining_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07487)
Decomposition-Based Variational Network for Multi-Contrast MRI Super-Resolution and Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lei_Decomposition-Based_Variational_Network_ICCV_2023_supplemental.pdf)
Semi-supervised Speech-driven 3D Facial Animation via Cross-modal Encoding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Semi-supervised_Speech-driven_3D_ICCV_2023_supplemental.pdf)
WaveNeRF- Wavelet-based Generalizable Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_WaveNeRF_Wavelet-based_Generalizable_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04826)
LoCUS- Learning Multiscale 3D-consistent Features from Posed Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kloepfer_LoCUS_Learning_Multiscale_ICCV_2023_supplemental.zip)
Foreground Object Search by Distilling Composite Image Feature | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Foreground_Object_Search_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04990)
Generalized Few-Shot Point Cloud Segmentation via Geometric Words | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Generalized_Few-Shot_Point_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.11222)
STEERER- Resolving Scale Variations for Counting and Localization via Selective Inheritance Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_STEERER_Resolving_Scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10468)
Geometric Viewpoint Learning with Hyper-Rays and Harmonics Encoding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Min_Geometric_Viewpoint_Learning_ICCV_2023_supplemental.pdf)
C2F2NeUS- Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2306.10003)
Fast Full-frame Video Stabilization with Iterative Optimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Fast_Full-frame_Video_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12774)
Learning Semi-supervised Gaussian Mixture Models for Generalized Category Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Learning_Semi-supervised_Gaussian_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2305.06144)
Rethinking Point Cloud Registration as Masking and Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Rethinking_Point_Cloud_ICCV_2023_supplemental.pdf)
Human Part-wise 3D Motion Context Learning for Sign Language Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09305)
Remembering Normality- Memory-guided Knowledge Distillation for Unsupervised Anomaly Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gu_Remembering_Normality_Memory-guided_ICCV_2023_supplemental.pdf)
Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11025)
MAS- Towards Resource-Efficient Federated Multiple-Task Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhuang_MAS_Towards_Resource-Efficient_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11285)
Bridging Cross-task Protocol Inconsistency for Distillation in Dense Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14286)
Narrator- Towards Natural Control of Human-Scene Interaction Generation via Relationship Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xuan_Narrator_Towards_Natural_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09410)
Vision Relation Transformer for Unbiased Scene Graph Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sudhakaran_Vision_Relation_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09472)
Revisit PCA-based Technique for Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guan_Revisit_PCA-based_Technique_ICCV_2023_supplemental.pdf)
Visually-Prompted Language Model for Fine-Grained Scene Graph Generation in an Open World | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Visually-Prompted_Language_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13233)
FishNet- A Large-scale Dataset and Benchmark for Fish Recognition, Detection, and Functional Trait Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.pdf)
Masked Spatio-Temporal Structure Prediction for Self-supervised Learning on Point Cloud Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09245)
DreamPose- Fashion Video Synthesis with Stable Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Karras_DreamPose_Fashion_Video_ICCV_2023_supplemental.pdf)
PhysDiff- Physics-Guided Human Motion Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_PhysDiff_Physics-Guided_Human_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.02500)
SwiftFormer- Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shaker_SwiftFormer_Efficient_Additive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15446)
UpCycling- Semi-supervised 3D Object Detection without Sharing Raw-level Unlabeled Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hwang_UpCycling_Semi-supervised_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11950)
s-Adaptive Decoupled Prototype for Few-Shot Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Du_s-Adaptive_Decoupled_Prototype_ICCV_2023_supplemental.pdf)
Semantics Meets Temporal Correspondence- Self-supervised Object-centric Learning in Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qian_Semantics_Meets_Temporal_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09951)
First Session Adaptation- A Strong Replay-Free Baseline for Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Panos_First_Session_Adaptation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13199)
Ada3D - Exploiting the Spatial Redundancy with Adaptive Inference for Efficient 3D Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.08209)
Point Contrastive Prediction with Semantic Clustering for Self-Supervised Learning on Point Cloud Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09247)
Preserving Modality Structure Improves Multi-Modal Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Swetha_Preserving_Modality_Structure_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13077)
Pre-training Vision Transformers with Very Limited Synthesized Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14710)
PADDLES- Phase-Amplitude Spectrum Disentangled Early Stopping for Learning with Noisy Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_PADDLES_Phase-Amplitude_Spectrum_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.03462)
CLIP-Cluster- CLIP-Guided Attribute Hallucination for Face Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.pdf)
Compositional Feature Augmentation for Unbiased Scene Graph Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Compositional_Feature_Augmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06712)
Foreground and Text-lines Aware Document Image Rectification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.pdf)
INSTA-BNN- Binary Neural Network with INSTAnce-aware Threshold | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_INSTA-BNN_Binary_Neural_ICCV_2023_supplemental.pdf)
When Epipolar Constraint Meets Non-Local Operators in Multi-View Stereo | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_When_Epipolar_Constraint_ICCV_2023_supplemental.pdf)
LU-NeRF- Scene and Pose Estimation by Synchronizing Local Unposed NeRFs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_LU-NeRF_Scene_and_ICCV_2023_supplemental.pdf)
GrowCLIP- Data-Aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deng_GrowCLIP_Data-Aware_Automatic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11331)
LA-Net- Landmark-Aware Learning for Reliable Facial Expression Recognition under Label Noise | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_LA-Net_Landmark-Aware_Learning_ICCV_2023_supplemental.pdf)
SGAligner- 3D Scene Alignment with Scene Graphs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sarkar_SGAligner_3D_Scene_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.14880)
Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity- A Benchmark and Beyond | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barkan_Efficient_Discovery_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14753)
Improving Representation Learning for Histopathologic Images with Cluster Constraints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Improving_Representation_Learning_ICCV_2023_supplemental.pdf)
Learning Neural Implicit Surfaces with Object-Aware Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.pdf)
PADCLIP- Pseudo-labeling with Adaptive Debiasing in CLIP for Unsupervised Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lai_PADCLIP_Pseudo-labeling_with_ICCV_2023_supplemental.pdf)
Causal-DFQ- Causality Guided Data-Free Network Quantization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.pdf)
CancerUniT- Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_CancerUniT_Towards_a_ICCV_2023_supplemental.pdf)
Dual Meta-Learning with Longitudinally Consistent Regularization for One-Shot Brain Tissue Segmentation Across the Human Lifespan | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.pdf)
Active Self-Supervised Learning- A Few Low-Cost Relationships Are All You Need | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cabannes_Active_Self-Supervised_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.15256)
Wasserstein Expansible Variational Autoencoder for Discriminative and Generative Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_supplemental.pdf)
Label-Free Event-based Object Recognition via Joint Learning with Image Reconstruction from Events | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_Label-Free_Event-based_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09383)
Gloss-Free Sign Language Translation- Improving from Visual-Language Pretraining | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Gloss-Free_Sign_Language_ICCV_2023_supplemental.pdf)
Shrinking Class Space for Enhanced Certainty in Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.06777)
eP-ALM- Efficient Perceptual Augmentation of Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shukor_eP-ALM_Efficient_Perceptual_ICCV_2023_supplemental.pdf)
Multimodal Optimal Transport-based Co-Attention Transformer with Global Structure Consistency for Survival Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Multimodal_Optimal_Transport-based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.08330)
Robust One-Shot Face Video Re-enactment using Hybrid Latent Spaces of StyleGAN2 | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Oorloff_Robust_One-Shot_Face_ICCV_2023_supplemental.zip)
RPG-Palm- Realistic Pseudo-data Generation for Palmprint Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shen_RPG-Palm_Realistic_Pseudo-data_ICCV_2023_supplemental.pdf)
Lecture Presentations Multimodal Dataset- Towards Understanding Multimodality in Educational Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Lecture_Presentations_Multimodal_ICCV_2023_supplemental.zip)
Window-Based Early-Exit Cascades for Uncertainty Estimation- When Deep Ensembles are More Efficient than Single Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_Window-Based_Early-Exit_Cascades_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08010)
XNet- Wavelet-Based Low and High Frequency Fusion Networks for Fully- and Semi-Supervised Semantic Segmentation of Biomedical Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.pdf)
Betrayed by Captions- Joint Caption Grounding and Generation for Open Vocabulary Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Betrayed_by_Captions_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.00805)
StyleGANEX- StyleGAN-Based Manipulation Beyond Cropped Aligned Faces | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_StyleGANEX_StyleGAN-Based_Manipulation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.06146)
HandR2N2- Iterative 3D Hand Pose Estimation Using a Residual Recurrent Neural Network | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.pdf)
Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wolf_Unsupervised_Learning_of_ICCV_2023_supplemental.pdf)
XiNet- Efficient Neural Networks for tinyML | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ancilotto_XiNet_Efficient_Neural_ICCV_2023_supplemental.pdf)
GridPull- Towards Scalability in Learning Implicit Representations from 3D Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.13175)
GeoMIM- Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.11325)
RenderIH- A Large-Scale Synthetic Dataset for 3D Interacting Hand Pose Estimation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_RenderIH_A_Large-Scale_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.09301)
Cross-modal Scalable Hyperbolic Hierarchical Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.pdf)
PointMBF- A Multi-scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_PointMBF_A_Multi-scale_ICCV_2023_supplemental.pdf)
LiveHand- Real-time and Photorealistic Neural Hand Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mundra_LiveHand_Real-time_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2302.07672)
TripLe- Revisiting Pretrained Model Reuse and Progressive Learning for Efficient Vision Transformer Scaling and Searching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fu_TripLe_Revisiting_Pretrained_ICCV_2023_supplemental.pdf)
Learning Unified Decompositional and Compositional NeRF for Editable Novel View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Learning_Unified_Decompositional_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.02840)
SeeABLE- Soft Discrepancies and Bounded Contrastive Learning for Exposing Deepfakes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Larue_SeeABLE_Soft_Discrepancies_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.11296)
Semi-Supervised Learning via Weight-Aware Distillation under Class Distribution Mismatch | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Du_Semi-Supervised_Learning_via_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11874)
ELFNet- Evidential Local-global Fusion for Stereo Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.00728)
SimpleClick- Interactive Image Segmentation with Simple Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_SimpleClick_Interactive_Image_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2210.11006)
Towards Content-based Pixel Retrieval in Revisited Oxford and Paris | [link](https://openaccess.thecvf.com/content/ICCV2023/html/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.05438)
Retro-FPN- Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_Retro-FPN_Retrospective_Feature_ICCV_2023_supplemental.pdf)
Benchmarking Low-Shot Robustness to Natural Distribution Shifts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Singh_Benchmarking_Low-Shot_Robustness_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.11263)
DeLiRa- Self-Supervised Depth, Light, and Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guizilini_DeLiRa_Self-Supervised_Depth_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.02797)
Stable Cluster Discrimination for Deep Clustering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qian_Stable_Cluster_Discrimination_ICCV_2023_supplemental.pdf)
Pix2Video- Video Editing using Image Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.12688)
Holistic Geometric Feature Learning for Structured Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.09622)
FateZero- Fusing Attentions for Zero-shot Text-based Video Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/QI_FateZero_Fusing_Attentions_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09535)
Uncertainty-guided Learning for Improving Image Manipulation Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Uncertainty-guided_Learning_for_ICCV_2023_supplemental.pdf)
AdaMV-MoE- Adaptive Multi-Task Vision Mixture-of-Experts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_AdaMV-MoE_Adaptive_Multi-Task_ICCV_2023_supplemental.pdf)
Hierarchical Visual Categories Modeling- A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Hierarchical_Visual_Categories_ICCV_2023_supplemental.pdf)
ReNeRF- Relightable Neural Radiance Fields with Nearfield Lighting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_ReNeRF_Relightable_Neural_ICCV_2023_supplemental.zip)
360VOT- A New Benchmark Dataset for Omnidirectional Visual Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_360VOT_A_New_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14630)
Is Imitation All You Need- Generalized Decision-Making with Dual-Phase Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Is_Imitation_All_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07909)
LERF- Language Embedded Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kerr_LERF_Language_Embedded_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.09553)
DomainAdaptor- A Novel Approach to Test-time Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_DomainAdaptor_A_Novel_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10297)
Mitigating and Evaluating Static Bias of Action Representations in the Background and the Foreground | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.12883)
CuNeRF- Cube-Based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.16242)
Beyond Object Recognition- A New Benchmark towards Object Concept Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Beyond_Object_Recognition_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.02710)
EgoObjects- A Large-Scale Egocentric Dataset for Fine-Grained Object Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_EgoObjects_A_Large-Scale_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.08816)
Simulating Fluids in Real-World Still Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fan_Simulating_Fluids_in_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.11335)
SC3K- Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zohaib_SC3K_Self-supervised_and_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.05410)
Segmenting Known Objects and Unseen Unknowns without Prior Knowledge | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gasperini_Segmenting_Known_Objects_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2209.05407)
CMDA- Cross-Modality Domain Adaptation for Nighttime Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15942)
Learning with Diversity- Self-Expanded Equalization for Better Generalized Deep Metric Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.pdf)
Dynamic Residual Classifier for Class Incremental Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Dynamic_Residual_Classifier_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13305)
Optimizing the Placement of Roadside LiDARs for Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_supplemental.pdf)
Diverse Inpainting and Editing with GAN Inversion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yildirim_Diverse_Inpainting_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15033)
DiFaReli- Diffusion Face Relighting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ponglertnapakorn_DiFaReli_Diffusion_Face_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.09479)
Building3D- A Urban-Scale Dataset and Benchmarks for Learning Roof Structures from Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.pdf)
Localizing Object-Level Shape Variations with Text-to-Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Patashnik_Localizing_Object-Level_Shape_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11306)
CoSign- Exploring Co-occurrence Signals in Skeleton-based Continuous Sign Language Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiao_CoSign_Exploring_Co-occurrence_ICCV_2023_supplemental.pdf)
Disentangle then Parse- Night-time Semantic Segmentation with Illumination Disentanglement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Disentangle_then_Parse_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09362)
Large-Scale Land Cover Mapping with Fine-Grained Classes via Class-Aware Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Large-Scale_Land_Cover_ICCV_2023_supplemental.pdf)
LISTER- Neighbor Decoding for Length-Insensitive Scene Text Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_LISTER_Neighbor_Decoding_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.12774)
Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Proxy_Anchor-based_Unsupervised_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10943)
Distribution-Aware Prompt Tuning for Vision-Language Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_Distribution-Aware_Prompt_Tuning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03406)
Fantasia3D- Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.13873)
MagicFusion- Boosting Text-to-Image Generation Performance by Fusing Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_MagicFusion_Boosting_Text-to-Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13126)
UCF- Uncovering Common Features for Generalizable Deepfake Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yan_UCF_Uncovering_Common_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.13949)
Sample4Geo- Hard Negative Sampling For Cross-View Geo-Localisation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deuser_Sample4Geo_Hard_Negative_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11851)
Novel Scenes & Classes- Towards Adaptive Open-set Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_supplemental.pdf)
LIMITR- Leveraging Local Information for Medical Image-Text Representation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dawidowicz_LIMITR_Leveraging_Local_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11755)
Multi-task View Synthesis with Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Multi-task_View_Synthesis_ICCV_2023_supplemental.zip)
Visual Traffic Knowledge Graph Generation from Scene Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Visual_Traffic_Knowledge_ICCV_2023_supplemental.pdf)
OmnimatteRF- Robust Omnimatte with 3D Background Modeling | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_OmnimatteRF_Robust_Omnimatte_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.07749)
Bold but Cautious- Unlocking the Potential of Personalized Federated Learning through Cautiously Aggressive Collaboration | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Bold_but_Cautious_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.11103)
ESSAformer- Efficient Transformer for Hyperspectral Image Super-resolution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_ESSAformer_Efficient_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.14010)
Thinking Image Color Aesthetics Assessment- Models, Datasets and Benchmarks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.pdf)
Multi-body Depth and Camera Pose Estimation from Multiple Views | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dal_Cin_Multi-body_Depth_and_ICCV_2023_supplemental.pdf)
DISeR- Designing Imaging Systems with Reinforcement Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Klinghoffer_DISeR_Designing_Imaging_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.13851)
The Euclidean Space is Evil- Hyperbolic Attribute Editing for Few-shot Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_The_Euclidean_Space_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.12347)
Invariant Feature Regularization for Fair Face Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Invariant_Feature_Regularization_ICCV_2023_supplemental.pdf)
Local Context-Aware Active Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Local_Context-Aware_Active_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.12856)
Deep Incubation- Training Large Models by Divide-and-Conquering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ni_Deep_Incubation_Training_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04129)
iVS-Net- Learning Human View Synthesis from Internet Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_supplemental.pdf)
All4One- Symbiotic Neighbour Contrastive Learning via Self-Attention and Redundancy Reduction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Estepa_All4One_Symbiotic_Neighbour_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09417)
Contrastive Pseudo Learning for Open-World DeepFake Attribution | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Contrastive_Pseudo_Learning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.11132)
ICL-D3IE- In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.pdf)
Shape Anchor Guided Holistic Indoor Scene Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.11133)
Knowledge-Aware Federated Active Learning with Non-IID Data | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Knowledge-Aware_Federated_Active_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.13579)
PlankAssembly- Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_PlankAssembly_Robust_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05744)
PODIA-3D- Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_PODIA-3D_Domain_Adaptation_ICCV_2023_supplemental.zip)
Steered Diffusion- A Generalized Framework for Plug-and-Play Conditional Image Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_supplemental.pdf)
Vision Grid Transformer for Document Layout Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Da_Vision_Grid_Transformer_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14978)
Few Shot Font Generation Via Transferring Similarity Guided Global Style and Quantization Local Style | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2309.00827)
Differentiable Transportation Pruning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Differentiable_Transportation_Pruning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08483)
Large Selective Kernel Network for Remote Sensing Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.09030)
I-ViT- Integer-only Quantization for Efficient Vision Transformer Inference | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.pdf)
To Adapt or Not to Adapt- Real-Time Adaptation for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Colomer_To_Adapt_or_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.15063)
Strivec- Sparse Tri-Vector Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13226)
Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Multiscale_Representation_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10075)
Borrowing Knowledge From Pre-trained Language Model- A New Data-efficient Visual Learning Paradigm | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Borrowing_Knowledge_From_ICCV_2023_supplemental.pdf)
Tracking without Label- Unsupervised Multiple Object Tracking via Contrastive Similarity Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Meng_Tracking_without_Label_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.00942)
Re-mine, Learn and Reason- Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Re-mine_Learn_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.13529)
Strata-NeRF - Neural Radiance Fields for Stratified Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dhiman_Strata-NeRF__Neural_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.10337)
3D-aware Blending with Generative NeRFs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_3D-aware_Blending_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.06608)
Multi-Modal Gated Mixture of Local-to-Global Experts for Dynamic Image Fusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Multi-Modal_Gated_Mixture_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.01392)
DELFlow- Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_DELFlow_Dense_Efficient_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.04383)
E^2VPT- An Effective and Efficient Approach for Visual Prompt Tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_E2VPT_An_Effective_ICCV_2023_supplemental.pdf)
From Knowledge Distillation to Self-Knowledge Distillation- A Unified Approach with Normalized Loss and Customized Soft Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_From_Knowledge_Distillation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.13005)
Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.01194)
Graph Matching with Bi-level Noisy Correspondence | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Graph_Matching_with_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04085)
InfiniCity- Infinite-Scale City Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_InfiniCity_Infinite-Scale_City_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2301.09637)
OpenOccupancy- A Large Scale Benchmark for Surrounding Semantic Occupancy Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2303.03991)
Weakly-Supervised Text-Driven Contrastive Learning for Facial Behavior Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Weakly-Supervised_Text-Driven_Contrastive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.00058)
Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gomel_Box-based_Refinement_for_ICCV_2023_supplemental.pdf)
PRIOR- Prototype Representation Joint Learning from Medical Images and Reports | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_PRIOR_Prototype_Representation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.12577)
Vision HGNN- An Image is More than a Graph of Nodes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.pdf)
HumanSD- A Native Skeleton-Guided Diffusion Model for Human Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ju_HumanSD_A_Native_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.04269)
HRS-Bench- Holistic, Reliable and Scalable Benchmark for Text-to-Image Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bakr_HRS-Bench_Holistic_Reliable_ICCV_2023_supplemental.pdf)
DiffCloth- Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_DiffCloth_Diffusion_Based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11206)
Class Prior-Free Positive-Unlabeled Learning with Taylor Variational Loss for Hyperspectral Remote Sensing Imagery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Class_Prior-Free_Positive-Unlabeled_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.15081)
HoloAssist- an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_HoloAssist_an_Egocentric_ICCV_2023_supplemental.pdf)
StableVideo- Text-driven Consistency-aware Diffusion Video Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chai_StableVideo_Text-driven_Consistency-aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09592)
PIRNet- Privacy-Preserving Image Restoration Network via Wavelet Lifting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.pdf)
LAW-Diffusion- Complex Scene Generation by Diffusion with Layouts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_LAW-Diffusion_Complex_Scene_ICCV_2023_supplemental.pdf)
Multi-Label Knowledge Distillation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.06453)
Towards Geospatial Foundation Models via Continual Pretraining | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Mendieta_Towards_Geospatial_Foundation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.04476)
ConSlide- Asynchronous Hierarchical Interaction Transformer with Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_ConSlide_Asynchronous_Hierarchical_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13324)
RepQ-ViT- Scale Reparameterization for Post-Training Quantization of Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.pdf)
ReactioNet- Learning High-Order Facial Behavior from Universal Stimulus-Reaction by Dyadic Relation Reasoning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_ReactioNet_Learning_High-Order_ICCV_2023_supplemental.pdf)
Emotional Listener Portrait- Neural Listener Head Generation with Emotion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Emotional_Listener_Portrait_ICCV_2023_supplemental.zip)
Unsupervised Domain Adaptation for Training Event-Based Networks Using Contrastive Learning and Uncorrelated Conditioning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jian_Unsupervised_Domain_Adaptation_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.12424)
DRAW- Defending Camera-shooted RAW Against Image Manipulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.16418)
Controllable Person Image Synthesis with Pose-Constrained Latent Diffusion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Controllable_Person_Image_ICCV_2023_supplemental.pdf)
TopoSeg- Topology-Aware Nuclear Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.pdf)
CPCM- Contextual Point Cloud Modeling for Weakly-supervised Point Cloud Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_CPCM_Contextual_Point_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10316)
PATMAT- Person Aware Tuning of Mask-Aware Transformer for Face Inpainting | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Motamed_PATMAT_Person_Aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.06107)
Adaptive Nonlinear Latent Transformation for Conditional Face Editing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Adaptive_Nonlinear_Latent_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07790)
Tiny Updater- Towards Efficient Neural Network-Driven Software Updating | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.pdf)
CAD-Estate- Large-scale CAD Model Annotation in RGB Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.pdf)
Muscles in Action | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chiquier_Muscles_in_Action_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chiquier_Muscles_in_Action_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chiquier_Muscles_in_Action_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2212.02978)
Large-Scale Person Detection and Localization Using Overhead Fisheye Cameras | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Large-Scale_Person_Detection_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08252)
All-to-Key Attention for Arbitrary Style Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_All-to-Key_Attention_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04105)
Learning to Distill Global Representation for Sparse-View CT | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Learning_to_Distill_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08463)
SparseMAE- Sparse Training Meets Masked Autoencoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_SparseMAE_Sparse_Training_ICCV_2023_supplemental.pdf)
ELITE- Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_ELITE_Encoding_Visual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.13848)
Text2Performer- Text-Driven Human Video Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Text2Performer_Text-Driven_Human_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.08483)
A Simple Recipe to Meta-Learn Forward and Backward Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cetin_A_Simple_Recipe_ICCV_2023_supplemental.pdf)
4D Myocardium Reconstruction with Decoupled Motion and Shape Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_4D_Myocardium_Reconstruction_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.14083)
LiDAR-UDA- Self-ensembling Through Time for Unsupervised LiDAR Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shaban_LiDAR-UDA_Self-ensembling_Through_ICCV_2023_supplemental.pdf)
MSI- Maximize Support-Set Information for Few-Shot Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Moon_MSI_Maximize_Support-Set_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.04673)
H3WB- Human3.6M 3D WholeBody Dataset and Benchmark | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_H3WB_Human3.6M_3D_ICCV_2023_supplemental.pdf)
LDP-Feat- Image Features with Local Differential Privacy | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pittaluga_LDP-Feat_Image_Features_ICCV_2023_supplemental.pdf)
Pre-Training-Free Image Manipulation Localization through Non-Mutually Exclusive Contrastive Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.pdf)
MRN- Multiplexed Routing Network for Incremental Multilingual Text Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_MRN_Multiplexed_Routing_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.14758)
MOST- Multiple Object Localization with Self-Supervised Transformers for Object Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Rambhatla_MOST_Multiple_Object_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.05387)
SAFE- Machine Unlearning With Shard Graphs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dukler_SAFE_Machine_Unlearning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.13169)
OrthoPlanes- A Novel Representation for Better 3D-Awareness of GANs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_supplemental.pdf)
NeTO-Neural Reconstruction of Transparent Objects with Self-Occlusion Aware Refraction-Tracing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_NeTONeural_Reconstruction_of_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.11219)
Boosting 3-DoF Ground-to-Satellite Camera Localization Accuracy via Geometry-Guided Cross-View Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Boosting_3-DoF_Ground-to-Satellite_ICCV_2023_supplemental.pdf)
Adaptive Reordering Sampler with Neurally Guided MAGSAC | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Adaptive_Reordering_Sampler_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14093)
Learning Cross-Representation Affinity Consistency for Sparsely Supervised Biomedical Instance Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Learning_Cross-Representation_Affinity_ICCV_2023_supplemental.pdf)
A Skeletonization Algorithm for Gradient-Based Optimization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Menten_A_Skeletonization_Algorithm_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02527)
V3Det- Vast Vocabulary Visual Detection Dataset | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.03752)
Multi-weather Image Restoration via Domain Translation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Patil_Multi-weather_Image_Restoration_ICCV_2023_supplemental.pdf)
Improving Unsupervised Visual Program Inference with Code Rewriting Families | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_supplemental.pdf)
Essential Matrix Estimation using Convex Relaxations in Orthogonal Space | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Karimian_Essential_Matrix_Estimation_ICCV_2023_supplemental.pdf)
Concept-wise Fine-tuning Matters in Preventing Negative Transfer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Concept-wise_Fine-tuning_Matters_ICCV_2023_supplemental.pdf)
Learning Human Dynamics in Autonomous Driving Scenarios | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_supplemental.pdf)
DDP- Diffusion Model for Dense Visual Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_DDP_Diffusion_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.17559)
Semantics-Consistent Feature Search for Self-Supervised Visual Representation Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Semantics-Consistent_Feature_Search_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.06486)
Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf)
Total-Recon- Deformable Scene Reconstruction for Embodied View Synthesis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Total-Recon_Deformable_Scene_ICCV_2023_supplemental.pdf)
AdaNIC- Towards Practical Neural Image Compression via Dynamic Transform Routing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.pdf)
Privacy Preserving Localization via Coordinate Permutations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Privacy_Preserving_Localization_ICCV_2023_supplemental.pdf)
SMMix- Self-Motivated Image Mixing for Vision Transformers | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_SMMix_Self-Motivated_Image_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.12977)
Reconciling Object-Level and Global-Level Objectives for Long-Tail Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Reconciling_Object-Level_and_ICCV_2023_supplemental.pdf)
In-Style- Bridging Text and Uncurated Videos with Style Transfer for Text-Video Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shvetsova_In-Style_Bridging_Text_ICCV_2023_supplemental.pdf)
CLIPTER- Looking at the Bigger Picture in Scene Text Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Aberdam_CLIPTER_Looking_at_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2301.07464)
Revisiting Scene Text Recognition- A Data Perspective | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Revisiting_Scene_Text_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08723)
DPM-OT- A New Diffusion Probabilistic Model Based on Optimal Transport | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DPM-OT_A_New_ICCV_2023_supplemental.pdf)
Inherent Redundancy in Spiking Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_Inherent_Redundancy_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.08227)
FastRecon- Few-shot Industrial Anomaly Detection via Fast Feature Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.pdf)
Local or Global- Selective Knowledge Assimilation for Federated Learning with Limited Labels | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_Local_or_Global_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08809)
Learning Pseudo-Relations for Cross-domain Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Learning_Pseudo-Relations_for_ICCV_2023_supplemental.pdf)
Human-centric Scene Understanding for 3D Large-scale Scenarios | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2307.14392)
SimMatchV2- Semi-Supervised Learning with Graph Consistency | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.06692)
Reinforced Disentanglement for Face Swapping without Skip Connection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_Reinforced_Disentanglement_for_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.07928)
Privacy-Preserving Face Recognition Using Random Frequency Components | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10461)
Vision Transformer Adapters for Generalizable Multitask Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bhattacharjee_Vision_Transformer_Adapters_ICCV_2023_supplemental.pdf)
CVRecon- Rethinking 3D Geometric Feature Learning For Neural Reconstruction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_CVRecon_Rethinking_3D_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.14633)
ClothesNet- An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.09987)
StyleLipSync- Style-based Personalized Lip-sync Video Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ki_StyleLipSync_Style-based_Personalized_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.00521)
Efficient 3D Semantic Segmentation with Superpoint Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Robert_Efficient_3D_Semantic_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.08045)
Minimum Latency Deep Online Video Stabilization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2212.02073)
Speech2Lip- High-fidelity Speech to Lip Generation by Learning from a Short Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Speech2Lip_High-fidelity_Speech_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.04814)
UHDNeRF- Ultra-High-Definition Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_UHDNeRF_Ultra-High-Definition_Neural_ICCV_2023_supplemental.zip)
Why do networks have inhibitory-negative connections- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Why_do_networks_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.03211)
Ordinal Label Distribution Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.pdf)
Boosting Multi-modal Model Performance with Adaptive Gradient Modulation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Boosting_Multi-modal_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.07686)
PODA- Prompt-driven Zero-shot Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fahes_PODA_Prompt-driven_Zero-shot_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.03241)
SAFL-Net- Semantic-Agnostic Feature Learning Network with Auxiliary Plugins for Image Manipulation Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_SAFL-Net_Semantic-Agnostic_Feature_ICCV_2023_supplemental.pdf)
DataDAM- Efficient Dataset Distillation with Attention Matching | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sajedi_DataDAM_Efficient_Dataset_ICCV_2023_supplemental.pdf)
PlanarTrack- A Large-scale Challenging Benchmark for Planar Object Tracking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_PlanarTrack_A_Large-scale_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.07625)
Structural Alignment for Network Pruning through Partial Regularization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Structural_Alignment_for_ICCV_2023_supplemental.pdf)
Learning Long-Range Information with Dual-Scale Transformers for Indoor Scene Completion | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Learning_Long-Range_Information_ICCV_2023_supplemental.pdf)
Discriminative Class Tokens for Text-to-Image Diffusion Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Schwartz_Discriminative_Class_Tokens_ICCV_2023_supplemental.pdf)
ORC- Network Group-based Knowledge Distillation using Online Role Change | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Choi_ORC_Network_Group-based_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.01186)
Audiovisual Masked Autoencoders | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.05922)
DomainDrop- Suppressing Domain-Sensitive Channels for Domain Generalization | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_DomainDrop_Suppressing_Domain-Sensitive_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.10285)
StyleInV- A Temporal Style Modulated Inversion Network for Unconditional Video Generation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_StyleInV_A_Temporal_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.16909)
Anatomical Invariance Modeling and Semantic Alignment for Self-supervised Learning in 3D Medical Image Analysis | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Anatomical_Invariance_Modeling_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2302.05615)
SSDA- Secure Source-Free Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ahmed_SSDA_Secure_Source-Free_ICCV_2023_supplemental.pdf)
ESTextSpotter- Towards Better Scene Text Spotting with Explicit Synergy in Transformer | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10147)
UGC- Unified GAN Compression for Efficient Image-to-Image Translation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_UGC_Unified_GAN_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.09310)
Efficient View Synthesis with Neural Radiance Distribution Field | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Efficient_View_Synthesis_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2308.11130)
SparseBEV- High-Performance Sparse 3D Object Detection from Multi-Camera Videos | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_SparseBEV_High-Performance_Sparse_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09244)
Boosting Whole Slide Image Classification from the Perspectives of Distribution, Correlation and Magnification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.pdf)
Multimodal High-order Relation Transformer for Scene Boundary Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.pdf)
Tri-MipRF- Tri-Mip Representation for Efficient Anti-Aliasing Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.pdf)
LaRS- A Diverse Panoptic Maritime Obstacle Detection Dataset and Benchmark | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zust_LaRS_A_Diverse_ICCV_2023_supplemental.pdf)
Self-Evolved Dynamic Expansion Model for Task-Free Continual Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Self-Evolved_Dynamic_Expansion_ICCV_2023_supplemental.pdf)
Adaptive Template Transformer for Mitochondria Segmentation in Electron Microscopy Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.pdf)
Tangent Model Composition for Ensembling and Continual Fine-tuning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08114)
Knowledge-Spreader- Learning Semi-Supervised Facial Action Dynamics by Consistifying Knowledge Granularity | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Knowledge-Spreader_Learning_Semi-Supervised_ICCV_2023_supplemental.pdf)
Kick Back & Relax- Learning to Reconstruct the World by Watching SlowTV | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Spencer_Kick_Back__ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.10713)
ChildPlay- A New Benchmark for Understanding Childrens Gaze Behaviour | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tafasca_ChildPlay_A_New_ICCV_2023_supplemental.zip)
When Noisy Labels Meet Long Tail Dilemmas- A Representation Calibration Method | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_When_Noisy_Labels_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10955)
Reinforce Data, Multiply Impact- Improved Model Accuracy and Robustness with Dataset Reinforcement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Faghri_Reinforce_Data_Multiply_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.08983)
Incremental Generalized Category Discovery | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Incremental_Generalized_Category_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.14310)
Guiding Local Feature Matching with Surface Curvature | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Guiding_Local_Feature_ICCV_2023_supplemental.pdf)
Constraining Depth Map Geometry for Multi-View Stereo- A Dual-Depth Approach with Saddle-shaped Depth Cells | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Constraining_Depth_Map_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.09160)
DiffusionDet- Diffusion Model for Object Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_DiffusionDet_Diffusion_Model_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.09788)
Forward Flow for Novel View Synthesis of Dynamic Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Forward_Flow_for_ICCV_2023_supplemental.zip)
CopyRNeRF- Protecting the CopyRight of Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_CopyRNeRF_Protecting_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.11526)
SegRCDB- Semantic Segmentation via Formula-Driven Supervised Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shinoda_SegRCDB_Semantic_Segmentation_ICCV_2023_supplemental.pdf)
LoTE-Animal- A Long Time-span Dataset for Endangered Animal Behavior Understanding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_LoTE-Animal_A_Long_ICCV_2023_supplemental.zip)
DQS3D- Densely-matched Quantization-aware Semi-supervised 3D Detection | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_DQS3D_Densely-matched_Quantization-aware_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.13031)
Towards Inadequately Pre-trained Models in Transfer Learning | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deng_Towards_Inadequately_Pre-trained_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04668)
Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hao_Class-Aware_Patch_Embedding_ICCV_2023_supplemental.pdf)
Federated Learning Over Images- Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Federated_Learning_Over_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.03237)
HOSNeRF- Dynamic Human-Object-Scene Neural Radiance Fields from a Single Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_HOSNeRF_Dynamic_Human-Object-Scene_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2304.12281)
Collaborative Propagation on Multiple Instance Graphs for 3D Instance Segmentation with Single-point Supervision | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Collaborative_Propagation_on_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2208.05110)
RMP-Loss- Regularizing Membrane Potential Distribution for Spiking Neural Networks | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf)
Multi-grained Temporal Prototype Learning for Few-shot Video Object Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Multi-grained_Temporal_Prototype_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.11160)
Time Does Tell- Self-Supervised Time-Tuning of Dense Image Representations | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Salehi_Time_Does_Tell_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11796)
CroCo v2- Improved Cross-view Completion Pre-training for Stereo Matching and Optical Flow | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Weinzaepfel_CroCo_v2_Improved_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.10408)
ExBluRF- Efficient Radiance Fields for Extreme Motion Blurred Images | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_ExBluRF_Efficient_Radiance_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2309.08957)
Text2Video-Zero- Text-to-Image Diffusion Models are Zero-Shot Video Generators | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_ICCV_2023_supplemental.pdf)
Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Exploring_Video_Quality_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2211.04894)
Distributed Bundle Adjustment with Block-Based Sparse Matrix Compression for Super Large Scale Datasets | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Distributed_Bundle_Adjustment_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2307.08383)
Spurious Features Everywhere - Large-Scale Detection of Harmful Spurious Features in ImageNet | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Neuhaus_Spurious_Features_Everywhere_ICCV_2023_supplemental.pdf)
Delicate Textured Mesh Recovery from NeRF via Adaptive Surface Refinement | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Delicate_Textured_Mesh_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.02091)
Probabilistic Precision and Recall Towards Reliable Evaluation of Generative Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Probabilistic_Precision_and_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.01590)
Deep Multitask Learning with Progressive Parameter Sharing | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shi_Deep_Multitask_Learning_ICCV_2023_supplemental.pdf)
Personalized Semantics Excitation for Federated Image Classification | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.pdf)
SurroundOcc- Multi-camera 3D Occupancy Prediction for Autonomous Driving | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_SurroundOcc_Multi-camera_3D_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.09551)
Deep Multiview Clustering by Contrasting Cluster Assignments | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Deep_Multiview_Clustering_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.10769)
Look at the Neighbor- Distortion-aware Unsupervised Domain Adaptation for Panoramic Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Look_at_the_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.05493)
Rethinking Safe Semi-supervised Learning- Transferring the Open-set Problem to A Close-set One | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Rethinking_Safe_Semi-supervised_ICCV_2023_supplemental.pdf)
Iterative Superquadric Recomposition of 3D Objects from Multiple Views | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Alaniz_Iterative_Superquadric_Recomposition_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2309.02102)
SiLK- Simple Learned Keypoints | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gleize_SiLK_Simple_Learned_ICCV_2023_supplemental.pdf)
EfficientViT- Lightweight Multi-Scale Attention for High-Resolution Dense Prediction | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.pdf)
Rapid Adaptation in Online Continual Learning- Are We Evaluating It Right- | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2305.09275)
Label-Efficient Online Continual Object Detection in Streaming Video | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Label-Efficient_Online_Continual_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.00309)
Diverse Cotraining Makes Strong Semi-Supervised Segmentor | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Diverse_Cotraining_Makes_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09281)
VQA-GNN- Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_VQA-GNN_Reasoning_with_ICCV_2023_supplemental.pdf)
Unmasked Teacher- Towards Training-Efficient Video Foundation Models | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Unmasked_Teacher_Towards_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2303.16058)
SQAD- Automatic Smartphone Camera Quality Assessment and Benchmarking | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_SQAD_Automatic_Smartphone_ICCV_2023_supplemental.pdf)
Multi-Event Video-Text Retrieval | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.11551)
You Never Get a Second Chance To Make a Good First Impression- Seeding Active Learning for 3D Semantic Segmentation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Samet_You_Never_Get_ICCV_2023_supplemental.pdf)
Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Scalable_Multi-Temporal_Remote_ICCV_2023_supplemental.pdf)
NerfAcc- Efficient Sampling Accelerates NeRFs | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2305.04966)
A2Q- Accumulator-Aware Quantization with Guaranteed Overflow Avoidance | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Colbert_A2Q_Accumulator-Aware_Quantization_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.13504)
ARNOLD- A Benchmark for Language-Grounded Task Learning with Continuous States in Realistic 3D Scenes | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2304.04321)
CLNeRF- Continual Learning Meets NeRF | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_CLNeRF_Continual_Learning_ICCV_2023_supplemental.pdf)
CrossMatch- Source-Free Domain Adaptive Semantic Segmentation via Cross-Modal Consistency Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.pdf)
Improving Equivariance in State-of-the-Art Supervised Depth and Normal Predictors | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhong_Improving_Equivariance_in_ICCV_2023_supplemental.zip)
Reducing Training Time in Cross-Silo Federated Learning Using Multigraph Topology | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2207.09657)
Counting Crowds in Bad Weather | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Counting_Crowds_in_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2306.01209)
FreeDoM- Training-Free Energy-Guided Conditional Diffusion Model | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_FreeDoM_Training-Free_Energy-Guided_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2303.09833)
UniT3D- A Unified Transformer for 3D Dense Captioning and Visual Grounding | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_UniT3D_A_Unified_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.00836)
SKiT- a Fast Key Information Video Transformer for Online Surgical Phase Recognition | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_SKiT_a_Fast_ICCV_2023_supplemental.pdf)
Automatic Network Pruning via Hilbert-Schmidt Independence Criterion Lasso under Information Bottleneck Principle | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_Automatic_Network_Pruning_ICCV_2023_supplemental.pdf)
Neglected Free Lunch - Learning Image Classifiers Using Annotation Byproducts | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Neglected_Free_Lunch_ICCV_2023_supplemental.pdf)
Rethinking the Role of Pre-Trained Networks in Source-Free Domain Adaptation | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Rethinking_the_Role_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2212.07585)
RLIPv2- Fast Scaling of Relational Language-Image Pre-Training | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_RLIPv2_Fast_Scaling_ICCV_2023_supplemental.pdf), [arXiv](http://arxiv.org/abs/2308.09351)
TransFace- Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.pdf), [arXiv](http://arxiv.org/abs/2308.10133)
Aria Digital Twin- A New Benchmark Dataset for Egocentric 3D Machine Perception | [link](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.html), [pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.pdf), [supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Aria_Digital_Twin_ICCV_2023_supplemental.zip), [arXiv](http://arxiv.org/abs/2306.06362)