COSMOS- Catching Out-of-Context Image Misuse Using Self-Supervised Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26648), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26648/26420), [keywords](General), [abstract](Abstract
Despite the recent attention to DeepFakes, one of the most prevalent ways to mislead audiences on social media is the use of unaltered images in a new but false context. We propose a new method that automatically highlights out-of-context image and text pairs, for assisting fact-checkers. Our key insight is to leverage the grounding of images with text to distinguish out-of-context scenarios that cannot be disambiguated with language alone. We propose a self-supervised training strategy where we only need a set of captioned images. At train time, our method learns to selectively align individual objects in an image with textual claims, without explicit supervision. At test time, we check if both captions correspond to the same object(s) in the image but are semantically different, which allows us to make fairly accurate out-of-context predictions. Our method achieves 85% out-of-context detection accuracy. To facilitate benchmarking of this task, we create a large-scale dataset of 200K images with 450K textual captions from a variety of news websites, blogs, and social media posts), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Med-EASi- Finely Annotated Dataset and Models for Controllable Simplification of Medical Texts | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26649), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26649/26421), [keywords](General), [abstract](Abstract
Automatic medical text simplification can assist providers with patient-friendly communication and make medical texts more accessible, thereby improving health literacy. But curating a quality corpus for this task requires the supervision of medical experts. In this work, we present Med-EASi (Medical dataset for Elaborative and Abstractive Simplification), a uniquely crowdsourced and finely annotated dataset for supervised simplification of short medical texts. Its expert-layman-AI collaborative annotations facilitate controllability over text simplification by marking four kinds of textual transformations: elaboration, replacement, deletion, and insertion. To learn medical text simplification, we fine-tune T5-large with four different styles of input-output combinations, leading to two control-free and two controllable versions of the model. We add two types of controllability into text simplification, by using a multi-angle training approach: position-aware, which uses in-place annotated inputs and outputs, and position-agnostic, where the model only knows the contents to be edited, but not their positions. Our results show that our fine-grained annotations improve learning compared to the unannotated baseline. Furthermore, our position-aware control enhances the model's ability to generate better simplification than the position-agnostic version. The data and code are available at https://github.com/Chandrayee/CTRL-SIMP.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
On the Challenges of Using Reinforcement Learning in Precision Drug Dosing- Delay and Prolongedness of Action Effects | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26650), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26650/26422), [keywords](General), [abstract](Abstract
Drug dosing is an important application of AI, which can be formulated as a Reinforcement Learning (RL) problem. In this paper, we identify two major challenges of using RL for drug dosing: delayed and prolonged effects of administering medications, which break the Markov assumption of the RL framework. We focus on prolongedness and define PAE-POMDP (Prolonged Action Effect-Partially Observable Markov Decision Process), a subclass of POMDPs in which the Markov assumption does not hold specifically due to prolonged effects of actions. Motivated by the pharmacology literature, we propose a simple and effective approach to converting drug dosing PAE-POMDPs into MDPs, enabling the use of the existing RL algorithms to solve such problems. We validate the proposed approach on a toy task, and a challenging glucose control task, for which we devise a clinically-inspired reward function. Our results demonstrate that: (1) the proposed method to restore the Markov assumption leads to significant improvements over a vanilla baseline; (2) the approach is competitive with recurrent policies which may inherently capture the prolonged affect of actions; (3) it is remarkably more time and memory efficient than the recurrent baseline and hence more suitable for real-time dosing control systems; and (4) it exhibits favourable qualitative behavior in our policy analysis.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
On the Cost of Demographic Parity in Influence Maximization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26651), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26651/26423), [keywords](General), [abstract](Abstract
Modeling and shaping how information spreads through a network is a major research topic in network analysis. While initially the focus has been mostly on efficiency, recently fairness criteria have been taken into account in this setting.
Most work has focused on the maximin criteria however, and thus still different groups can receive very different shares of information. In this work we propose to consider fairness as a notion to be guaranteed by an algorithm rather than as a criterion to be maximized. To this end, we propose three optimization problems that aim at maximizing the overall spread while enforcing strict levels of demographic parity fairness via constraints (either ex-post or ex-ante). The level of fairness hence becomes a user choice rather than a property to be observed upon output. We study this setting from various perspectives.
First, we prove that the cost of introducing demographic parity can be high in terms of both overall spread and computational complexity, i.e., the price of fairness may be unbounded for all three problems and optimal solutions are hard to compute, in some case even approximately or when fairness constraints may be violated. 
For one of our problems, we still design an algorithm with both constant approximation factor and fairness violation.
We also give two heuristics that allow the user to choose the tolerated fairness violation. By means of an extensive experimental study, we show that our algorithms perform well in practice, that is, they achieve the best demographic parity fairness values. For certain instances we additionally even obtain an overall spread comparable to the most efficient algorithms that come without any fairness guarantee, indicating that the empirical price of fairness may actually be small when using our algorithms.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Improving Fairness in Information Exposure by Adding Links | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26652), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26652/26424), [keywords](General), [abstract](Abstract
Fairness in influence maximization has been a very active research topic recently. Most works in this context study the question of how to find seeding strategies (deterministic or probabilistic) such that nodes or communities in the network get their fair share of coverage. Different fairness criteria have been used in this context. All these works assume that the entity that is spreading the information has an inherent interest in spreading the information fairly, otherwise why would they want to use the developed fair algorithms? This assumption may however be flawed in reality -- the spreading entity may be purely efficiency-oriented. In this paper we propose to study two optimization problems with the goal to modify the network structure by adding links in such a way that efficiency-oriented information spreading becomes automatically fair. We study the proposed optimization problems both from a theoretical and experimental perspective, that is, we give several hardness and hardness of approximation results, provide efficient algorithms for some special cases, and more importantly provide heuristics for solving one of the problems in practice. In our experimental study we then first compare the proposed heuristics against each other and establish the most successful one. In a second experiment, we then show that our approach can be very successful in practice. That is, we show that already after adding a few edges to the networks the greedy algorithm that purely maximizes spread surpasses all fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly, we even show that our approach achieves ex-post fairness values that are comparable or even better than the ex-ante fairness values of the currently most efficient algorithms that optimize ex-ante fairness.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
A Fair Incentive Scheme for Community Health Workers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26653), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26653/26425), [keywords](General), [abstract](Abstract
Community health workers (CHWs) play a crucial role in
the last mile delivery of essential health services to underserved
populations in low-income countries. Many nongovernmental
organizations (NGOs) provide training and
support to enable CHWs to deliver health services to their
communities, with no charge to the recipients of the services.
This includes monetary compensation for the work that
CHWs perform, which is broken down into a series of well defined
tasks. In this work, we partner with a NGO D-Tree
International to design a fair monetary compensation scheme
for tasks performed by CHWs in the semi-autonomous region
of Zanzibar in Tanzania, Africa. In consultation with
stakeholders, we interpret fairness as the equal opportunity
to earn, which means that each CHW has the opportunity to
earn roughly the same total payment over a given T month
period, if the CHW reacts to the incentive scheme almost rationally.
We model this problem as a reward design problem
for a Markov Decision Process (MDP) formulation for the
CHWs’ earning. There is a need for the mechanism to be
simple so that it is understood by the CHWs, thus, we explore
linear and piecewise linear rewards in the CHWs’ measured
units of work. We solve this design problem via a novel
policy-reward gradient result. Our experiments using two real
world parameters from the ground provide evidence of reasonable
incentive output by our scheme.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Rehabilitating Homeless- Dataset and Key Insights | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26654), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26654/26426), [keywords](General), [abstract](Abstract
This paper presents a large anonymized dataset of homelessness alongside insights into the data-driven rehabilitation of homeless people. The dataset was gathered by a large non-profit organization working on rehabilitating the homeless for twenty years. This is the first dataset that we know of that contains rich information on thousands of homeless individuals seeking rehabilitation. We show how data analysis can help to make the rehabilitation of homeless people more effective and successful. Thus, we hope this paper alerts the data science community to the problem of homelessness.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Counterfactuals for the Future | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26655), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26655/26427), [keywords](General), [abstract](Abstract
Counterfactuals are often described as 'retrospective,' focusing on hypothetical alternatives to a realized past. This description relates to an often implicit assumption about the structure and stability of exogenous variables in the system being modeled --- an assumption that is reasonable in many settings where counterfactuals are used. In this work, we consider cases where we might reasonably make a different assumption about exogenous variables; namely, that the exogenous noise terms of each unit do exhibit some unit-specific structure and/or stability. This leads us to a different use of counterfactuals --- a forward-looking rather than retrospective counterfactual. We introduce "counterfactual treatment choice," a type of treatment choice problem that motivates using forward-looking counterfactuals. We then explore how mismatches between interventional versus forward-looking counterfactual approaches to treatment choice, consistent with different assumptions about exogenous noise, can lead to counterintuitive results.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Towards Learning to Discover Money Laundering Sub-network in Massive Transaction Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26656), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26656/26428), [keywords](General), [abstract](Abstract
Anti-money laundering (AML) systems play a critical role in safeguarding global economy. As money laundering is considered as one of the top group crimes, there is a crucial need to discover money laundering sub-network behind a particular money laundering transaction for a robust AML system. However, existing rule-based methods for money laundering sub-network discovery is heavily based on domain knowledge and may lag behind the modus operandi of launderers. Therefore, in this work, we first address the money laundering sub-network discovery problem with a neural network based approach, and propose an AML framework AMAP equipped with an adaptive sub-network proposer. In particular, we design an adaptive sub-network proposer guided by a supervised contrastive loss to discriminate money laundering transactions from massive benign transactions. We conduct extensive experiments on real-word datasets in AliPay of Ant Group. The result demonstrates the effectiveness of our AMAP in both money laundering transaction detection and money laundering sub-network discovering. The learned framework which yields money laundering sub-network from massive transaction network leads to a more comprehensive risk coverage and a deeper insight to money laundering strategies.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Estimating Geographic Spillover Effects of COVID-19 Policies from Large-Scale Mobility Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26657), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26657/26429), [keywords](General), [abstract](Abstract
Many policies in the US are determined locally, e.g., at the county-level. Local policy regimes provide flexibility between regions, but may become less effective in the presence of geographic spillovers, where populations circumvent local restrictions by traveling to less restricted regions nearby. Due to the endogenous nature of policymaking, there have been few opportunities to reliably estimate causal spillover effects or evaluate their impact on local policies. In this work, we identify a novel setting and develop a suitable methodology that allow us to make unconfounded estimates of spillover effects of local policies. Focusing on California’s Blueprint for a Safer Economy, we leverage how county-level mobility restrictions were deterministically set by public COVID-19 severity statistics, enabling a regression discontinuity design framework to estimate spillovers between counties. We estimate these effects using a mobility network with billions of timestamped edges and find significant spillover movement, with larger effects in retail, eating places, and gyms. Contrasting local and global policy regimes, our spillover estimates suggest that county-level restrictions are only 54% as effective as statewide restrictions at reducing mobility. However, an intermediate strategy of macro-county restrictions---where we optimize county partitions by solving a minimum k-cut problem on a graph weighted by our spillover estimates---can recover over 90% of statewide mobility reductions, while maintaining substantial flexibility between counties.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26658), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26658/26430), [keywords](General), [abstract](Abstract
Epidemic models are powerful tools in understanding infectious disease. However, as they increase in size and complexity, they can quickly become computationally intractable. Recent progress in modelling methodology has shown that surrogate models can be used to emulate complex epidemic models with a high-dimensional parameter space. We show that deep sequence-to-sequence (seq2seq) models can serve as accurate surrogates for complex epidemic models with sequence based model parameters, effectively replicating seasonal and long-term transmission dynamics. Once trained, our surrogate can predict scenarios a several thousand times faster than the original model, making them ideal for policy exploration. We demonstrate that replacing a traditional epidemic model with a learned simulator facilitates robust Bayesian inference.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Leveraging Old Knowledge to Continually Learn New Classes in Medical Images | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26659), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26659/26431), [keywords](General), [abstract](Abstract
Class-incremental continual learning is a core step towards developing artificial intelligence systems that can continuously adapt to changes in the environment by learning new concepts without forgetting those previously learned. This is especially needed in the medical domain where continually learning from new incoming data is required to classify an expanded set of diseases. In this work, we focus on how old knowledge can be leveraged to learn new classes without catastrophic forgetting. We propose a framework that comprises of two main components: (1) a dynamic architecture with expanding representations to preserve previously learned features and accommodate new features; and (2) a training procedure alternating between two objectives to balance the learning of new features while maintaining the model’s performance on old classes. Experiment results on multiple medical datasets show that our solution is able to achieve superior performance over state-of-the-art baselines in terms of class accuracy and forgetting.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
SARAS-Net- Scale and Relation Aware Siamese Network for Change Detection | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26660), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26660/26432), [keywords](General), [abstract](Abstract
Change detection (CD) aims to find the difference between two images at different times and output a change map to represent whether the region has changed or not. To achieve a better result in generating the change map, many State-of-The-Art (SoTA) methods design a deep learning model that has a powerful discriminative ability. However, these methods still get lower performance because they ignore spatial information and scaling changes between objects, giving rise to blurry boundaries. In addition to these, they also neglect the interactive information of two different images. To alleviate these problems, we propose our network, the Scale and Relation-Aware Siamese Network (SARAS-Net) to deal with this issue. In this paper, three modules are proposed that include relation-aware, scale-aware, and cross-transformer to tackle the problem of scene change detection more effectively.  To verify our model, we tested three public datasets, including LEVIR-CD, WHU-CD, and DSFIN, and obtained SoTA accuracy. Our code is available at https://github.com/f64051041/SARAS-Net.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26661), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26661/26433), [keywords](General), [abstract](Abstract
Knowledge tracing (KT) is a crucial technique to predict students’ future performance by observing their historical learning processes. Due to the powerful representation ability of deep neural networks, remarkable progress has been made by using deep learning techniques to solve the KT problem. The majority of existing approaches rely on the homogeneous question assumption that questions have equivalent contributions if they share the same set of knowledge components. Unfortunately, this assumption is inaccurate in real-world educational scenarios. Furthermore, it is very challenging to interpret the prediction results from the existing deep learning based KT models. Therefore, in this paper, we present QIKT, a question-centric interpretable KT model to address the above challenges. The proposed QIKT approach explicitly models students’ knowledge state variations at a ﬁne-grained level with question-sensitive cognitive representations that are jointly learned from a question-centric knowledge acquisition module and a question-centric problem solving module. Meanwhile, the QIKT utilizes an item response theory based prediction layer to generate interpretable prediction results. The proposed QIKT model is evaluated on three public real-world educational datasets. The results demonstrate that our approach is superior on the KT prediction task, and it outperforms a wide range of deep learning based KT models in terms of prediction accuracy with better model interpretability. To encourage reproducible results, we have provided all the datasets and code at https://pykt.org/.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Critical Firms Prediction for Stemming Contagion Risk in Networked-Loans through Graph-Based Deep Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26662), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26662/26434), [keywords](General), [abstract](Abstract
The networked-loan is major financing support for Micro, Small and Medium-sized Enterprises (MSMEs) in some developing countries. But external shocks may weaken the financial networks' robustness; an accidental default may spread across the network and collapse the whole network. Thus, predicting the critical firms in networked-loans to stem contagion risk and prevent potential systemic financial crises is of crucial significance to the long-term health of inclusive finance and sustainable economic development. Existing approaches in the banking industry dismiss the contagion risk across loan networks and need extensive knowledge with sophisticated financial expertise. Regarding the issues, we propose a novel approach to predict critical firms for stemming contagion risk in the bank industry with deep reinforcement learning integrated with high-order graph message-passing networks. We demonstrate that our approach outperforms the state-of-the-art baselines significantly on the dataset from a large commercial bank. Moreover, we also conducted empirical studies on the real-world loan dataset for risk mitigation. The proposed approach enables financial regulators and risk managers to better track and understands contagion and systemic risk in networked-loans. The superior performance also represents a paradigm shift in addressing the modern challenges in financing support of MSMEs and sustainable economic development.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
GAN-Based Domain Inference Attack | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26663), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26663/26435), [keywords](General), [abstract](Abstract
Model-based attacks can infer training data information from deep neural network models. These attacks heavily depend on the attacker's knowledge of the application domain, e.g., using it to determine the auxiliary data for model-inversion attacks. However, attackers may not know what the model is used for in practice. We propose a generative adversarial network (GAN) based method to explore likely or similar domains of a target model -- the model domain inference (MDI) attack. For a given target (classification) model, we assume that the attacker knows nothing but the input and output formats and can use the model to derive the prediction for any input in the desired form. Our basic idea is to use the target model to affect a GAN training process for a candidate domain's dataset that is easy to obtain. We find that the target model may distort the training procedure less if the domain is more similar to the target domain. We then measure the distortion level with the distance between GAN-generated datasets, which can be used to rank candidate domains for the target model. Our experiments show that the auxiliary dataset from an MDI top-ranked domain can effectively boost the result of model-inversion attacks.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Physics Guided Neural Networks for Time-Aware Fairness- An Application in Crop Yield Prediction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26664), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26664/26436), [keywords](General), [abstract](Abstract
This paper proposes a physics-guided neural network model to predict crop yield and maintain the fairness over space. Failures to preserve the spatial fairness in predicted maps of crop yields can result in biased policies and intervention strategies in the distribution of assistance or subsidies in supporting individuals at risk. Existing methods for fairness enforcement are not designed for capturing the complex physical processes that underlie the crop growing process, and thus are unable to produce good predictions over large regions under different weather conditions and soil properties. More importantly, the fairness is often degraded when existing methods are applied to different years due to the change of weather conditions and farming practices. To address these issues, we propose a physics-guided neural network model, which leverages the physical knowledge from existing physics-based models to guide the extraction of representative physical information and discover the temporal data shift across years. In particular, we use a reweighting strategy to discover the relationship between training years and testing years using the physics-aware representation. Then the physics-guided neural network will be refined via a bi-level optimization process based on the reweighted fairness objective. The proposed method has been evaluated using real county-level crop yield data and simulated data produced by a physics-based model. The results demonstrate that this method can significantly improve the predictive performance and preserve the spatial fairness when generalized to different years.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
“Nothing Abnormal”- Disambiguating Medical Reports via Contrastive Knowledge Infusion | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26665), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26665/26437), [keywords](General), [abstract](Abstract
Sharing medical reports is essential for patient-centered care. A recent line of work has focused on automatically generating reports with NLP methods. However, different audiences have different purposes when writing/reading medical reports – for example, healthcare professionals care more about pathology, whereas patients are more concerned with the diagnosis ("Is there any abnormality?"). The expectation gap results in a common situation where patients find their medical reports to be ambiguous and therefore unsure about the next steps. In this work, we explore the audience expectation gap in healthcare and summarize common ambiguities that lead patients to be confused about their diagnosis into three categories: medical jargon, contradictory findings, and misleading grammatical errors. Based on our analysis, we define a disambiguation rewriting task to regenerate an input to be unambiguous while preserving information about the original content. We further propose a rewriting algorithm based on contrastive pretraining and perturbation-based rewriting. In addition, we create two datasets, OpenI-Annotated based on chest reports and VA-Annotated based on general medical reports, with available binary labels for ambiguity and abnormality presence annotated by radiology specialists. Experimental results on these datasets show that our proposed algorithm effectively rewrites input sentences in a less ambiguous way with high content fidelity. Our code and annotated data will be released to facilitate future research.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
MTDiag- An Effective Multi-Task Framework for Automatic Diagnosis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26666), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26666/26438), [keywords](General), [abstract](Abstract
Automatic diagnosis systems aim to probe for symptoms (i.e., symptom checking) and diagnose disease through multi-turn conversations with patients. Most previous works formulate it as a sequential decision process and use reinforcement learning (RL) to decide whether to inquire about symptoms or make a diagnosis. However, these RL-based methods heavily rely on the elaborate reward function and usually suffer from an unstable training process and low data efficiency. In this work, we propose an effective multi-task framework for automatic diagnosis called MTDiag. We first reformulate symptom checking as a multi-label classification task by direct supervision. Each medical dialogue is equivalently converted into multiple samples for classification, which can also help alleviate the data scarcity problem. Furthermore, we design a multi-task learning strategy to guide the symptom checking procedure with disease information and further utilize contrastive learning to better distinguish symptoms between diseases. Extensive experimental results show that our method achieves state-of-the-art performance on four public datasets with 1.7%~3.1% improvement in disease diagnosis, demonstrating the superiority of the proposed method. Additionally, our model is now deployed in an online medical consultant system as an assistant tool for real-life doctors.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Walkability Optimization- Formulations, Algorithms, and a Case Study of Toronto | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26667), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26667/26439), [keywords](General), [abstract](Abstract
The concept of walkable urban development has gained increased
attention due to its public health, economic, and environmental
sustainability benefits. Unfortunately, land zoning
and historic under-investment have resulted in spatial inequality
in walkability and social inequality among residents.
We tackle the problem of Walkability Optimization through
the lens of combinatorial optimization. The task is to select
locations in which additional amenities (e.g., grocery stores,
schools, restaurants) can be allocated to improve resident access
via walking while taking into account existing amenities
and providing multiple options (e.g., for restaurants).
To this end, we derive Mixed-Integer Linear Programming
(MILP) and Constraint Programming (CP) models. Moreover,
we show that the problem’s objective function is submodular
in special cases, which motivates an efficient greedy
heuristic. We conduct a case study on 31 underserved neighborhoods
in the City of Toronto, Canada. MILP finds the
best solutions in most scenarios but does not scale well with
network size. The greedy algorithm scales well and finds
high-quality solutions. Our empirical evaluation shows that
neighbourhoods with low walkability have a great potential
for transformation into pedestrian-friendly neighbourhoods
by strategically placing new amenities. Allocating 3 additional
grocery stores, schools, and restaurants can improve the
“WalkScore” by more than 50 points (on a scale of 100) for 4
neighbourhoods and reduce the walking distances to amenities
for 75% of all residential locations to 10 minutes for all
amenity types. Our code and paper appendix are available at
https://github.com/khalil-research/walkability.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Low Emission Building Control with Zero-Shot Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26668), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26668/26440), [keywords](General), [abstract](Abstract
Heating and cooling systems in buildings account for 31% of global energy use, much of which are regulated by Rule Based Controllers (RBCs) that neither maximise energy efficiency nor minimise emissions by interacting optimally with the grid. Control via Reinforcement Learning (RL) has been shown to significantly improve building energy efficiency, but existing solutions require access to building-specific simulators or data that cannot be expected for every building in the world. In response, we show it is possible to obtain emission-reducing policies without such knowledge a priori–a paradigm we call zero-shot building control. We combine ideas from system identification and model-based RL to create PEARL (Probabilistic Emission-Abating Reinforcement Learning) and show that a short period of active exploration is all that is required to build a performant model. In experiments across three varied building energy simulations, we show PEARL outperforms an existing RBC once, and popular RL baselines in all cases, reducing building emissions by as much as 31% whilst maintaining thermal comfort. Our source code is available online via: https://enjeeneer.io/projects/pearl/.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26669), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26669/26441), [keywords](General), [abstract](Abstract
Traffic congestion event prediction is an important yet challenging task in intelligent transportation systems. Many existing works about traffic prediction integrate various temporal encoders and graph convolution networks (GCNs), called spatio-temporal graph-based neural networks, which focus on predicting dense variables such as flow, speed and demand in time snapshots, but they can hardly forecast the traffic congestion events that are sparsely distributed on the continuous time axis. In recent years, neural point process (NPP) has emerged as an appropriate framework for event prediction in continuous time scenarios. However, most conventional works about NPP cannot model the complex spatio-temporal dependencies and congestion evolution patterns. To address these limitations, we propose a spatio-temporal graph neural point process framework, named STGNPP for traffic congestion event prediction. Specifically, we first design the spatio-temporal graph learning module to fully capture the long-range spatio-temporal dependencies from the historical traffic state data along with the road network. The extracted spatio-temporal hidden representation and congestion event information are then fed into a continuous gated recurrent unit to model the congestion evolution patterns. In particular, to fully exploit the periodic information, we also improve the intensity function calculation of the point process with a periodic gated mechanism. Finally, our model simultaneously predicts the occurrence time and duration of the next congestion. Extensive experiments on two real-world datasets demonstrate that our method achieves superior performance in comparison to existing state-of-the-art approaches.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Taxonomizing and Measuring Representational Harms- A Look at Image Tagging | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26670), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26670/26442), [keywords](General), [abstract](Abstract
In this paper, we examine computational approaches for measuring the "fairness" of image tagging systems, finding that they cluster into five distinct categories, each with its own analytic foundation. We also identify a range of normative concerns that are often collapsed under the terms "unfairness," "bias," or even "discrimination" when discussing problematic cases of image tagging. Specifically, we identify four types of representational harms that can be caused by image tagging systems, providing concrete examples of each. We then consider how different computational measurement approaches map to each of these types, demonstrating that there is not a one-to-one mapping. Our findings emphasize that no single measurement approach will be definitive and that it is not possible to infer from the use of a particular measurement approach which type of harm was intended to be measured. Lastly, equipped with this more granular understanding of the types of representational harms that can be caused by image tagging systems, we show that attempts to mitigate some of these types of harms may be in tension with one another.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Winning the CityLearn Challenge- Adaptive Optimization with Evolutionary Search under Trajectory-Based Guidance | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26671), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26671/26443), [keywords](General), [abstract](Abstract
Modern power systems will have to face difficult challenges in the years to come: frequent blackouts in urban areas caused by high peaks of electricity demand, grid instability exacerbated by the intermittency of renewable generation, and climate change on a global scale amplified by increasing carbon emissions. While current practices are growingly inadequate, the pathway of artificial intelligence (AI)-based methods to widespread adoption is hindered by missing aspects of trustworthiness. The CityLearn Challenge is an exemplary opportunity for researchers from multi-disciplinary fields to investigate the potential of AI to tackle these pressing issues within the energy domain, collectively modeled as a reinforcement learning (RL) task. Multiple real-world challenges faced by contemporary RL techniques are embodied in the problem formulation. In this paper, we present a novel method using the solution function of optimization as policies to compute the actions for sequential decision-making, while notably adapting the parameters of the optimization model from online observations. Algorithmically, this is achieved by an evolutionary algorithm under a novel trajectory-based guidance scheme. Formally, the global convergence property is established. Our agent ranked first in the latest 2021 CityLearn Challenge, being able to achieve superior performance in almost all metrics while maintaining some key aspects of interpretability.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Robust Planning over Restless Groups- Engagement Interventions for a Large-Scale Maternal Telehealth Program | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26672), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26672/26444), [keywords](General), [abstract](Abstract
In 2020, maternal mortality in India was estimated to be as high as 130 deaths per 100K live births, nearly twice the UN's target. To improve health outcomes, the non-profit ARMMAN sends automated voice messages to expecting and new mothers across India. However, 38% of mothers stop listening to these calls, missing critical preventative care information. To improve engagement, ARMMAN employs health workers to intervene by making service calls, but workers can only call a fraction of the 100K enrolled mothers. Partnering with ARMMAN, we model the problem of allocating limited interventions across mothers as a restless multi-armed bandit (RMAB), where the realities of large scale and model uncertainty present key new technical challenges. We address these with GROUPS, a double oracle–based algorithm for robust planning in RMABs with scalable grouped arms. Robustness over grouped arms requires several methodological advances. First, to adversarially select stochastic group dynamics, we develop a new method to optimize Whittle indices over transition probability intervals. Second, to learn group-level RMAB policy best responses to these adversarial environments, we introduce a weighted index heuristic. Third, we prove a key theoretical result that planning over grouped arms achieves the same minimax regret--optimal strategy as planning over individual arms, under a technical condition. Finally, using real-world data from ARMMAN, we show that GROUPS produces robust policies that reduce minimax regret by up to 50%, halving the number of preventable missed voice messages to connect more mothers with life-saving maternal health information.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Equivariant Message Passing Neural Network for Crystal Material Discovery | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26673), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26673/26445), [keywords](General), [abstract](Abstract
Automatic material discovery with desired properties is a fundamental challenge for material sciences. Considerable attention has recently been devoted to generating stable crystal structures. While existing work has shown impressive success on supervised tasks such as property prediction, the progress on unsupervised tasks such as material generation is still hampered by the limited extent to which the equivalent geometric representations of the same crystal are considered. To address this challenge, we propose EPGNN a periodic equivariant message-passing neural network that learns crystal lattice deformation in an unsupervised fashion. Our model equivalently acts on lattice according to the deformation action that must be performed, making it suitable for crystal generation, relaxation and optimisation. We present experimental evaluations that demonstrate the effectiveness of our approach.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Accurate Fairness- Improving Individual Fairness without Trading Accuracy | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26674), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26674/26446), [keywords](General), [abstract](Abstract
Accuracy and individual fairness are both crucial for trustworthy machine learning, but these two aspects are often incompatible with each other so that enhancing one aspect may sacrifice the other inevitably with side effects of true bias or false fairness. We propose in this paper a new fairness criterion, accurate fairness, to align individual fairness with accuracy. Informally, it requires the treatments of an individual and the individual's similar counterparts to conform to a uniform target, i.e., the ground truth of the individual. We prove that accurate fairness also implies typical group fairness criteria over a union of similar sub-populations. We then present a Siamese fairness in-processing approach to minimize the accuracy and fairness losses of a machine learning model under the accurate fairness constraints. To the best of our knowledge, this is the first time that a Siamese approach is adapted for bias mitigation. We also propose fairness confusion matrix-based metrics, fair-precision, fair-recall, and fair-F1 score, to quantify a trade-off between accuracy and individual fairness. Comparative case studies with popular fairness datasets show that our Siamese fairness approach can achieve on average 1.02%-8.78% higher individual fairness (in terms of fairness through awareness) and 8.38%-13.69% higher accuracy, as well as 10.09%-20.57% higher true fair rate, and 5.43%-10.01% higher fair-F1 score, than the state-of-the-art bias mitigation techniques. This demonstrates that our Siamese fairness approach can indeed improve individual fairness without trading accuracy. Finally, the accurate fairness criterion and Siamese fairness approach are applied to mitigate the possible service discrimination with a real Ctrip dataset, by on average fairly serving 112.33% more customers (specifically, 81.29% more customers in an accurately fair way) than baseline models.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Point-to-Region Co-learning for Poverty Mapping at High Resolution Using Satellite Imagery | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26675), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26675/26447), [keywords](General), [abstract](Abstract
Despite improvements in safe water and sanitation services in low-income countries, a substantial proportion of the population in Africa still does not have access to these essential services. Up-to-date fine-scale maps of low-income settlements are urgently needed by authorities  to improve service provision. We aim to develop a cost-effective solution to generate fine-scale maps of these vulnerable populations using multi-source public information. The problem is challenging as ground-truth maps are available at only a limited number of cities, and the patterns are heterogeneous across cities. Recent attempts tackling the spatial heterogeneity issue focus on scenarios where true labels partially exist for each input region, which are unavailable for the present problem. We propose a dynamic point-to-region co-learning framework to learn heterogeneity patterns that cannot be reflected by point-level information and generalize deep learners to new areas with no labels. We also propose an attention-based correction layer to remove spurious signatures, and a region-gate to capture both region-invariant and variant patterns. Experiment results on real-world fine-scale data in three cities of Kenya show that the proposed approach can largely improve model performance on various base network architectures.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
AirFormer- Predicting Nationwide Air Quality in China with Transformers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26676), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26676/26448), [keywords](General), [abstract](Abstract
Air pollution is a crucial issue affecting human health and livelihoods, as well as one of the barriers to economic growth. Forecasting air quality has become an increasingly important endeavor with significant social impacts, especially in emerging countries. In this paper, we present a novel Transformer termed AirFormer to predict nationwide air quality in China, with an unprecedented fine spatial granularity covering thousands of locations. AirFormer decouples the learning process into two stages: 1) a bottom-up deterministic stage that contains two new types of self-attention mechanisms to efficiently learn spatio-temporal representations; 2) a top-down stochastic stage with latent variables to capture the intrinsic uncertainty of air quality data. We evaluate AirFormer with 4-year data from 1,085 stations in Chinese Mainland. Compared to prior models, AirFormer reduces prediction errors by 5%∼8% on 72-hour future predictions. Our source code is available at https://github.com/yoshall/airformer.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
SimFair- A Unified Framework for Fairness-Aware Multi-Label Classification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26677), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26677/26449), [keywords](General), [abstract](Abstract
Recent years have witnessed increasing concerns towards unfair decisions made by machine learning algorithms. To improve fairness in model decisions, various fairness notions have been proposed and many fairness-aware methods are developed. However, most of existing definitions and methods focus only on single-label classification. Fairness for multi-label classification, where each instance is associated with more than one labels, is still yet to establish. To fill this gap, we study fairness-aware multi-label classification in this paper. We start by extending Demographic Parity (DP) and Equalized Opportunity (EOp), two popular fairness notions, to multi-label classification scenarios. Through a systematic study, we show that on multi-label data, because of unevenly distributed labels, EOp usually fails to construct a reliable estimate on labels with few instances. We then propose a new framework named Similarity s-induced Fairness (sγ -SimFair). This new framework utilizes data that have similar labels when estimating fairness on a particular label group for better stability, and can unify DP and EOp. Theoretical analysis and experimental results on real-world datasets together demonstrate the advantage of sγ -SimFair over existing methods on multi-label classification tasks.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Human Mobility Modeling during the COVID-19 Pandemic via Deep Graph Diffusion Infomax | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26678), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26678/26450), [keywords](General), [abstract](Abstract
Non-Pharmaceutical Interventions (NPIs), such as social gathering restrictions, have shown effectiveness to slow the transmission of COVID-19 by reducing the contact of people. To support policy-makers, multiple studies have first modelled human mobility via macro indicators (e.g., average daily travel distance) and then study the effectiveness of NPIs. In this work, we focus on mobility modelling and, from a micro perspective, aim to predict locations that will be visited by COVID-19 cases. Since NPIs generally cause economic and societal loss, such a prediction benefits governments when they design and evaluate them. However, in real-world situations, strict privacy data protection regulations result in severe data sparsity problems (i.e., limited case and location information).
To address these challenges and jointly model variables including a geometric graph, a set of diffusions and a set of locations, we propose a model named Deep Graph Diffusion Infomax (DGDI). We show the maximization of DGDI can be bounded by two tractable components: a univariate Mutual Information (MI) between geometric graph and diffusion representation, and a univariate MI between diffusion representation and location representation. To facilitate the research of COVID-19 prediction, we present two benchmarks that contain geometric graphs and location histories of COVID-19 cases. Extensive experiments on the two benchmarks show that DGDI significantly outperforms other competing methods.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26679), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26679/26451), [keywords](General), [abstract](Abstract
In computer-aided drug discovery, quantitative structure activity relation models are trained to predict biological activity from chemical structure. Despite the recent success of applying graph neural network to this task, important chemical information such as molecular chirality is ignored. To fill this crucial gap, we propose Molecular-Kernel Graph NeuralNetwork (MolKGNN) for molecular representation learning, which features SE(3)-/conformation invariance, chirality-awareness, and interpretability. For our MolKGNN, we first design a molecular graph convolution to capture the chemical pattern by comparing the atom's similarity with the learnable molecular kernels. Furthermore, we propagate the similarity score to capture the higher-order chemical pattern. To assess the method, we conduct a comprehensive evaluation with nine well-curated datasets spanning numerous important drug targets that feature realistic high class imbalance and it demonstrates the superiority of MolKGNN over other graph neural networks in computer-aided drug discovery. Meanwhile, the learned kernels identify patterns that agree with domain knowledge, confirming the pragmatic interpretability of this approach.  Our code and supplementary material are publicly available at https://github.com/meilerlab/MolKGNN.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Task-Adaptive Meta-Learning Framework for Advancing Spatial Generalizability | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26680), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26680/26452), [keywords](General), [abstract](Abstract
Spatio-temporal machine learning is critically needed for a variety of societal applications, such as agricultural monitoring, hydrological forecast, and traffic management. These applications greatly rely on regional features that characterize spatial and temporal differences. However, spatio-temporal data often exhibit complex patterns and significant data variability across different locations. The labels in many real-world applications can also be limited, which makes it difficult to separately train independent models for different locations. Although meta learning has shown promise in model adaptation with small samples, existing meta learning methods remain limited in handling a large number of heterogeneous tasks, e.g., a large number of locations with varying data patterns. To bridge the gap, we propose task-adaptive formulations and a model-agnostic meta-learning framework that transforms regionally heterogeneous data into location-sensitive meta tasks. We conduct task adaptation following an easy-to-hard task hierarchy in which different meta models are adapted to tasks of different difficulty levels. One major advantage of our proposed method is that it improves the model adaptation to a large number of heterogeneous tasks. It also enhances the model generalization  by automatically adapting the meta model of the corresponding difficulty level to any new tasks. We demonstrate the superiority of our proposed framework over a diverse set of baselines and state-of-the-art meta-learning frameworks. Our extensive experiments on real crop yield data show the effectiveness of the proposed method in handling spatial-related heterogeneous tasks in real societal applications.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
A Composite Multi-Attention Framework for Intraoperative Hypotension Early Warning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26681), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26681/26453), [keywords](General), [abstract](Abstract
Intraoperative hypotension (IOH) events warning plays a crucial role in preventing postoperative complications, such as postoperative delirium and mortality. Despite significant efforts, two fundamental problems limit its wide clinical use. The well-established IOH event warning systems are often built on proprietary medical devices that may not be available in all hospitals. The warnings are also triggered mainly through a predefined IOH event that might not be suitable for all patients. This work proposes a composite multi-attention (CMA) framework to tackle these problems by conducting short-term predictions on user-definable IOH events using vital signals in a low sampling rate with demographic characteristics. Our framework leverages a multi-modal fusion network to make four vital signals and three demographic characteristics as input modalities. For each modality, a multi-attention mechanism is used for feature extraction for better model training. Experiments on two large-scale real-world data sets show that our method can achieve up to 94.1% accuracy on IOH events early warning while the signals sampling rate is reduced by 3000 times. Our proposal CMA can achieve a mean absolute error of 4.50 mm Hg in the most challenging 15-minute mean arterial pressure prediction task and the error reduction by 42.9% compared to existing solutions.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Bugs in the Data- How ImageNet Misrepresents Biodiversity | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26682), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26682/26454), [keywords](General), [abstract](Abstract
ImageNet-1k is a dataset often used for benchmarking machine learning (ML) models and evaluating tasks such as image recognition and object detection. Wild animals make up 27% of ImageNet-1k but, unlike classes representing people and objects, these data have not been closely scrutinized. In the current paper, we analyze the 13,450 images from 269 classes that represent wild animals in the ImageNet-1k validation set, with the participation of expert ecologists. We find that many of the classes are ill-defined or overlapping, and that 12% of the images are incorrectly labeled, with some classes having >90% of images incorrect. We also find that both the wildlife-related labels and images included in ImageNet-1k present significant geographical and cultural biases, as well as ambiguities such as artificial animals, multiple species in the same image, or the presence of humans. Our findings highlight serious issues with the extensive use of this dataset for evaluating ML systems, the use of such algorithms in wildlife-related tasks, and more broadly the ways in which ML datasets are commonly created and curated.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
LUCID- Exposing Algorithmic Bias through Inverse Design | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26683), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26683/26455), [keywords](General), [abstract](Abstract
AI systems can create, propagate, support, and automate bias in decision-making processes. To mitigate biased decisions, we both need to understand the origin of the bias and define what it means for an algorithm to make fair decisions. Most group fairness notions assess a model's equality of outcome by computing statistical metrics on the outputs. We argue that these output metrics encounter intrinsic obstacles and present a complementary approach that aligns with the increasing focus on equality of treatment. By Locating Unfairness through Canonical Inverse Design (LUCID), we generate a canonical set that shows the desired inputs for a model given a preferred output. The canonical set reveals the model's internal logic and exposes potential unethical biases by repeatedly interrogating the decision-making process. We evaluate LUCID on the UCI Adult and COMPAS data sets and find that some biases detected by a canonical set differ from those of output metrics. The results show that by shifting the focus towards equality of treatment and looking into the algorithm's internal workings, the canonical sets are a valuable addition to the toolbox of algorithmic fairness evaluation.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Neighbor Auto-Grouping Graph Neural Networks for Handover Parameter Configuration in Cellular Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26684), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26684/26456), [keywords](General), [abstract](Abstract
The mobile communication enabled by cellular networks is the one of the main foundations of our modern society. Optimizing the performance of cellular networks and providing massive connectivity with improved coverage and user experience has a considerable social and economic impact on our daily life. This performance relies heavily on the configuration of the network parameters. However, with the massive increase in both the size and complexity of cellular networks, network management, especially parameter configuration, is becoming complicated. The current practice, which relies largely on experts' prior knowledge, is not adequate and will require lots of domain experts and high maintenance costs. In this work, we propose a learning-based framework for handover parameter configuration. The key challenge, in this case, is to tackle the complicated dependencies between neighboring cells and jointly optimize the whole network. Our framework addresses this challenge in two ways. First, we introduce a novel approach to imitate how the network responds to different network states and parameter values, called auto-grouping graph convolutional network (AG-GCN). During the parameter configuration stage, instead of solving the global optimization problem, we design a local multi-objective optimization strategy where each cell considers several local performance metrics to balance its own performance and its neighbors. We evaluate our proposed algorithm via a simulator constructed using real network data. We demonstrate that the handover parameters our model can find, achieve better average network throughput compared to those recommended by experts as well as alternative baselines, which can bring better network quality and stability. It has the potential to massively reduce costs arising from human expert intervention and maintenance.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Help Me Heal- A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26685), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26685/26457), [keywords](General), [abstract](Abstract
The potential for conversational agents offering mental health and legal counseling in an autonomous, interactive, and vitally accessible environment is getting highlighted due to the increased access to information through the internet and mobile devices. A counseling conversational agent should be able to offer higher engagement mimicking the real-time counseling sessions. The ability to empathize or comprehend and feel another person’s emotions and experiences is a crucial quality that promotes effective therapeutic bonding and rapport-building. Further, the use of polite encoded language in the counseling reflects the nobility and creates a familiar, warm, and comfortable atmosphere to resolve human issues. Therefore, focusing on these two aspects, we propose a Polite and Empathetic Mental Health and Legal Counseling Dialogue System (Po-Em-MHLCDS) for the victims of crimes. To build Po-Em-MHLCDS, we first create a Mental Health and Legal Counseling Dataset (MHLCD) by recruiting six employees who are asked to converse with each other, acting as a victim and the agent interchangeably following a fixed stated guidelines. Second, the MHLCD dataset is annotated with three informative labels, viz. counseling strategies, politeness, and empathy. Lastly, we train the Po-Em-MHLCDS in a reinforcement learning framework by designing an efficient and effective reward function to reinforce correct counseling strategy, politeness and empathy while maintaining contextual-coherence and non-repetitiveness in the generated responses. Our extensive automatic and human evaluation demonstrate the strength of the proposed system. Codes and Data can be accessed at https://www.iitp.ac.in/ ai-nlp-ml/resources.html#MHLCD or https://github.com/Mishrakshitij/Po-Em-MHLCDS), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Carburacy- Summarization Models Tuning and Comparison in Eco-Sustainable Regimes with a Novel Carbon-Aware Accuracy | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26686), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26686/26458), [keywords](General), [abstract](Abstract
Generative transformer-based models have reached cutting-edge performance in long document summarization. Nevertheless, this task is witnessing a paradigm shift in developing ever-increasingly computationally-hungry solutions, focusing on effectiveness while ignoring the economic, environmental, and social costs of yielding such results. Accordingly, such extensive resources impact climate change and raise barriers to small and medium organizations distinguished by low-resource regimes of hardware and data. As a result, this unsustainable trend has lifted many concerns in the community, which directs the primary efforts on the proposal of tools to monitor models' energy costs. Despite their importance, no evaluation measure considering models' eco-sustainability exists yet. In this work, we propose Carburacy, the first carbon-aware accuracy measure that captures both model effectiveness and eco-sustainability. We perform a comprehensive benchmark for long document summarization, comparing multiple state-of-the-art quadratic and linear transformers on several datasets under eco-sustainable regimes. Finally, thanks to Carburacy, we found optimal combinations of hyperparameters that let models be competitive in effectiveness with significantly lower costs.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Joint Self-Supervised Image-Volume Representation Learning with Intra-inter Contrastive Clustering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26687), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26687/26459), [keywords](General), [abstract](Abstract
Collecting large-scale medical datasets with fully annotated samples for training of deep networks is prohibitively expensive, especially for 3D volume data. Recent breakthroughs in self-supervised learning (SSL) offer the ability to overcome the lack of labeled training samples by learning feature representations from unlabeled data. However, most current SSL techniques in the medical field have been designed for either 2D images or 3D volumes. In practice, this restricts the capability to fully leverage unlabeled data from numerous sources, which may include both 2D and 3D data. Additionally, the use of these pre-trained networks is constrained to downstream tasks with compatible data dimensions.
In this paper, we propose a novel framework for unsupervised joint learning on 2D and 3D data modalities. Given a set of 2D images or 2D slices extracted from 3D volumes, we construct an SSL task based on a 2D contrastive clustering problem for distinct classes. The 3D volumes are exploited by computing vectored embedding at each slice and then assembling a holistic feature through deformable self-attention mechanisms in Transformer, allowing incorporating long-range dependencies between slices inside 3D volumes. These holistic features are further utilized to define a novel 3D clustering agreement-based SSL task and masking embedding prediction inspired by pre-trained language models. Experiments on downstream tasks, such as 3D brain segmentation, lung nodule detection, 3D heart structures segmentation, and abnormal chest X-ray detection, demonstrate the effectiveness of our joint 2D and 3D SSL approach. We improve plain 2D Deep-ClusterV2 and SwAV by a significant margin and also surpass various modern 2D and 3D SSL approaches.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
For the Underrepresented in Gender Bias Research- Chinese Name Gender Prediction with Heterogeneous Graph Attention Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26688), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26688/26460), [keywords](General), [abstract](Abstract
Achieving gender equality is an important pillar for humankind’s sustainable future. Pioneering data-driven gender bias research is based on large-scale public records such as scientific papers, patents, and company registrations, covering female researchers, inventors and entrepreneurs, and so on. Since gender information is often missing in relevant datasets, studies rely on tools to infer genders from names. However, available open-sourced Chinese gender-guessing tools are not yet suitable for scientific purposes, which may be partially responsible for female Chinese being underrepresented in mainstream gender bias research and affect their universality. Specifically, these tools focus on character-level information while overlooking the fact that the combinations of Chinese characters in multi-character names, as well as the components and pronunciations of characters, convey important messages. As a first effort, we design a Chinese Heterogeneous Graph Attention (CHGAT) model to capture the heterogeneity in component relationships and incorporate the pronunciations of characters. Our model largely surpasses current tools and also outperforms the state-of-the-art algorithm. Last but not least, the most popular Chinese name-gender dataset is single-character based with far less female coverage from an unreliable source, naturally hindering relevant studies. We open-source a more balanced multi-character dataset from an official source together with our code, hoping to help future research promoting gender equality.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
FakeSV- A Multimodal Benchmark with Rich Social Context for Fake News Detection on Short Video Platforms | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26689), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26689/26461), [keywords](General), [abstract](Abstract
Short video platforms have become an important channel for news sharing, but also a new breeding ground for fake news. To mitigate this problem, research of fake news video detection has recently received a lot of attention. Existing works face two roadblocks: the scarcity of comprehensive and largescale datasets and insufficient utilization of multimodal information. Therefore, in this paper, we construct the largest Chinese short video dataset about fake news named FakeSV, which includes news content, user comments, and publisher profiles simultaneously. To understand the characteristics of fake news videos, we conduct exploratory analysis of FakeSV from different perspectives. Moreover, we provide a new multimodal detection model named SV-FEND, which exploits the cross-modal correlations to select the most informative features and utilizes the social context information for detection. Extensive experiments evaluate the superiority of the proposed method and provide detailed comparisons of different methods and modalities for future works. Our dataset and codes are available in https://github.com/ICTMCG/FakeSV.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
EINNs- Epidemiologically-Informed Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26690), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26690/26462), [keywords](General), [abstract](Abstract
We introduce EINNs, a framework crafted for epidemic forecasting that builds upon the theoretical grounds provided by mechanistic models as well as the data-driven expressibility afforded by AI models, and their capabilities to ingest heterogeneous information. Although neural forecasting models have been successful in multiple tasks, predictions well-correlated with epidemic trends and long-term predictions remain open challenges. Epidemiological ODE models contain mechanisms that can guide us in these two tasks; however, they have limited capability of ingesting data sources and modeling composite signals. Thus, we propose to leverage work in physics-informed neural networks to learn latent epidemic dynamics and transfer relevant knowledge to another neural network which ingests multiple data sources and has more appropriate inductive bias. In contrast with previous work, we do not assume the observability of complete dynamics and do not need to numerically solve the ODE equations during training. Our thorough experiments on all US states and HHS regions for COVID-19 and influenza forecasting showcase the clear benefits of our approach in both short-term and long-term forecasting as well as in learning the mechanistic dynamics over other non-trivial alternatives.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Counterfactual Fairness Is Basically Demographic Parity | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26691), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26691/26463), [keywords](General), [abstract](Abstract
Making fair decisions is crucial to ethically implementing machine learning algorithms in social settings. In this work, we consider the celebrated definition of counterfactual fairness. We begin by showing that an algorithm which satisfies counterfactual fairness also satisfies demographic parity, a far simpler fairness constraint. Similarly, we show that all algorithms satisfying demographic parity can be trivially modified to satisfy counterfactual fairness. Together, our results indicate that counterfactual fairness is basically equivalent to demographic parity, which has important implications for the growing body of work on counterfactual fairness. We then validate our theoretical findings empirically, analyzing three existing algorithms for counterfactual fairness against three simple benchmarks. We find that two simple benchmark algorithms outperform all three existing algorithms---in terms of fairness, accuracy, and efficiency---on several data sets. Our analysis leads us to formalize a concrete fairness goal: to preserve the order of individuals within protected groups. We believe transparency around the ordering of individuals within protected groups makes fair algorithms more trustworthy. By design, the two simple benchmark algorithms satisfy this goal while the existing algorithms do not.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Detecting Anomalous Networks of Opioid Prescribers and Dispensers in Prescription Drug Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26692), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26692/26464), [keywords](General), [abstract](Abstract
The opioid overdose epidemic represents a serious public health crisis, with fatality rates rising considerably over the past several years. To help address the abuse of prescription opioids, state governments collect data on dispensed prescriptions, yet the use of these data is typically limited to manual searches. In this paper, we propose a novel graph-based framework for detecting anomalous opioid prescribing patterns in state Prescription Drug Monitoring Program (PDMP) data, which could aid governments in deterring opioid diversion and abuse. Specifically, we seek to identify connected networks of opioid prescribers and dispensers who engage in high-risk and possibly illicit activity. We develop and apply a novel extension of the Non-Parametric Heterogeneous Graph Scan (NPHGS) to two years of de-identified PDMP data from the state of Kansas, and find that NPHGS identifies subgraphs that are significantly more anomalous than those detected by other graph-based methods. NPHGS also reveals clusters of potentially illicit activity, which may strengthen state law enforcement and regulatory capabilities. Our paper is the first to demonstrate how prescription data can systematically identify anomalous opioid prescribers and dispensers, as well as illustrating the efficacy of a network-based approach. Additionally, our technical extensions to NPHGS offer both improved flexibility and graph density reduction, enabling the framework to be replicated across jurisdictions and extended to other problem domains.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Practical Disruption of Image Translation Deepfake Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26693), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26693/26465), [keywords](General), [abstract](Abstract
By harnessing the latest advances in deep learning, image-to-image translation architectures have recently achieved impressive capabilities. Unfortunately, the growing representational power of these architectures has prominent unethical uses. Among these, the threats of (1) face manipulation ("DeepFakes") used for misinformation or pornographic use (2) "DeepNude" manipulations of body images to remove clothes from individuals, etc. Several works tackle the task of disrupting such image translation networks by inserting imperceptible adversarial attacks into the input image. Nevertheless, these works have limitations that may result in disruptions that are not practical in the real world. Specifically, most works generate disruptions in a white-box scenario, assuming perfect knowledge about the image translation network. The few remaining works that assume a black-box scenario require a large number of queries to successfully disrupt the adversary's image translation network. In this work we propose Leaking Transferable Perturbations (LTP), an algorithm that significantly reduces the number of queries needed to disrupt an image translation network by dynamically re-purposing previous disruptions into new query efficient disruptions.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Daycare Matching in Japan- Transfers and Siblings | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26694), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26694/26466), [keywords](General), [abstract](Abstract
In this paper, we study a daycare matching problem in Japan and report the design and implementation of a new centralized algorithm, which is going to be deployed in one municipality in the Tokyo metropolis. There are two features that make this market different from the classical hospital-doctor matching problem: i) some children are initially enrolled and prefer to be transferred to other daycare centers; ii) one family may be associated with two or more children and is allowed to submit preferences over combinations of daycare centers. We revisit some well-studied properties including individual rationality, non-wastefulness, as well as stability, and generalize them to this new setting. We design an algorithm based on integer programming (IP) that captures these properties and conduct experiments on five real-life data sets provided by three municipalities. Experimental results show that i) our algorithm performs at least as well as currently used methods in terms of numbers of matched children and blocking coalition; ii) we can find a stable outcome for all instances, although the existence of such an outcome is not guaranteed in theory.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
City-Scale Pollution Aware Traffic Routing by Sampling Max Flows Using MCMC | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26695), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26695/26467), [keywords](General), [abstract](Abstract
A significant cause of air pollution in urban areas worldwide is the high volume of road traffic. Long-term exposure to severe pollution can cause serious health issues. One approach towards tackling this problem is to design a pollution-aware traffic routing policy that balances multiple objectives of i) avoiding extreme pollution in any area ii) enabling short transit times, and iii) making effective use of the road capacities. We propose a novel sampling-based approach for this problem. We give the first construction of a Markov Chain that can sample integer max flow solutions of a planar graph, with theoretical guarantees that the probabilities depend on the aggregate transit length. We designed a traffic policy using diverse samples and simulated traffic on real-world road maps using the SUMO traffic simulator. We observe a considerable decrease in areas with severe pollution when experimented with maps of large cities across the world compared to other approaches.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Weather2vec- Representation Learning for Causal Inference with Non-local Confounding in Air Pollution and Climate Studies | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26696), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26696/26468), [keywords](General), [abstract](Abstract
Estimating the causal effects of a spatially-varying intervention on a spatially-varying outcome may be subject to non-local confounding (NLC), a phenomenon that can bias estimates when the treatments and outcomes of a given unit are dictated in part by the covariates of other nearby units. In particular, NLC is a challenge for evaluating the effects of environmental policies and climate events on health-related outcomes such as air pollution exposure. This paper first formalizes NLC using the potential outcomes framework, providing a comparison with the related phenomenon of causal interference. Then, it proposes a broadly applicable framework, termed weather2vec, that uses the theory of balancing scores to learn representations of non-local information into a scalar or vector defined for each observational unit, which is subsequently used to adjust for confounding in conjunction with causal inference methods. The framework is evaluated in a simulation study and two case studies on air pollution where the weather is an (inherently regional) known confounder.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Evaluating Digital Agriculture Recommendations with Causal Inference | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26697), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26697/26469), [keywords](General), [abstract](Abstract
In contrast to the rapid digitalization of several industries, agriculture suffers from low adoption of smart farming tools. Even though recent advancements in AI-driven digital agriculture can offer high-performing predictive functionalities, they lack tangible quantitative evidence on their benefits to the farmers. Field experiments can derive such evidence, but are often costly, time consuming and hence limited in scope and scale of application. To this end, we propose an observational causal inference framework for the empirical evaluation of the impact of digital tools on target farm performance indicators (e.g., yield in this case). This way, we can increase farmers' trust via enhancing the transparency of the digital agriculture market, and in turn accelerate the adoption of technologies that aim to secure farmer income resilience and global agricultural sustainability against a changing climate. As a case study, we designed and implemented a recommendation system for the optimal sowing time of cotton based on numerical weather predictions, which was used by a farmers' cooperative during the growing season of 2021. We then leverage agricultural knowledge, collected yield data, and environmental information to develop a causal graph of the farm system. Using the back-door criterion, we identify the impact of sowing recommendations on the yield and subsequently estimate it using linear regression, matching, inverse propensity score weighting and meta-learners. The results revealed that a field sown according to our recommendations exhibited a statistically significant yield increase that ranged from 12% to 17%, depending on the method. The effect estimates were robust, as indicated by the agreement among the estimation methods and four successful refutation tests. We argue that this approach can be implemented for decision support systems of other fields, extending their evaluation beyond a performance assessment of internal functionalities.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Everyone’s Voice Matters- Quantifying Annotation Disagreement Using Demographic Information | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26698), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26698/26470), [keywords](General), [abstract](Abstract
In NLP annotation, it is common to have multiple annotators label the text and then obtain the ground truth labels based on major annotators’ agreement. However, annotators are individuals with different backgrounds and various voices. When annotation tasks become subjective, such as detecting politeness, offense, and social norms, annotators’ voices differ and vary. Their diverse voices may represent the true distribution of people’s opinions on subjective matters. Therefore, it is crucial to study the disagreement from annotation to understand which content is controversial from the annotators. In our research, we extract disagreement labels from five subjective datasets, then fine-tune language models to predict annotators’ disagreement. Our results show that knowing annotators’ demographic information (e.g., gender, ethnicity, education level), in addition to the task text, helps predict the disagreement. To investigate the effect of annotators’ demographics on their disagreement level, we simulate different combinations of their artificial demographics and explore the variance of the prediction to distinguish the disagreement from the inherent controversy from text content and the disagreement in the annotators’ perspective. Overall, we propose an innovative disagreement prediction mechanism for better design of the annotation process that will achieve more accurate and inclusive results for NLP systems. Our code and dataset are publicly available.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
MixFairFace- Towards Ultimate Fairness via MixFair Adapter in Face Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26699), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26699/26471), [keywords](General), [abstract](Abstract
Although significant progress has been made in face recognition, demographic bias still exists in face recognition systems. For instance, it usually happens that the face recognition performance for a certain demographic group is lower than the others. In this paper, we propose MixFairFace framework to improve the fairness in face recognition models. First of all, we argue that the commonly used attribute-based fairness metric is not appropriate for face recognition. A face recognition system can only be considered fair while every person has a close performance. Hence, we propose a new evaluation protocol to fairly evaluate the fairness performance of different approaches. Different from previous approaches that require sensitive attribute labels such as race and gender for reducing the demographic bias, we aim at addressing the identity bias in face representation, i.e., the performance inconsistency between different identities, without the need for sensitive attribute labels. To this end, we propose MixFair Adapter to determine and reduce the identity bias of training samples. Our extensive experiments demonstrate that our MixFairFace approach achieves state-of-the-art fairness performance on all benchmark datasets.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
PateGail- A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26700), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26700/26472), [keywords](General), [abstract](Abstract
Generating human mobility trajectories is of great importance to solve the lack of large-scale trajectory data in numerous applications, which is caused by privacy concerns. However, existing mobility trajectory generation methods still require real-world human trajectories centrally collected as the training data, where there exists an inescapable risk of privacy leakage. To overcome this limitation, in this paper, we propose PateGail, a privacy-preserving imitation learning model to generate mobility trajectories, which utilizes the powerful generative adversary imitation learning model to simulate the decision-making process of humans. Further, in order to protect user privacy, we train this model collectively based on decentralized mobility data stored in user devices, where personal discriminators are trained locally to distinguish and reward the real and generated human trajectories. In the training process, only the generated trajectories and their rewards obtained based on personal discriminators are shared between the server and devices, whose privacy is further preserved by our proposed perturbation mechanisms with theoretical proof to satisfy differential privacy. Further, to better model the human decision-making process, we propose a novel aggregation mechanism of the rewards obtained from personal discriminators. We theoretically prove that under the reward obtained based on the aggregation mechanism, our proposed model maximizes the lower bound of the discounted total rewards of users. Extensive experiments show that the trajectories generated by our model are able to resemble real-world trajectories in terms of five key statistical metrics, outperforming state-of-the-art algorithms by over 48.03%. Furthermore, we demonstrate that the synthetic trajectories are able to efficiently support practical applications, including mobility prediction and location recommendation.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Noise Based Deepfake Detection via Multi-Head Relative-Interaction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26701), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26701/26473), [keywords](General), [abstract](Abstract
Deepfake brings huge and potential negative impacts to our daily lives. As the real-life Deepfake videos circulated on the Internet become more authentic, most existing detection algorithms have failed since few visual differences can be observed between an authentic video and a Deepfake one. However, the forensic traces are always retained within the synthesized videos. In this study, we present a noise-based Deepfake detection model, NoiseDF for short, which focuses on the underlying forensic noise traces left behind the Deepfake videos. In particular, we enhance the RIDNet denoiser to extract noise traces and features from the cropped face and background squares of the video image frames. Meanwhile, we devise a novel Multi-Head Relative-Interaction method to evaluate the degree of interaction between the faces and backgrounds that plays a pivotal role in the Deepfake detection task. Besides outperforming the state-of-the-art models, the visualization of the extracted Deepfake forensic noise traces has further displayed the evidence and proved the robustness of our approach.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26702), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26702/26474), [keywords](General), [abstract](Abstract
Credit card fraud incurs a considerable cost for both cardholders and issuing banks. Contemporary methods apply machine learning-based classifiers to detect fraudulent behavior from labeled transaction records. But labeled data are usually a small proportion of billions of real transactions due to expensive labeling costs, which implies that they do not well exploit many natural features from unlabeled data. Therefore, we propose a semi-supervised graph neural network for fraud detection. Specifically, we leverage transaction records to construct a temporal transaction graph, which is composed of temporal transactions (nodes) and interactions (edges) among them. Then we pass messages among the nodes through a Gated Temporal Attention Network (GTAN) to learn the transaction representation. We further model the fraud patterns through risk propagation among transactions. The extensive experiments are conducted on a real-world transaction dataset and two publicly available fraud detection datasets. The result shows that our proposed method, namely GTAN, outperforms other state-of-the-art baselines on three fraud detection datasets. Semi-supervised experiments demonstrate the excellent fraud detection performance of our model with only a tiny proportion of labeled data.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Privacy-Preserved Evolutionary Graph Modeling via Gromov-Wasserstein Autoregression | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26703), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26703/26475), [keywords](General), [abstract](Abstract
Real-world graphs like social networks are often evolutionary over time, whose observations at different timestamps lead to graph sequences. Modeling such evolutionary graphs is important for many applications, but solving this problem often requires the correspondence between the graphs at different timestamps, which may leak private node information, e.g., the temporal behavior patterns of the nodes. We proposed a Gromov-Wasserstein Autoregressive (GWAR) model to capture the generative mechanisms of evolutionary graphs, which does not require the correspondence information and thus preserves the privacy of the graphs' nodes. This model consists of two autoregressions, predicting the number of nodes and the probabilities of nodes and edges, respectively. The model takes observed graphs as its input and predicts future graphs via solving a joint graph alignment and merging task. This task leads to a fused Gromov-Wasserstein (FGW) barycenter problem, in which we approximate the alignment of the graphs based on a novel inductive fused Gromov-Wasserstein (IFGW) distance. The IFGW distance is parameterized by neural networks and can be learned under mild assumptions, thus, we can infer the FGW barycenters without iterative optimization and predict future graphs efficiently. Experiments show that our GWAR achieves encouraging performance in modeling evolutionary graphs in privacy-preserving scenarios.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Auto-CM- Unsupervised Deep Learning for Satellite Imagery Composition and Cloud Masking Using Spatio-Temporal Dynamics | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26704), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26704/26476), [keywords](General), [abstract](Abstract
Cloud masking is both a fundamental and a critical task in the vast majority of Earth observation problems across social sectors, including agriculture, energy, water, etc. The sheer volume of satellite imagery to be processed has fast-climbed to a scale (e.g., >10 PBs/year) that is prohibitive for manual processing. Meanwhile, generating reliable cloud masks and image composite is increasingly challenging due to the continued distribution-shifts in the imagery collected by existing sensors and the ever-growing variety of sensors and platforms. Moreover, labeled samples are scarce and geographically limited compared to the needs in real large-scale applications. In related work, traditional remote sensing methods are often physics-based and rely on special spectral signatures from multi- or hyper-spectral bands, which are often not available in data collected by many -- and especially more recent -- high-resolution platforms. Machine learning and deep learning based methods, on the other hand, often require large volumes of up-to-date training data to be reliable and generalizable over space. We propose an autonomous image composition and masking (Auto-CM) framework to learn to solve the fundamental tasks in a label-free manner, by leveraging different dynamics of events in both geographic domains and time-series. Our experiments show that Auto-CM outperforms existing methods on a wide-range of data with different satellite platforms, geographic regions and bands.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
ERASER- AdvERsArial Sensitive Element Remover for Image Privacy Preservation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26705), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26705/26477), [keywords](General), [abstract](Abstract
The daily practice of online image sharing enriches our lives, but also raises a severe issue of privacy leakage. To mitigate the privacy risks during image sharing, some researchers modify the sensitive elements in images with visual obfuscation methods including traditional ones like blurring and pixelating, as well as generative ones based on deep learning. However, images processed by such methods may be recovered or recognized by models, which cannot guarantee privacy. Further, traditional methods make the images very unnatural with low image quality. Although generative methods produce better images, most of them suffer from insufficiency in the frequency domain, which influences image quality. Therefore, we propose the AdvERsArial Sensitive Element Remover (ERASER) to guarantee both image privacy and image quality. 1) To preserve image privacy, for the regions containing sensitive elements, ERASER guarantees enough difference after being modified in an adversarial way. Specifically, we take both the region and global content into consideration with a Prior Transformer and obtain the corresponding region prior and global prior. Based on the priors, ERASER is trained with an adversarial Difference Loss to make the content in the regions different. As a result, ERASER can reserve the main structure and change the texture of the target regions for image privacy preservation. 2) To guarantee the image quality, ERASER improves the frequency insufficiency of current generative methods. Specifically, the region prior and global prior are processed with Fast Fourier Convolution to capture characteristics and achieve consistency in both pixel and frequency domains. Quantitative analyses demonstrate that the proposed ERASER achieves a balance between image quality and image privacy preservation, while qualitative analyses demonstrate that ERASER indeed reduces the privacy risk from the visual perception aspect.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Deep Learning on a Healthy Data Diet- Finding Important Examples for Fairness | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26706), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26706/26478), [keywords](General), [abstract](Abstract
Data-driven predictive solutions predominant in commercial applications tend to suffer from biases and stereotypes, which raises equity concerns. Prediction models may discover, use, or amplify spurious correlations based on gender or other protected personal characteristics, thus discriminating against marginalized groups. Mitigating gender bias has become an important research focus in natural language processing (NLP) and is an area where annotated corpora are available. Data augmentation reduces gender bias by adding counterfactual examples to the training dataset. In this work, we show that some of the examples in the augmented dataset can be not important or even harmful to fairness. We hence propose a general method for pruning both the factual and counterfactual examples to maximize the model’s fairness as measured by the demographic parity, equality of opportunity, and equality of odds. The fairness achieved by our method surpasses that of data augmentation on three text classification datasets, using no more than half of the examples in the augmented dataset. Our experiments are conducted using models of varying sizes and pre-training settings. WARNING: This work uses language that is offensive in nature.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
On the Effectiveness of Curriculum Learning in Educational Text Scoring | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26707), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26707/26479), [keywords](General), [abstract](Abstract
Automatic Text Scoring (ATS) is a widely-investigated task in education. Existing approaches often stressed the structure design of an ATS model and neglected the training process of the model. Considering the difficult nature of this task, we argued that the performance of an ATS model could be potentially boosted by carefully selecting data of varying complexities in the training process. Therefore, we aimed to investigate the effectiveness of curriculum learning (CL) in scoring educational text. Specifically, we designed two types of difficulty measurers: (i) pre-defined, calculated by measuring a sample's readability, length, the number of grammatical errors or unique words it contains; and (ii) automatic, calculated based on whether a model in a training epoch can accurately score the samples. These measurers were tested in both the easy-to-hard to hard-to-easy training paradigms. Through extensive evaluations on two widely-used datasets (one for short answer scoring and the other for long essay scoring), we demonstrated that (a) CL indeed could boost the performance of state-of-the-art ATS models, and the maximum improvement could be up to 4.5%, but most improvements were achieved when assessing short and easy answers; (b) the pre-defined measurer calculated based on the number of grammatical errors contained in a text sample tended to outperform the other difficulty measurers across different training paradigms.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Censored Fairness through Awareness | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26708), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26708/26480), [keywords](General), [abstract](Abstract
There has been increasing concern within the machine learning community and beyond that Artificial Intelligence (AI) faces a bias and discrimination crisis which needs AI fairness with urgency. As many have begun to work on this problem, most existing work depends on the availability of class label for the given fairness definition and algorithm which may not align with real-world usage. In this work, we study an AI fairness problem that stems from the gap between the design of a "fair" model in the lab and its deployment in the real-world. Specifically, we consider defining and mitigating individual unfairness amidst censorship, where the availability of class label is not always guaranteed due to censorship, which is broadly applicable in a diversity of real-world socially sensitive applications. We show that our method is able to quantify and mitigate individual unfairness in the presence of censorship across three benchmark tasks, which provides the first known results on individual fairness guarantee in analysis of censored data.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
A Continual Pre-training Approach to Tele-Triaging Pregnant Women in Kenya | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26709), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26709/26481), [keywords](General), [abstract](Abstract
Access to high-quality maternal health care services is limited in Kenya, which resulted in ∼36,000 maternal and neonatal deaths in 2018. To tackle this challenge, Jacaranda Health (a non-profit organization working on maternal health in Kenya) developed PROMPTS, an SMS based tele-triage system for pregnant and puerperal women, which has more than 350,000 active users in Kenya. PROMPTS empowers pregnant women living far away from doctors and hospitals to send SMS messages to get quick answers (through human helpdesk agents) to questions about their medical symptoms and pregnancy status. Unfortunately, ∼1.1 million SMS messages are received by PROMPTS every month, which makes it challenging for helpdesk agents to ensure that these messages can be interpreted correctly and evaluated by their level of emergency to ensure timely responses and/or treatments for women in need. This paper reports on a collaborative effort with Jacaranda Health to develop a state-of-the-art natural language processing (NLP) framework, TRIM-AI (TRIage for Mothers using AI), which can automatically predict the emergency level (or severity of medical condition) of a pregnant mother based on the content of their SMS messages. TRIM-AI leverages recent advances in multi-lingual pre-training and continual pre-training to tackle code-mixed SMS messages (between English and Swahili), and achieves a weighted F1 score of 0.774 on real-world datasets. TRIM-AI has been successfully deployed in the field since June 2022, and is being used by Jacaranda Health to prioritize the provision of services and care to pregnant women with the most critical medical conditions. Our preliminary A/B tests in the field show that TRIM-AI is ∼17% more accurate at predicting high-risk medical conditions from SMS messages sent by pregnant Kenyan mothers, which reduces the helpdesk’s workload by ∼12%.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Future Aware Pricing and Matching for Sustainable On-Demand Ride Pooling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26710), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26710/26482), [keywords](General), [abstract](Abstract
The popularity of on-demand ride pooling is owing to the benefits offered to customers (lower prices), taxi drivers (higher revenue), environment (lower carbon footprint due to fewer vehicles) and aggregation companies like Uber (higher revenue). To achieve these benefits, two key interlinked challenges have to be solved effectively: (a) pricing -- setting prices to customer requests for taxis; and (b) matching -- assignment of customers (that accepted the prices) to taxis/cars. Traditionally, both these challenges have been studied individually and using myopic approaches (considering only current requests), without considering the impact of current matching on addressing future requests. In this paper, we develop a novel framework that handles the pricing and matching problems together, while also considering the future impact of the pricing and matching decisions. In our experimental results on a real-world taxi dataset, we demonstrate that our framework can significantly improve revenue (up to 17% and on average 6.4%) in a sustainable manner by reducing the number of vehicles  (up to 14% and on average 10.6%) required to obtain a given fixed revenue and the overall distance travelled by vehicles (up to 11.1% and on average 3.7%). That is to say, we are able to provide an ideal win-win scenario for all stakeholders (customers, drivers, aggregator, environment) involved by obtaining higher revenue for customers, drivers, aggregator (ride pooling company) while being good for the environment (due to fewer number of vehicles on the road and lesser fuel consumed).), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
A Crowd-AI Collaborative Duo Relational Graph Learning Framework towards Social Impact Aware Photo Classification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26711), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26711/26483), [keywords](General), [abstract](Abstract
In artificial intelligence (AI), negative social impact (NSI) represents the negative effect on the society as a result of mistakes conducted by AI agents. While the photo classification problem has been widely studied in the AI community, the NSI made by photo misclassification is largely ignored due to the lack of quantitative measurements of the NSI and effective approaches to reduce it. In this paper, we focus on an NSI-aware photo classification problem where the goal is to develop a novel crowd-AI collaborative learning framework that leverages online crowd workers to quantitatively estimate and effectively reduce the NSI of misclassified photos. Our problem is motivated by the limitations of current NSI-aware photo classification approaches that either 1) cannot accurately estimate NSI because they simply model NSI as the semantic difference between true and misclassified categories or 2) require costly human annotations to estimate NSI of pairwise class categories. To address such limitations, we develop SocialCrowd, a crowdsourcing-based NSI-aware photo classification framework that explicitly reduces the NSI of photo misclassification by designing a duo relational NSI-aware graph with the NSI estimated by online crowd workers. The evaluation results on two large-scale image datasets show that SocialCrowd not only reduces the NSI of photo misclassification but also improves the classification accuracy on both datasets.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
People Taking Photos That Faces Never Share- Privacy Protection and Fairness Enhancement from Camera to User | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26712), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26712/26484), [keywords](General), [abstract](Abstract
The soaring number of personal mobile devices and public cameras poses a threat to fundamental human rights and ethical principles. For example, the stolen of private information such as face image by malicious third parties will lead to catastrophic consequences. By manipulating appearance of face in the image, most of existing protection algorithms are effective but irreversible. Here, we propose a practical and systematic solution to invertiblely protect face information in the full-process pipeline from camera to final users. Specifically, We design a novel lightweight Flow-based Face Encryption Method (FFEM) on the local embedded system privately connected to the camera,  minimizing the risk of  eavesdropping during data transmission. FFEM uses a flow-based face encoder to encode each face to a Gaussian distribution and encrypts the encoded face feature by random rotating the Gaussian distribution with the rotation matrix is as the password. While encrypted latent-variable face  images  are sent to users through public but less reliable channels, password will be protected through more secure channels through technologies such as asymmetric encryption, blockchain, or other sophisticated security schemes. User could select to decode an image with fake faces from the encrypted image on the public channel. Only trusted users are able to recover the original face  using the encrypted matrix transmitted in secure channel. More interestingly, by  tuning Gaussian ball in latent space, we could control the fairness of the replaced face on attributes such as gender and race. Extensive experiments demonstrate that our solution could protect privacy and enhance fairness with minimal effect on high-level downstream task.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
OpenMapFlow- A Library for Rapid Map Creation with Machine Learning and Remote Sensing Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26713), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26713/26485), [keywords](General), [abstract](Abstract
The desired output for most real-world tasks using machine learning (ML) and remote sensing data is a set of dense predictions that form a predicted map for a geographic region. However, most prior work involving ML and remote sensing follows the traditional practice of reporting metrics on a set of independent, geographically-sparse samples and does not perform dense predictions. To reduce the labor of producing dense prediction maps, we present OpenMapFlow---an open-source python library for rapid map creation with ML and remote sensing data. OpenMapFlow provides 1) a data processing pipeline for users to create labeled datasets for any region, 2) code to train state-of-the-art deep learning models on custom or existing datasets, and 3) a cloud-based architecture to deploy models for efficient map prediction. We demonstrate the benefits of OpenMapFlow through experiments on three binary classification tasks: cropland, crop type (maize), and building mapping. We show that OpenMapFlow drastically reduces the time required for dense prediction compared to traditional workflows. We hope this library will stimulate novel research in areas such as domain shift, unsupervised learning, and societally-relevant applications and lessen the barrier to adopting research methods for real-world tasks.), [group](Special Tracks: AAAI Special Track on AI for Social Impact)
Formally Verified SAT-Based AI Planning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26714), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26714/26486), [keywords](General), [abstract](Abstract
We present an executable formally verified SAT encoding of ground classical AI planning problems. We use the theorem prover Isabelle/HOL to perform the verification. We experimentally test the verified encoding and show that it can be used for reasonably sized standard planning benchmarks. We also use it as a reference to test a state-of-the-art SAT-based
planner, showing that it sometimes falsely claims that problems have no solutions of certain lengths.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Shielding in Resource-Constrained Goal POMDPs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26715), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26715/26487), [keywords](General), [abstract](Abstract
We consider partially observable Markov decision processes (POMDPs) modeling an agent that needs a supply of a certain resource (e.g., electricity stored in batteries) to operate correctly. The resource is consumed by the agent's actions and can be replenished only in certain states. The agent aims to minimize the expected cost of reaching some goal while preventing resource exhaustion, a problem we call resource-constrained goal optimization (RSGO). We take a two-step approach to the RSGO problem. First, using formal methods techniques, we design an algorithm computing a shield for a given scenario: a procedure that observes the agent and prevents it from using actions that might eventually lead to resource exhaustion. Second, we augment the POMCP heuristic search algorithm for POMDP planning with our shields to obtain an algorithm solving the RSGO problem. We implement our algorithm and present experiments showing its applicability to benchmarks from the literature.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Implicit Bilevel Optimization- Differentiating through Bilevel Optimization Programming | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26716), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26716/26488), [keywords](General), [abstract](Abstract
Bilevel Optimization Programming is used to model complex and conflicting interactions between agents, for example in Robust AI or Privacy preserving AI. Integrating bilevel mathematical programming within deep learning is thus an essential objective for the Machine Learning community.  
Previously proposed approaches only consider single-level programming. In this paper, we extend existing single-level optimization programming approaches and thus propose Differentiating through Bilevel Optimization Programming (BiGrad) for end-to-end learning of models that use Bilevel Programming as a layer. 
BiGrad has wide applicability and can be used in modern machine learning frameworks. BiGrad is applicable to both continuous and combinatorial Bilevel optimization problems. We describe a class of gradient estimators for the combinatorial case which reduces the requirements in terms of computation complexity; for the case of the continuous variable, the gradient computation takes advantage of the push-back approach (i.e. vector-jacobian product) for an efficient implementation. Experiments show that the BiGrad successfully extends existing single-level approaches to Bilevel Programming.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Query-Based Hard-Image Retrieval for Object Detection at Test Time | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26717), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26717/26489), [keywords](General), [abstract](Abstract
There is a longstanding interest in capturing the error behaviour of object detectors by finding images where their performance is likely to be unsatisfactory. In real-world applications such as autonomous driving, it is also crucial to characterise potential failures beyond simple requirements of detection performance. For example, a missed detection of a pedestrian close to an ego vehicle will generally require closer inspection than a missed detection of a car in the distance. The problem of predicting such potential failures at test time  has largely been overlooked in the literature and conventional approaches based on detection uncertainty fall short in that they are agnostic to such fine-grained characterisation of errors. In this work, we propose to reformulate the problem of finding "hard" images as a query-based hard image retrieval task, where queries are specific definitions of "hardness", and offer a simple and intuitive method that can solve this task for a large family of queries. Our method is entirely post-hoc, does not require ground-truth annotations, is independent of the choice of a detector, and relies on an efficient Monte Carlo estimation that uses a simple stochastic model in place of the ground-truth. We show experimentally that it can be applied successfully to a wide variety of queries for which it can reliably identify hard images for a given detector without any labelled data. We provide results on ranking and classification tasks using the widely used RetinaNet, Faster-RCNN, Mask-RCNN, and Cascade Mask-RCNN object detectors. The code for this project is available at https://github.com/fiveai/hardest.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Probabilities Are Not Enough- Formal Controller Synthesis for Stochastic Dynamical Models with Epistemic Uncertainty | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26718), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26718/26490), [keywords](General), [abstract](Abstract
Capturing uncertainty in models of complex dynamical systems is crucial to designing safe controllers. Stochastic noise causes aleatoric uncertainty, whereas imprecise knowledge of model parameters leads to epistemic uncertainty. Several approaches use formal abstractions to synthesize policies that satisfy temporal specifications related to safety and reachability. However, the underlying models exclusively capture aleatoric but not epistemic uncertainty, and thus require that model parameters are known precisely. Our contribution to overcoming this restriction is a novel abstraction-based controller synthesis method for continuous-state models with stochastic noise and uncertain parameters. By sampling techniques and robust analysis, we capture both aleatoric and epistemic uncertainty, with a user-specified confidence level, in the transition probability intervals of a so-called interval Markov decision process (iMDP). We synthesize an optimal policy on this iMDP, which translates (with the specified confidence level) to a feedback controller for the continuous model with the same performance guarantees. Our experimental benchmarks confirm that accounting for epistemic uncertainty leads to controllers that are more robust against variations in parameter values.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Accelerating Inverse Learning via Intelligent Localization with Exploratory Sampling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26719), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26719/26491), [keywords](General), [abstract](Abstract
In the scope of "AI for Science", solving inverse problems is a longstanding challenge in materials and drug discovery, where the goal is to determine the hidden structures given a set of desirable properties. Deep generative models are recently proposed to solve inverse problems, but these are currently struggling in expensive forward operators, precisely localizing the exact solutions and fully exploring the parameter spaces without missing solutions. In this work, we propose a novel approach (called iPage) to accelerate the inverse learning process by leveraging probabilistic inference from deep invertible models and deterministic optimization via fast gradient descent.  Given a target property, the learned invertible model provides a posterior over the parameter space; we identify these posterior samples as an intelligent prior initialization which enables us to narrow down the search space. We then perform gradient descent to calibrate the inverse solutions within a local region. Meanwhile, a space-filling sampling is imposed on the latent space to better explore and capture all possible solutions. We evaluate our approach on three benchmark tasks and create two datasets of real-world applications from quantum chemistry and additive manufacturing and find our method achieves superior performance compared to several state-of-the-art baseline methods. The iPage code is available at https://github.com/jxzhangjhu/MatDesINNe.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Attention-Conditioned Augmentations for Self-Supervised Anomaly Detection and Localization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26720), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26720/26492), [keywords](General), [abstract](Abstract
Self-supervised anomaly detection and localization are critical to real-world scenarios in which collecting anomalous samples and pixel-wise labeling is tedious or infeasible, even worse when a wide variety of unseen anomalies could surface at test time. Our approach involves a pretext task in the context of masked image modeling, where the goal is to impose agreement between cluster assignments obtained from the representation of an image view containing saliency-aware masked patches and the uncorrupted image view. We harness the self-attention map extracted from the transformer to mask non-salient image patches without destroying the crucial structure associated with the foreground object. Subsequently, the pre-trained model is fine-tuned to detect and localize simulated anomalies generated under the guidance of the transformer's self-attention map. We conducted extensive validation and ablations on the benchmark of industrial images and achieved superior performance against competing methods. We also show the adaptability of our method to the medical images of the chest X-rays benchmark.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robust-by-Design Classification via Unitary-Gradient Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26721), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26721/26493), [keywords](General), [abstract](Abstract
The use of neural networks in safety-critical systems requires safe and robust models, due to the existence of adversarial attacks. Knowing the minimal adversarial perturbation of any input x, or, equivalently, knowing the distance of x from the classification boundary, allows evaluating the classification robustness, providing certifiable predictions. Unfortunately, state-of-the-art techniques for computing such a distance are computationally expensive and hence not suited for online applications. This work proposes a novel family of classifiers, namely Signed Distance Classifiers (SDCs), that, from a theoretical perspective, directly output the exact distance of x from the classification boundary, rather than a probability score (e.g., SoftMax). SDCs represent a family of robust-by-design classifiers. To practically address the theoretical requirements of an SDC, a novel network architecture named Unitary-Gradient Neural Network is presented. Experimental results show that the proposed architecture approximates a signed distance classifier, hence allowing an online certifiable classification of x at the cost of a single inference.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Ensemble-in-One- Ensemble Learning within Random Gated Networks for Enhanced Adversarial Robustness | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26722), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26722/26494), [keywords](General), [abstract](Abstract
Adversarial attacks have threatened modern deep learning systems by crafting adversarial examples with small perturbations to fool the convolutional neural networks (CNNs). To alleviate that, ensemble training methods are proposed to facilitate better adversarial robustness by diversifying the vulnerabilities among the sub-models, simultaneously maintaining comparable natural accuracy as standard training. Previous practices also demonstrate that enlarging the ensemble can improve the robustness. However, conventional ensemble methods are with poor scalability, owing to the rapidly increasing complexity when containing more sub-models in the ensemble. Moreover, it is usually infeasible to train or deploy an ensemble with substantial sub-models, owing to the tight hardware resource budget and latency requirement. In this work, we propose Ensemble-in-One (EIO), a simple but effective method to efficiently enlarge the ensemble with a random gated network (RGN). EIO augments a candidate model by replacing the parametrized layers with multi-path random gated blocks (RGBs) to construct an RGN. The scalability is significantly boosted because the number of paths exponentially increases with the RGN depth. Then by learning from the vulnerabilities of numerous other paths within the RGN, every path obtains better adversarial robustness. Our experiments demonstrate that EIO consistently outperforms previous ensemble training methods with smaller computational overheads, simultaneously achieving better accuracy-robustness trade-offs than adversarial training methods under black-box transfer attacks. Code is available at https://github.com/cai-y13/Ensemble-in-One.git), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Safe Reinforcement Learning via Shielding under Partial Observability | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26723), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26723/26495), [keywords](General), [abstract](Abstract
Safe exploration is a common problem in reinforcement learning (RL) that aims to prevent agents from making disastrous decisions while exploring their environment. A family of approaches to this problem assume domain knowledge in the form of a (partial) model of this environment to decide upon the safety of an action. A so-called shield forces the RL agent to select only safe actions. However, for adoption in various applications, one must look beyond enforcing safety and also ensure the applicability of RL with good performance. We extend the applicability of shields via tight integration with state-of-the-art deep RL, and provide an extensive, empirical study in challenging, sparse-reward environments under partial observability. We show that a carefully integrated shield ensures safety and can improve the convergence rate and final performance of RL agents. We furthermore show that a shield can be used to bootstrap state-of-the-art RL agents: they remain safe after initial learning in a shielded setting, allowing us to disable a potentially too conservative shield eventually.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
PowRL- A Reinforcement Learning Framework for Robust Management of Power Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26724), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26724/26496), [keywords](General), [abstract](Abstract
Power grids, across the world, play an important societal and economical role by providing uninterrupted, reliable and transient-free power to several industries, businesses and household consumers. With the advent of renewable power resources and EVs resulting into uncertain generation and highly dynamic load demands, it has become ever so important to ensure robust operation of power networks through suitable management of transient stability issues and localize the events of blackouts. In the light of ever increasing stress on the modern grid infrastructure and the grid operators, this paper presents a reinforcement learning (RL) framework, PowRL, to mitigate the effects of unexpected network events, as well as reliably maintain electricity everywhere on the network at all times. The PowRL leverages a novel heuristic for overload management, along with the RL-guided decision making on optimal topology selection to ensure that the grid is operated safely and reliably (with no overloads). PowRL is benchmarked on a variety of competition datasets hosted by the L2RPN (Learning to Run a Power Network). Even with its reduced action space, PowRL tops the leaderboard in the L2RPN NeurIPS 2020 challenge (Robustness track) at an aggregate level, while also being the top performing agent in the L2RPN WCCI 2020 challenge. Moreover, detailed analysis depicts state-of-the-art performances by the PowRL agent in some of the test scenarios.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Two Wrongs Don’t Make a Right- Combating Confirmation Bias in Learning with Label Noise | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26725), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26725/26497), [keywords](General), [abstract](Abstract
Noisy labels damage the performance of deep networks.  For robust learning, a prominent two-stage pipeline alternates between eliminating possible incorrect labels and semi-supervised training. However, discarding part of noisy labels could result in a loss of information, especially when the corruption has a dependency on data, e.g., class-dependent or instance-dependent. Moreover, from the training dynamics of a representative two-stage method DivideMix, we identify the domination of confirmation bias: pseudo-labels fail to correct a considerable amount of noisy labels, and consequently, the errors accumulate. To sufficiently exploit information from noisy labels and mitigate wrong corrections, we propose Robust Label Refurbishment (Robust LR)—a new hybrid method that integrates pseudo-labeling and confidence estimation techniques to refurbish noisy labels. We show that our method successfully alleviates the damage of both label noise and confirmation bias. As a result, it achieves state-of-the-art performance across datasets and noise types, namely CIFAR under different levels of synthetic noise and mini-WebVision and ANIMAL-10N with real-world noise.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Testing the Channels of Convolutional Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26726), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26726/26498), [keywords](General), [abstract](Abstract
Neural networks have complex structures, and thus it is hard to understand their inner workings and ensure correctness. To understand and debug convolutional neural networks (CNNs) we propose techniques for testing the channels of CNNs. We design FtGAN, an extension to GAN, that can generate test data with varying the intensity (i.e., sum of the neurons) of a channel of a target CNN. We also proposed a channel selection algorithm to find representative channels for testing. To efficiently inspect the target CNN’s inference computations, we define unexpectedness score, which estimates how similar the inference computation of the test data is to that of the training data. We evaluated FtGAN with five public datasets and showed that our techniques successfully identify defective channels in five different CNN models.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26727), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26727/26499), [keywords](General), [abstract](Abstract
We present a new algorithm to train a robust malware detector. Malware is a prolific problem and malware detectors are a front-line defense. Modern detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional. 
This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness. 
To explain the robustness of the Bayesian adversarial learning algorithm, we prove that our learning method bounds the difference between the adversarial risk and empirical risk and improves robustness. We show that Bayesian neural networks (BNNs) achieve state-of-the-art results; especially in the False Positive Rate (FPR) regime. Adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15% on a recent production-scale malware dataset of more than 20 million samples. Importantly, our efforts create a benchmark for future defenses in the malware domain.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Correct-by-Construction Reinforcement Learning of Cardiac Pacemakers from Duration Calculus Requirements | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26728), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26728/26500), [keywords](General), [abstract](Abstract
As the complexity of pacemaker devices continues to grow, the importance of capturing its functional correctness requirement formally cannot be overestimated. The pacemaker system specification document by \emph{Boston Scientific} provides a widely accepted set of specifications for pacemakers. 
As these specifications are written in a natural language, they are not amenable for automated verification, synthesis, or reinforcement learning of pacemaker systems. This paper presents a formalization of these requirements for a dual-chamber pacemaker in \emph{duration calculus} (DC), a highly expressive real-time specification language.
The proposed formalization allows us to automatically translate pacemaker requirements into executable specifications as stopwatch automata, which can be used to enable simulation, monitoring, validation, verification and automatic synthesis of pacemaker systems. 
The cyclic nature of the pacemaker-heart closed-loop system results in DC requirements that compile to a decidable subclass of stopwatch automata. We present shield reinforcement learning (shield RL),  a shield synthesis based reinforcement learning algorithm, by automatically constructing safety envelopes from DC specifications.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
SafeLight- A Reinforcement Learning Method toward Collision-Free Traffic Signal Control | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26729), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26729/26501), [keywords](General), [abstract](Abstract
Traffic signal control is safety-critical for our daily life. Roughly one-quarter of road accidents in the U.S. happen at intersections due to problematic signal timing, urging the development of safety-oriented intersection control. However, existing studies on adaptive traffic signal control using reinforcement learning technologies have focused mainly on minimizing traffic delay but neglecting the potential exposure to unsafe conditions. We, for the first time, incorporate road safety standards as enforcement to ensure the safety of existing reinforcement learning methods, aiming toward operating intersections with zero collisions. We have proposed a safety-enhanced residual reinforcement learning method (SafeLight) and employed multiple optimization techniques, such as multi-objective loss function and reward shaping for better knowledge integration. Extensive experiments are conducted using both synthetic and real-world benchmark datasets. Results show that our method can significantly reduce collisions while increasing traffic mobility.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
PatchNAS- Repairing DNNs in Deployment with Patched Network Architecture Search | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26730), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26730/26502), [keywords](General), [abstract](Abstract
Despite being widely deployed in safety-critical applications such as autonomous driving and health care, deep neural networks (DNNs) still suffer from non-negligible reliability issues. Numerous works had reported that DNNs were vulnerable to either natural environmental noises or man-made adversarial noises. How to repair DNNs in deployment with noisy samples is a crucial topic for the robustness of neural networks. While many network repairing methods based on data argumentation and weight adjustment have been proposed, they require retraining and redeploying the whole model, which causes high overhead and is infeasible for varying faulty cases on different deployment environments. In this paper, we propose a novel network repairing framework called PatchNAS from the architecture perspective, where we freeze the pretrained DNNs and introduce a small patch network to deal with failure samples at runtime. PatchNAS introduces a novel network instrumentation method to determine the faulty stage of the network structure given the collected failure samples. A small patch network structure is searched unsupervisedly using neural architecture search (NAS) technique with data samples from deployment environment. The patch network repairs the DNNs by correcting the output feature maps of the faulty stage, which helps to maintain network performance on normal samples and enhance robustness in noisy environments. Extensive experiments based on several DNNs across 15 types of natural noises show that the proposed PatchNAS outperforms the state-of-the-arts with significant performance improvement as well as much lower deployment overhead.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Similarity Distribution Based Membership Inference Attack on Person Re-identification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26731), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26731/26503), [keywords](General), [abstract](Abstract
While person Re-identification (Re-ID) has progressed rapidly due to its wide real-world applications, it also causes severe risks of leaking personal information from training data. Thus, this paper focuses on quantifying this risk by membership inference (MI) attack. Most of the existing MI attack algorithms focus on classification models, while Re-ID follows a totally different training and inference paradigm. Re-ID is a fine-grained recognition task with complex feature embedding, and model outputs commonly used by existing MI like logits and losses are not accessible during inference. Since Re-ID focuses on modelling the relative relationship between image pairs instead of individual semantics, we conduct a formal and empirical analysis which validates that the distribution shift of the inter-sample similarity between training and test set is a critical criterion for Re-ID membership inference. As a result, we propose a novel membership inference attack method based on the inter-sample similarity distribution. Specifically, a set of anchor images are sampled to represent the similarity distribution conditioned on a target image, and a neural network with a novel anchor selection module is proposed to predict the membership of the target image. Our experiments validate the effectiveness of the proposed approach on both the Re-ID task and conventional classification task.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Out-of-Distribution Detection Is Not All You Need | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26732), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26732/26504), [keywords](General), [abstract](Abstract
The usage of deep neural networks in safety-critical systems is limited by our ability to guarantee their correct behavior. Runtime monitors are components aiming to identify unsafe predictions and discard them before they can lead to catastrophic consequences. Several recent works on runtime monitoring have focused on out-of-distribution (OOD) detection, i.e., identifying inputs that are different from the training data. In this work, we argue that OOD detection is not a well-suited framework to design efficient runtime monitors and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions. We call this setting out-of-model-scope detection and discuss the conceptual differences with OOD. We also conduct extensive experiments on popular datasets from the literature to show that studying monitors in the OOD setting can be misleading: 1. very good OOD results can give a false impression of safety, 2. comparison under the OOD setting does not allow identifying the best monitor to detect errors. Finally, we also show that removing erroneous training data samples helps to train better monitors.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Contrastive Self-Supervised Learning Leads to Higher Adversarial Susceptibility | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26733), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26733/26505), [keywords](General), [abstract](Abstract
Contrastive self-supervised learning (CSL) has managed to match or surpass the performance of supervised learning in image and video classification. However, it is still largely unknown if the nature of the representations induced by the two learning paradigms is similar. We investigate this under the lens of adversarial robustness. Our analysis of the problem reveals that CSL has intrinsically higher sensitivity to perturbations over supervised learning. We identify the uniform distribution of data representation over a unit hypersphere in the CSL representation space as the key contributor to this phenomenon. We establish that this is a result of the presence of false negative pairs in the training process, which increases model sensitivity to input perturbations. Our finding is supported by extensive experiments for image and video classification using adversarial perturbations and other input corruptions. We devise a strategy to detect and remove false negative pairs that is simple, yet effective in improving model robustness with CSL training. We close up to 68% of the robustness gap between CSL and its supervised counterpart. Finally, we contribute to adversarial learning by incorporating our method in CSL. We demonstrate an average gain of about 5% over two different state-of-the-art methods in this domain.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
AutoCost- Evolving Intrinsic Cost for Zero-Violation Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26734), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26734/26506), [keywords](General), [abstract](Abstract
Safety is a critical hurdle that limits the application of deep reinforcement learning to real-world control tasks. To this end, constrained reinforcement learning leverages cost functions to improve safety in constrained Markov decision process. However, constrained methods fail to achieve zero violation even when the cost limit is zero. This paper analyzes the reason for such failure, which suggests that a proper cost function plays an important role in constrained RL. Inspired by the analysis, we propose AutoCost, a simple yet effective framework that automatically searches for cost functions that help constrained RL to achieve zero-violation performance. We validate the proposed method and the searched cost function on the safety benchmark Safety Gym. We compare the performance of augmented agents that use our cost function to provide additive intrinsic costs to a Lagrangian-based policy learner and a constrained-optimization policy learner with baseline agents that use the same policy learners but with only extrinsic costs. Results show that the converged policies with intrinsic costs in all environments achieve zero constraint violation and comparable performance with baselines.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Test Time Augmentation Meets Post-hoc Calibration- Uncertainty Quantification under Real-World Conditions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26735), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26735/26507), [keywords](General), [abstract](Abstract
Communicating the predictive uncertainty of deep neural networks transparently and reliably is important in many safety-critical applications such as medicine. However, modern neural networks tend to be poorly calibrated, resulting in wrong predictions made with a high confidence. While existing post-hoc calibration methods like temperature scaling or isotonic regression yield strongly calibrated predictions in artificial experimental settings, their efficiency can significantly reduce in real-world applications, where scarcity of labeled data or domain drifts are commonly present. In this paper, we first investigate the impact of these characteristics on post-hoc calibration and introduce an easy-to-implement extension of common post-hoc calibration methods based on test time augmentation. In extensive experiments, we demonstrate that our approach results in substantially better calibration on various architectures. We demonstrate the robustness of our proposed approach on a real-world application for skin cancer classification and show that it facilitates safe decision-making under real-world uncertainties.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robust Training of Neural Networks against Bias Field Perturbations | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26736), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26736/26508), [keywords](General), [abstract](Abstract
We introduce the problem of training neural networks such that they are robust against a class of smooth intensity perturbations modelled by bias fields. We first develop an approach towards this goal based on a state-of-the-art robust training method utilising Interval Bound Propagation (IBP). We analyse the resulting algorithm and observe that IBP often produces very loose bounds for bias field perturbations, which may be detrimental to training. We then propose an alternative approach based on Symbolic Interval Propagation (SIP), which usually results in significantly tighter bounds than IBP. We present ROBNET, a tool implementing these approaches for bias field robust training. In experiments networks trained with the SIP-based approach achieved up to 31% higher certified robustness while also maintaining a better accuracy than networks trained with the IBP approach.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Redactor- A Data-Centric and Individualized Defense against Inference Attacks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26737), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26737/26509), [keywords](General), [abstract](Abstract
Information leakage is becoming a critical problem as various information becomes publicly available by mistake, and machine learning models train on that data to provide services. As a result, one's private information could easily be memorized by such trained models. Unfortunately, deleting information is out of the question as the data is already exposed to the Web or third-party platforms. Moreover, we cannot necessarily control the labeling process and the model trainings by other parties either. In this setting, we study the problem of targeted disinformation generation where the goal is to dilute the data and thus make a model safer and more robust against inference attacks on a specific target (e.g., a person's profile) by only inserting new data. Our method finds the closest points to the target in the input space that will be labeled as a different class. Since we cannot control the labeling process, we instead conservatively estimate the labels probabilistically by combining decision boundaries of multiple classifiers using data programming techniques. Our experiments show that a probabilistic decision boundary can be a good proxy for labelers, and that our approach is effective in defending against inference attacks and can scale to large data.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Improving Adversarial Robustness with Self-Paced Hard-Class Pair Reweighting | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26738), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26738/26510), [keywords](General), [abstract](Abstract
Deep Neural Networks are vulnerable to adversarial attacks. Among many defense strategies, adversarial training with untargeted attacks is one of the most effective methods. Theoretically, adversarial perturbation in untargeted attacks can be added along arbitrary directions and the predicted labels of untargeted attacks should be unpredictable. However, we find that the naturally imbalanced inter-class semantic similarity makes those hard-class pairs become virtual targets of each other. This study investigates the impact of such closely-coupled classes on adversarial attacks and develops a self-paced reweighting strategy in adversarial training accordingly. Specifically, we propose to upweight hard-class pair losses in model optimization, which prompts learning discriminative features from hard classes. We further incorporate a term to quantify hard-class pair consistency in adversarial training, which greatly boosts model robustness. Extensive experiments show that the proposed adversarial training method achieves superior robustness performance over state-of-the-art defenses against a wide range of adversarial attacks. The code of the proposed SPAT is published at https://github.com/puerrrr/Self-Paced-Adversarial-Training.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
CodeAttack- Code-Based Adversarial Attacks for Pre-trained Programming Language Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26739), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26739/26511), [keywords](General), [abstract](Abstract
Pre-trained programming language (PL) models (such as CodeT5, CodeBERT, GraphCodeBERT, etc.,) have the potential to automate software engineering tasks involving code understanding and code generation. However, these models operate in the natural channel of code, i.e., primarily concerned with the human understanding of code. They are not robust to changes in the input and thus, are potentially susceptible to adversarial attacks in the natural channel. We propose, Code Attack, a simple yet effective black-box attack model that uses code structure to generate effective, efficient, and imperceptible adversarial code samples and demonstrates the vulnerabilities of the state-of-the-art PL models to code-specific adversarial attacks. We evaluate the transferability of CodeAttack on several code-code (translation and repair) and code-NL (summarization) tasks across different programming languages. Code Attack outperforms state-of-the-art adversarial NLP attack models to achieve the best overall drop in performance while being more efficient, imperceptible, consistent, and fluent. The code can be found at https://github.com/reddy-lab-code-research/CodeAttack.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Formalising the Robustness of Counterfactual Explanations for Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26740), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26740/26512), [keywords](General), [abstract](Abstract
The use of counterfactual explanations (CFXs) is an increasingly popular explanation strategy for machine learning models. However, recent studies have shown that these explanations may not be robust to changes in the underlying model (e.g., following retraining), which raises questions about their reliability in real-world applications. Existing attempts towards solving this problem are heuristic, and the robustness to model changes of the resulting CFXs is evaluated with only a small number of retrained models, failing to provide exhaustive guarantees. To remedy this, we propose ∆-robustness, the first notion to formally and deterministically assess the robustness (to model changes) of CFXs for neural networks. We introduce an abstraction framework based on interval neural networks 
to verify the ∆-robustness of CFXs against a possibly infinite set of changes to the model parameters, i.e., weights and biases. We then demonstrate the utility of this approach in two distinct ways. First, we  analyse the ∆-robustness of a number of CFX generation methods from the literature and show that they unanimously host significant deficiencies in this regard. Second, we demonstrate how embedding ∆-robustness within existing methods can provide CFXs which are provably robust.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
READ- Aggregating Reconstruction Error into Out-of-Distribution Detection | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26741), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26741/26513), [keywords](General), [abstract](Abstract
Detecting out-of-distribution (OOD) samples is crucial to the safe deployment of a classifier in the real world. However, deep neural networks are known to be overconfident for abnormal data. Existing works directly design score function by mining the inconsistency from classifier for in-distribution (ID) and OOD. In this paper, we further complement this inconsistency with reconstruction error, based on the assumption that an autoencoder trained on ID data cannot reconstruct OOD as well as ID. We propose a novel method, READ (Reconstruction Error Aggregated Detector), to unify inconsistencies from classifier and autoencoder. Specifically, the reconstruction error of raw pixels is transformed to latent space of classifier. We show that the transformed reconstruction error bridges the semantic gap and inherits detection performance from the original. Moreover, we propose an adjustment strategy to alleviate the overconfidence problem of autoencoder according to a fine-grained characterization of OOD data. Under two scenarios of pre-training and retraining, we respectively present two variants of our method, namely READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED (Euclidean Distance) which retrains the classifier. Our methods do not require access to test time OOD data for fine-tuning hyperparameters. Finally, we demonstrate the effectiveness of the proposed methods through extensive comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10 pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8% compared with previous state-of-the-art.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Sample-Dependent Adaptive Temperature Scaling for Improved Calibration | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26742), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26742/26514), [keywords](General), [abstract](Abstract
It is now well known that neural networks can be wrong with high confidence in their predictions, leading to poor calibration. The most common post-hoc approach to compensate for this is to perform temperature scaling, which adjusts the confidences of the predictions on any input by scaling the logits by a fixed value. Whilst this approach typically improves the average calibration across the whole test dataset, this improvement typically reduces the individual confidences of the predictions irrespective of whether the classification of a given input is correct or incorrect. With this insight, we base our method on the observation that different samples contribute to the calibration error by varying amounts, with some needing to increase their confidence and others needing to decrease it. Therefore, for each input, we propose to predict a different temperature value, allowing us to adjust the mismatch between confidence and accuracy at a finer granularity. Our method is applied post-hoc, enabling it to be very fast with a negligible memory footprint and is applied to off-the-shelf pre-trained classifiers. We test our method on the ResNet50 and WideResNet28-10 architectures using the CIFAR10/100 and Tiny-ImageNet datasets, showing that producing per-data-point temperatures improves the expected calibration error across the whole test set.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Heuristic Search in Dual Space for Constrained Fixed-Horizon POMDPs with Durative Actions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26743), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26743/26515), [keywords](General), [abstract](Abstract
The Partially Observable Markov Decision Process (POMDP) is widely used in probabilistic planning for stochastic domains. However, current extensions, such as constrained and chance-constrained POMDPs, have limitations in modeling real-world planning problems because they assume that all actions have a fixed duration. To address this issue, we propose a unified model that encompasses durative POMDP and its constrained extensions. To solve the durative POMDP and its constrained extensions, we first convert them into an Integer Linear Programming (ILP) formulation. This approach leverages existing solvers in the ILP literature and provides a foundation for solving these problems. We then introduce a heuristic search approach that prunes the search space, which is guided by solving successive partial ILP programs. Our empirical evaluation results show that our approach outperforms the current state-of-the-art fixed-horizon chance-constrained POMDP solver.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Iteratively Enhanced Semidefinite Relaxations for Efficient Neural Network Verification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26744), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26744/26516), [keywords](General), [abstract](Abstract
We propose an enhanced semidefinite program (SDP) relaxation to enable the tight and efficient verification of neural networks (NNs). The tightness improvement is achieved by introducing a nonlinear constraint to existing SDP relaxations previously proposed for NN verification. The efficiency of the proposal stems from the iterative nature of the proposed algorithm in that it solves the resulting non-convex SDP by recursively solving auxiliary convex layer-based SDP problems. We show formally that the solution generated by our algorithm is tighter than state-of-the-art SDP-based solutions for the problem. We also show that the solution sequence converges to the optimal solution of the non-convex enhanced SDP relaxation. The experimental results on standard benchmarks in the area show that our algorithm achieves the state-of-the-art performance whilst maintaining an acceptable computational cost.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
A Semidefinite Relaxation Based Branch-and-Bound Method for Tight Neural Network Verification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26745), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26745/26517), [keywords](General), [abstract](Abstract
We introduce a novel method based on semidefinite program (SDP) for the tight and efficient verification of neural networks. The proposed SDP relaxation advances the present state of the art in SDP-based neural network verification by adding a set of linear constraints based on eigenvectors. We extend this novel SDP relaxation by combining it with a branch-and-bound method that can provably close the relaxation gap up to zero. We show formally that the proposed approach leads to a provably tighter solution than the present state of the art. We report experimental results showing that the proposed method outperforms baselines in terms of verified accuracy while retaining an acceptable computational overhead.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robust Image Steganography- Hiding Messages in Frequency Coefficients | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26746), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26746/26518), [keywords](General), [abstract](Abstract
Steganography is a technique that hides secret messages into a public multimedia object without raising suspicion from third parties. However, most existing works cannot provide good robustness against lossy JPEG compression while maintaining a relatively large embedding capacity. This paper presents an end-to-end robust steganography system based on the invertible neural network (INN). Instead of hiding in the spatial domain, our method directly hides secret messages into the discrete cosine transform (DCT) coefficients of the cover image, which significantly improves the robustness and anti-steganalysis security. A mutual information loss is first proposed to constrain the flow of information in INN. Besides, a two-way fusion module (TWFM) is implemented, utilizing spatial and DCT domain features as auxiliary information to facilitate message extraction. These two designs aid in recovering secret messages from the DCT coefficients losslessly. Experimental results demonstrate that our method yields significantly lower error rates than other existing hiding methods. For example, our method achieves reliable extraction with 0 error rate for 1 bit per pixel (bpp) embedding payload; and under the JPEG compression with quality factor QF=10, the error rate of our method is about 22% lower than the state-of-the-art robust image hiding methods, which demonstrates remarkable robustness against JPEG compression.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Quantization-Aware Interval Bound Propagation for Training Certifiably Robust Quantized Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26747), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26747/26519), [keywords](General), [abstract](Abstract
We study the problem of training and certifying adversarially robust quantized neural networks (QNNs). Quantization is a technique for making neural networks more efficient by running them using low-bit integer arithmetic and is therefore commonly adopted in industry. Recent work has shown that floating-point neural networks that have been verified to be robust can become vulnerable to adversarial attacks after quantization, and certification of the quantized representation is necessary to guarantee robustness.
In this work, we present quantization-aware interval bound propagation (QA-IBP), a novel method for training robust QNNs.
Inspired by advances in robust learning of non-quantized networks, our training algorithm computes the gradient of an abstract representation of the actual network. Unlike existing approaches, our method can handle the discrete semantics of QNNs. 
Based on QA-IBP, we also develop a complete verification procedure for verifying the adversarial robustness of QNNs, which is guaranteed to terminate and produce a correct answer. Compared to existing approaches, the key advantage of our verification procedure is that it runs entirely on GPU or other accelerator devices. 
We demonstrate experimentally that our approach significantly outperforms existing methods and establish the new state-of-the-art for training and certifying the robustness of QNNs.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Revisiting the Importance of Amplifying Bias for Debiasing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26748), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26748/26520), [keywords](General), [abstract](Abstract
In image classification, debiasing aims to train a classifier to be less susceptible to dataset bias, the strong correlation between peripheral attributes of data samples and a target class. For example, even if the frog class in the dataset mainly consists of frog images with a swamp background (i.e., bias aligned samples), a debiased classifier should be able to correctly classify a frog at a beach (i.e., bias conflicting samples). Recent debiasing approaches commonly use two components for debiasing, a biased model fB and a debiased model fD. fB is trained to focus on bias aligned samples (i.e., overfitted to the bias) while fD is mainly trained with bias conflicting samples by concentrating on samples which fB fails to learn, leading fD to be less susceptible to the dataset bias. While the state of the art debiasing techniques have aimed to better train fD, we focus on training fB, an overlooked component until now. Our empirical analysis reveals that removing the bias conflicting samples from the training set for fB is important for improving the debiasing performance of fD. This is due to the fact that the bias conflicting samples work as noisy samples for amplifying the bias for fB since those samples do not include the bias attribute. To this end, we propose a simple yet effective data sample selection method which removes the bias conflicting samples to construct a bias amplified dataset for training fB. Our data sample selection method can be directly applied to existing reweighting based debiasing approaches, obtaining consistent performance boost and achieving the state of the art performance on both synthetic and real-world datasets.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
WAT- Improve the Worst-Class Robustness in Adversarial Training | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26749), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26749/26521), [keywords](General), [abstract](Abstract
Deep Neural Networks (DNN) have been shown to be vulnerable to adversarial examples. Adversarial training (AT) is a popular and effective strategy to defend against adversarial attacks. Recent works have shown that a robust model well-trained by AT exhibits a remarkable robustness disparity among classes, and propose various methods to obtain consistent robust accuracy across classes. Unfortunately, these methods sacrifice a good deal of the average robust accuracy. Accordingly, this paper proposes a novel framework of worst-class adversarial training and leverages no-regret dynamics to solve this problem. Our goal is to obtain a classifier with great performance on worst-class and sacrifice just a little average robust accuracy at the same time. We then rigorously analyze the theoretical properties of our proposed algorithm, and the generalization error bound in terms of the worst-class robust risk. Furthermore, we propose a measurement to evaluate the proposed method in terms of both the average and worst-class accuracies. Experiments on various datasets and networks show that our proposed method outperforms the state-of-the-art approaches.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
PLMmark- A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26750), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26750/26522), [keywords](General), [abstract](Abstract
The huge training overhead, considerable commercial value, and various potential security risks make it urgent to protect the intellectual property (IP) of Deep Neural Networks (DNNs). DNN watermarking has become a plausible method to meet this need. However, most of the existing watermarking schemes focus on image classification tasks. The schemes designed for the textual domain lack security and reliability. Moreover, how to protect the IP of widely-used pre-trained language models (PLMs) remains a blank. 
To fill these gaps, we propose PLMmark, the first secure and robust black-box watermarking framework for PLMs. It consists of three phases: (1) In order to generate watermarks that contain owners’ identity information, we propose a novel encoding method to establish a strong link between a digital signature and trigger words by leveraging the original vocabulary tables of PLMs. Combining this with public key cryptography ensures the security of our scheme. (2) To embed robust, task-agnostic, and highly transferable watermarks in PLMs, we introduce a supervised contrastive loss to deviate the output representations of trigger sets from that of clean samples. In this way, the watermarked models will respond to the trigger sets anomaly and thus can identify the ownership. (3) To make the model ownership verification results reliable, we perform double verification, which guarantees the unforgeability of ownership. Extensive experiments on text classification tasks demonstrate that the embedded watermark can transfer to all the downstream tasks and can be effectively extracted and verified. The watermarking scheme is robust to watermark removing attacks (fine-pruning and re-initializing) and is secure enough to resist forgery attacks.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Rethinking Label Refurbishment- Model Robustness under Label Noise | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26751), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26751/26523), [keywords](General), [abstract](Abstract
A family of methods that generate soft labels by mixing the hard labels with a certain distribution, namely label refurbishment, are widely used to train deep neural networks. However, some of these methods are still poorly understood in the presence of label noise. In this paper, we revisit four label refurbishment methods and reveal the strong connection between them. We find that they affect the neural network models in different manners. Two of them smooth the estimated posterior for regularization effects, and the other two force the model to produce high-confidence predictions. We conduct extensive experiments to evaluate related methods and observe that both effects improve the model generalization under label noise. Furthermore, we theoretically show that both effects lead to generalization guarantees on the clean distribution despite being trained with noisy labels.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
A Holistic Approach to Undesired Content Detection in the Real World | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26752), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26752/26524), [keywords](General), [abstract](Abstract
We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation. The success of such a system relies on a chain of carefully designed and executed steps, including the design of content taxonomies and labeling instructions, data quality control, an active learning pipeline to capture rare events, and a variety of methods to make the model robust and to avoid overfitting. Our moderation system is trained to detect a broad set of categories of undesired content, including sexual content, hateful content, violence, self-harm, and harassment. This approach generalizes to a wide range of different content taxonomies and can be used to create high-quality content classifiers that outperform off-the-shelf models.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
A Risk-Sensitive Approach to Policy Optimization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26753), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26753/26525), [keywords](General), [abstract](Abstract
Standard deep reinforcement learning (DRL) aims to maximize expected reward, considering collected experiences equally in formulating a policy. This differs from human decision-making, where gains and losses are valued differently and outlying outcomes are given increased consideration.  It also fails to capitalize on opportunities to improve safety and/or performance through the incorporation of distributional context. Several approaches to distributional DRL have been investigated, with one popular strategy being to evaluate the projected distribution of returns for possible actions.  We propose a more direct approach whereby risk-sensitive objectives, specified in terms of the cumulative distribution function (CDF) of the distribution of full-episode rewards, are optimized. This approach allows for outcomes to be weighed based on relative quality, can be used for both continuous and discrete action spaces, and may naturally be applied in both constrained and unconstrained settings.  We show how to compute an asymptotically consistent estimate of the policy gradient for a broad class of risk-sensitive objectives via sampling, subsequently incorporating variance reduction and regularization measures to facilitate effective on-policy learning.  We then demonstrate that the use of moderately "pessimistic" risk profiles, which emphasize scenarios where the agent performs poorly, leads to enhanced exploration and a continual focus on addressing deficiencies.  We test the approach using different risk profiles in six OpenAI Safety Gym environments, comparing to state of the art on-policy methods.  Without cost constraints, we find that pessimistic risk profiles can be used to reduce cost while improving total reward accumulation.  With cost constraints, they are seen to provide higher positive rewards than risk-neutral approaches at the prescribed allowable cost.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Anonymization for Skeleton Action Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26754), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26754/26526), [keywords](General), [abstract](Abstract
Skeleton-based action recognition attracts practitioners and researchers due to the lightweight, compact nature of datasets. Compared with RGB-video-based action recognition, skeleton-based action recognition is a safer way to protect the privacy of subjects while having competitive recognition performance. However, due to improvements in skeleton recognition algorithms as well as motion and depth sensors, more details of motion characteristics can be preserved in the skeleton dataset, leading to potential privacy leakage. We first train classifiers to categorize private information from skeleton trajectories to investigate the potential privacy leakage from skeleton datasets. Our preliminary experiments show that the gender classifier achieves 87% accuracy on average, and the re-identification classifier achieves 80% accuracy on average with three baseline models: Shift-GCN, MS-G3D, and 2s-AGCN. We propose an anonymization framework based on adversarial learning to protect potential privacy leakage from the skeleton dataset. Experimental results show that an anonymized dataset can reduce the risk of privacy leakage while having marginal effects on action recognition performance even with simple anonymizer architectures. The code used in our experiments is available at https://github.com/ml-postech/Skeleton-anonymization/), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Monitoring Model Deterioration with Explainable Uncertainty Estimation via Non-parametric Bootstrap | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26755), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26755/26527), [keywords](General), [abstract](Abstract
Monitoring machine learning models once they are deployed
is challenging. It is even more challenging to decide when
to retrain models in real-case scenarios when labeled data is
beyond reach, and monitoring performance metrics becomes
unfeasible. In this work, we use non-parametric bootstrapped
uncertainty estimates and SHAP values to provide explainable
uncertainty estimation as a technique that aims to monitor
the deterioration of machine learning models in deployment
environments, as well as determine the source of model deteri-
oration when target labels are not available. Classical methods
are purely aimed at detecting distribution shift, which can lead
to false positives in the sense that the model has not deterio-
rated despite a shift in the data distribution. To estimate model
uncertainty we construct prediction intervals using a novel
bootstrap method, which improves previous state-of-the-art
work. We show that both our model deterioration detection
system as well as our uncertainty estimation method achieve
better performance than the current state-of-the-art. Finally,
we use explainable AI techniques to gain an understanding
of the drivers of model deterioration. We release an open
source Python package, doubt, which implements our pro-
posed methods, as well as the code used to reproduce our
experiments.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26756), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26756/26528), [keywords](General), [abstract](Abstract
Cooperative multi-agent reinforcement learning (c-MARL) is widely applied in safety-critical scenarios, thus the analysis of robustness for c-MARL models is profoundly important. However, robustness certification for c-MARLs has not yet been explored in the community. In this paper, we propose a novel certification method, which is the first work to leverage a scalable approach for c-MARLs to determine actions with guaranteed certified bounds. c-MARL certification poses two key challenges compared to single-agent systems:  (i) the accumulated uncertainty as the number of agents increases; (ii) the potential lack of impact when changing the action of a single agent into a global team reward. These challenges prevent us from directly using existing algorithms. Hence, we employ the false discovery rate (FDR) controlling procedure considering the importance of each agent to certify per-state robustness. We further propose a tree-search-based algorithm to find a lower bound of the global reward under the minimal certified perturbation. As our method is general, it can also be applied in a single-agent environment. We empirically show that our certification bounds are much tighter than those of state-of-the-art RL certification solutions. We also evaluate our method on two popular c-MARL algorithms: QMIX and VDN, under two different environments, with two and four agents. The experimental results show that our method can certify the robustness of all c-MARL models in various environments. Our tool CertifyCMARL is available at https://github.com/TrustAI/CertifyCMARL.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Constrained Reinforcement Learning in Hard Exploration Problems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26757), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26757/26529), [keywords](General), [abstract](Abstract
One approach to guaranteeing safety in Reinforcement Learning is through cost constraints that are dependent on the policy. Recent works in constrained RL have developed methods that ensure  constraints are enforced even at learning time while maximizing the overall value of the policy. Unfortunately, as demonstrated in our experimental results, such approaches do not perform well on complex multi-level tasks, with longer episode lengths or sparse rewards. To that end, we propose a scalable hierarchical approach for constrained RL problems that employs backward cost value functions in the context of task hierarchy and a novel intrinsic reward function in lower levels of the hierarchy to enable cost constraint enforcement. One of our key contributions is in proving that backward value functions are theoretically viable even when there are multiple levels of decision making. We also show that our new approach, referred to as Hierarchically Limited consTraint Enforcement (HiLiTE) significantly improves on state of the art Constrained RL approaches for many  benchmark problems from literature. We further demonstrate that this performance (on value and constraint enforcement) clearly outperforms existing best approaches for constrained RL and hierarchical RL.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Defending from Physically-Realizable Adversarial Attacks through Internal Over-Activation Analysis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26758), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26758/26530), [keywords](General), [abstract](Abstract
This work presents Z-Mask, an effective and deterministic strategy to improve the adversarial robustness of convolutional networks against physically-realizable adversarial attacks.
The presented defense relies on specific Z-score analysis performed on the internal network features to detect and mask the pixels corresponding to adversarial objects in the input image. To this end, spatially contiguous activations are examined in shallow and deep layers to suggest potential adversarial regions. Such proposals are then aggregated through a multi-thresholding mechanism.
The effectiveness of Z-Mask is evaluated with an extensive set of experiments carried out on models for semantic segmentation and object detection. The evaluation is performed with both digital patches added to the input images and printed patches in the real world.
The results confirm that Z-Mask outperforms the state-of-the-art methods in terms of detection accuracy and overall performance of the networks under attack.
Furthermore, Z-Mask preserves its robustness against defense-aware attacks, making it suitable for safe and secure AI applications.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Formally Verified Solution Methods for Markov Decision Processes | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26759), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26759/26531), [keywords](General), [abstract](Abstract
We formally verify executable algorithms for solving Markov decision processes (MDPs) in the interactive theorem prover Isabelle/HOL. We build on existing formalizations of probability theory to analyze the expected total reward criterion on finite and infinite-horizon problems. Our developments formalize the Bellman equation and give conditions under which optimal policies exist. Based on this analysis, we verify dynamic programming algorithms to solve tabular MDPs. We evaluate the formally verified implementations experimentally on standard problems, compare them with state-of-the-art systems, and show that they are practical.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Improving Training and Inference of Face Recognition Models via Random Temperature Scaling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26760), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26760/26532), [keywords](General), [abstract](Abstract
Data uncertainty is commonly observed in the images for face recognition (FR). However, deep learning algorithms often make predictions with high confidence even for uncertain or irrelevant inputs. Intuitively, FR algorithms can benefit from both the estimation of uncertainty and the detection of out-of-distribution (OOD) samples. Taking a probabilistic view of the current classification model, the temperature scalar is exactly the scale of uncertainty noise implicitly added in the softmax function. Meanwhile, the uncertainty of images in a dataset should follow a prior distribution. Based on the observation, a unified framework for uncertainty modeling and FR, Random Temperature Scaling (RTS), is proposed to learn a reliable FR algorithm. The benefits of RTS are two-fold. (1) In the training phase, it can adjust the learning strength of clean and noisy samples for stability and accuracy. (2) In the test phase, it can provide a score of confidence to detect uncertain, low-quality and even OOD samples, without training on extra labels. Extensive experiments on FR benchmarks demonstrate that the magnitude of variance in RTS, which serves as an OOD detection metric, is closely related to the uncertainty of the input image. RTS can achieve top performance on both the FR and OOD detection tasks. Moreover, the model trained with RTS can perform robustly on datasets with noise. The proposed module is light-weight and only adds negligible computation cost to the model.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Task and Model Agnostic Adversarial Attack on Graph Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26761), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26761/26533), [keywords](General), [abstract](Abstract
Adversarial attacks on Graph Neural Networks (GNNs) reveal their security vulnerabilities, limiting their adoption in safety-critical applications. However, existing attack strategies rely on the knowledge of either the GNN model being used or the predictive task being attacked. Is this knowledge necessary? For example, a graph may be used for multiple downstream tasks unknown to a practical attacker. It is thus important to test the vulnerability of GNNs to adversarial perturbations in a model and task-agnostic setting. In this work, we study this problem and show that Gnns remain vulnerable even when the downstream task and model are unknown. The proposed algorithm, TANDIS (Targeted Attack via Neighborhood DIStortion) shows that distortion of node neighborhoods is effective in drastically compromising prediction performance. Although neighborhood distortion is an NP-hard problem, TANDIS designs an effective heuristic through a novel combination of Graph Isomorphism Network with deep Q-learning. Extensive experiments on real datasets show that, on average, TANDIS is up to 50% more effective than state-of-the-art techniques, while being more than 1000 times faster.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robust Sequence Networked Submodular Maximization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26762), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26762/26534), [keywords](General), [abstract](Abstract
In this paper, we study the Robust optimization for sequence Networked submodular maximization (RoseNets) problem. We interweave the robust optimization  with the sequence networked submodular maximization. The elements are connected by a directed acyclic graph and the objective function is not submodular on the elements but on the edges in the graph. Under such networked submodular scenario, the impact of removing an element from a sequence depends both on its position in the sequence and in the network. This makes the existing robust algorithms inapplicable and calls for new robust algorithms. In this paper, we take the first step to study the RoseNets problem. We design a robust greedy algorithms, which is robust against the removal of an arbitrary subset of the selected elements. The approximation ratio of the algorithm depends both on the number of the removed elements and the network topology. We further conduct experiments on real applications of recommendation and link prediction. The experimental results demonstrate the effectiveness of the proposed algorithm.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Safe Policy Improvement for POMDPs via Finite-State Controllers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26763), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26763/26535), [keywords](General), [abstract](Abstract
We study safe policy improvement (SPI) for partially observable Markov decision processes (POMDPs). SPI is an offline reinforcement learning (RL) problem that assumes access to (1) historical data about an environment, and (2) the so-called behavior policy that previously generated this data by interacting with the environment. SPI methods neither require access to a model nor the environment itself, and aim to reliably improve upon the behavior policy in an offline manner. Existing methods make the strong assumption that the environment is fully observable. In our novel approach to the SPI problem for POMDPs, we assume that a finite-state controller (FSC) represents the behavior policy and that finite memory is sufficient to derive optimal policies. This assumption allows us to map the POMDP to a finite-state fully observable MDP, the history MDP. We estimate this MDP by combining the historical data and the memory of the FSC, and compute an improved policy using an off-the-shelf SPI algorithm. The underlying SPI method constrains the policy space according to the available data, such that the newly computed policy only differs from the behavior policy when sufficient data is available. We show that this new policy, converted into a new FSC for the (unknown) POMDP, outperforms the behavior policy with high probability. Experimental results on several well-established benchmarks show the applicability of the approach, even in cases where finite memory is not sufficient.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26764), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26764/26536), [keywords](General), [abstract](Abstract
Deep Reinforcement Learning (DRL) has the potential to be used for synthesizing feedback controllers (agents) for various complex systems with unknown dynamics. These systems are expected to satisfy diverse safety and liveness properties best captured using temporal logic. In RL, the reward function plays a crucial role in specifying the desired behaviour of these agents. However, the problem of designing the reward function for an RL agent to satisfy complex temporal logic specifications has received limited attention in the literature. To address this, we provide a systematic way of generating rewards in real-time by using the quantitative semantics of Signal Temporal Logic (STL), a widely used temporal logic to specify the behaviour of cyber-physical systems. We propose a new quantitative semantics for STL having several desirable properties, making it suitable for reward generation. We evaluate our STL-based reinforcement learning mechanism on several complex continuous control benchmarks and compare our STL semantics with those available in the literature in terms of their efficacy in synthesizing the controller agent. Experimental results establish our new semantics to be the most suitable for synthesizing feedback controllers for complex continuous dynamical systems through reinforcement learning.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Understanding and Enhancing Robustness of Concept-Based Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26765), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26765/26537), [keywords](General), [abstract](Abstract
Rising usage of deep neural networks to perform decision making in critical applications like medical diagnosis and fi- nancial analysis have raised concerns regarding their reliability and trustworthiness. As automated systems become more mainstream, it is important their decisions be transparent, reliable and understandable by humans for better trust and confidence. To this effect, concept-based models such as Concept Bottleneck Models (CBMs) and Self-Explaining Neural Networks (SENN) have been proposed which constrain the latent space of a model to represent high level concepts easily understood by domain experts in the field. Although concept-based models promise a good approach to both increasing explainability and reliability, it is yet to be shown if they demonstrate robustness and output consistent concepts under systematic perturbations to their inputs. To better understand performance of concept-based models on curated malicious samples, in this paper, we aim to study their robustness to adversarial perturbations, which are also known as the imperceptible changes to the input data that are crafted by an attacker to fool a well-learned concept-based model. Specifically, we first propose and analyze different malicious attacks to evaluate the security vulnerability of concept based models. Subsequently, we propose a potential general adversarial training-based defense mechanism to increase robustness of these systems to the proposed malicious attacks. Extensive experiments on one synthetic and two real-world datasets demonstrate the effectiveness of the proposed attacks and the defense approach. An appendix of the paper with more comprehensive results can also be viewed at https://arxiv.org/abs/2211.16080.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Misspecification in Inverse Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26766), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26766/26538), [keywords](General), [abstract](Abstract
The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function R from a policy pi. To do this, we need a model of how pi relates to R. In the current literature, the most common models are optimality, Boltzmann rationality, and causal entropy maximisation. One of the primary motivations behind IRL is to infer human preferences from human behaviour. However, the true relationship between human preferences and human behaviour is much more complex than any of the models currently used in IRL. This means that they are misspecified, which raises the worry that they might lead to unsound inferences if applied to real-world data. In this paper, we provide a mathematical analysis of how robust different IRL models are to misspecification, and answer precisely how the demonstrator policy may differ from each of the standard models before that model leads to faulty inferences about the reward function R. We also introduce a framework for reasoning about misspecification in IRL, together with formal tools that can be used to easily derive the misspecification robustness of new IRL models.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Planning and Learning for Non-markovian Negative Side Effects Using Finite State Controllers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26767), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26767/26539), [keywords](General), [abstract](Abstract
Autonomous systems are often deployed in the open world where it is hard to obtain complete specifications of objectives and constraints. Operating based on an incomplete model can produce negative side effects (NSEs), which affect the safety and reliability of the system. We focus on mitigating NSEs in environments modeled as Markov decision processes (MDPs). First, we learn a model of NSEs using observed data that contains state-action trajectories and severity of associated NSEs. Unlike previous works that associate NSEs with state-action pairs, our framework associates NSEs with entire trajectories, which is more general and captures non-Markovian dependence on states and actions. Second, we learn finite state controllers (FSCs) that predict NSE severity for a given trajectory and generalize well to unseen data. Finally, we develop a constrained MDP model that uses information from the underlying MDP and the learned FSC for planning while avoiding NSEs. Our empirical evaluation demonstrates the effectiveness of our approach in learning and mitigating Markovian and non-Markovian NSEs.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Toward Robust Uncertainty Estimation with Random Activation Functions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26768), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26768/26540), [keywords](General), [abstract](Abstract
Deep neural networks are in the limelight of machine learning with their excellent performance in many data-driven applications. However, they can lead to inaccurate predictions when queried in out-of-distribution data points, which can have detrimental effects especially in sensitive domains, such as healthcare and transportation, where erroneous predictions can be very costly and/or dangerous. Subsequently, quantifying the uncertainty of the output of a neural network is often leveraged to evaluate the confidence of its predictions, and ensemble models have proved to be effective in measuring the uncertainty by utilizing the variance of predictions over a pool of models. In this paper, we propose a novel approach for uncertainty quantification via ensembles, called Random Activation Functions (RAFs) Ensemble, that aims at improving the ensemble diversity toward a more robust estimation, by accommodating each neural network with a different (random) activation function. Extensive empirical study demonstrates that RAFs Ensemble outperforms state-of-the-art ensemble uncertainty quantification methods on both synthetic and real-world datasets in a series of regression tasks.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Improving Robust Fariness via Balance Adversarial Training | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26769), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26769/26541), [keywords](General), [abstract](Abstract
Adversarial training (AT) methods are effective against adversarial attacks, yet they introduce severe disparity of accuracy and robustness between different classes, known as the robust fairness problem. Previously proposed Fair Robust Learning (FRL) adaptively reweights different classes to improve fairness. However, the performance of the better-performed classes decreases, leading to a strong performance drop. In this paper, we observed two unfair phenomena during adversarial training: different difficulties in generating adversarial examples from each class (source-class fairness) and disparate target class tendencies when generating adversarial examples (target-class fairness). From the observations, we propose Balance Adversarial Training (BAT) to address the robust fairness problem. Regarding source-class fairness, we adjust the attack strength and difficulties of each class to generate samples near the decision boundary for easier and fairer model learning; considering target-class fairness, by introducing a uniform distribution constraint, we encourage the adversarial example generation process for each class with a fair tendency. Extensive experiments conducted on multiple datasets (CIFAR-10, CIFAR-100, and ImageNette) demonstrate that our BAT can significantly outperform other baselines in mitigating the robust fairness problem (+5-10\% on the worst class accuracy)(Our codes can be found at https://github.com/silvercherry/Improving-Robust-Fairness-via-Balance-Adversarial-Training).), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
DPAUC- Differentially Private AUC Computation in Federated Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26770), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26770/26542), [keywords](General), [abstract](Abstract
Federated learning (FL) has gained significant attention recently as a privacy-enhancing tool to jointly train a machine learning model by multiple participants. 
The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to the potential leakage of private label information.
In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth. The code is available at https://github.com/bytedance/fedlearner/tree/master/example/privacy/DPAUC), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Conflicting Interactions among Protection Mechanisms for Machine Learning Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26771), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26771/26543), [keywords](General), [abstract](Abstract
Nowadays, systems based on machine learning (ML) are widely used in different domains.
Given their popularity, ML models have become targets for various attacks.
As a result, research at the intersection of security/privacy and ML has flourished. Typically such work has focused on individual types of security/privacy concerns and mitigations thereof.

However, in real-life deployments, an ML model will need to be protected against several concerns simultaneously.
A protection mechanism optimal for a specific security or privacy concern may interact negatively with mechanisms intended to address other concerns. Despite its practical relevance, the potential for such conflicts has not been studied adequately.

In this work, we first provide a framework for analyzing such conflicting interactions.
We then focus on systematically analyzing pairwise interactions between protection mechanisms for one concern, model and data ownership verification, with two other classes of ML protection mechanisms: differentially private training, and robustness against model evasion.
We find that several pairwise interactions result in conflicts.

We also explore potential approaches for avoiding such conflicts. First, we study the effect of hyperparameter relaxations, finding that there is no sweet spot balancing the performance of both protection mechanisms.
Second, we explore whether modifying one type of protection mechanism (ownership verification) so as to decouple it from factors that may be impacted by a conflicting mechanism (differentially private training or robustness to model evasion) can avoid conflict.
We show that this approach can indeed avoid the conflict between ownership verification mechanisms when combined with differentially private training, but has no effect on robustness to model evasion. We conclude by identifying the gaps in the landscape of studying interactions between other types of ML protection mechanisms.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Neural Policy Safety Verification via Predicate Abstraction- CEGAR | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26772), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26772/26544), [keywords](General), [abstract](Abstract
Neural networks (NN) are an increasingly important representation of action policies pi. Recent work has extended predicate abstraction to prove safety of such pi, through policy predicate abstraction (PPA) which over-approximates the state space subgraph induced by pi. The advantage of PPA is that reasoning about the NN – calls to SMT solvers – is required only locally, at individual abstract state transitions, in contrast to bounded model checking (BMC) where SMT must reason globally about sequences of NN decisions. Indeed, it has been shown that PPA can outperform a simple BMC implementation. However, the abstractions underlying these results (i.e., the abstraction predicates) were supplied manually. Here we automate this step. We extend counterexample guided abstraction refinement (CEGAR) to PPA. This involves dealing with a new source of spuriousness in abstract unsafe paths, pertaining not to transition behavior but to the decisions of the neural network pi. We introduce two methods tackling this issue based on the states involved, and we show that global SMT calls deciding spuriousness exactly can be avoided. We devise algorithmic enhancements leveraging incremental computation and heuristic search. We show empirically that the resulting verification tool has significant advantages over an encoding into the state-of-the-art model checker nuXmv. In particular, ours is the only approach in our experiments that succeeds in proving policies safe.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Towards Verifying the Geometric Robustness of Large-Scale Neural Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26773), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26773/26545), [keywords](General), [abstract](Abstract
Deep neural networks (DNNs) are known to be vulnerable to adversarial geometric transformation. This paper aims to verify the robustness of large-scale DNNs against the combination of multiple geometric transformations with a provable guarantee.  Given a set of transformations (e.g., rotation, scaling, etc.), we develop GeoRobust, a black-box robustness analyser built upon a novel global optimisation strategy, for locating the worst-case combination of transformations that affect and even alter a network's output.  GeoRobust can provide provable guarantees on finding the worst-case combination based on recent advances in Lipschitzian theory. Due to its black-box nature, GeoRobust can be deployed on large-scale DNNs regardless of their architectures, activation functions, and the number of neurons. In practice, GeoRobust can locate the worst-case geometric transformation with high precision for the ResNet50 model on ImageNet in a few seconds on average. We examined 18 ImageNet classifiers, including the ResNet family and vision transformers, and found a positive correlation between the geometric robustness of the networks and the parameter numbers. We also observe that increasing the depth of DNN is more beneficial than increasing its width in terms of improving its geometric robustness. Our tool GeoRobust is available at https://github.com/TrustAI/GeoRobust.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Revisiting Item Promotion in GNN-Based Collaborative Filtering- A Masked Targeted Topological Attack Perspective | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26774), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26774/26546), [keywords](General), [abstract](Abstract
Graph neural networks (GNN) based collaborative filtering (CF) has attracted increasing attention in e-commerce and financial marketing platforms. However, there still lack efforts to evaluate the robustness of such CF systems in deployment. Fundamentally different from existing attacks, this work revisits the item promotion task and reformulates it from a targeted topological attack perspective for the first time. Specifically, we first develop a targeted attack formulation to maximally increase a target item's popularity. We then leverage gradient-based optimizations to find a solution. However, we observe the gradient estimates often appear noisy due to the discrete nature of a graph, which leads to a degradation of attack ability. To resolve noisy gradient effects, we then propose a masked attack objective that can remarkably enhance the topological attack ability. Furthermore, we design a computationally efficient approach to the proposed attack, thus making it feasible to evaluate large-large CF systems. Experiments on two real-world datasets show the effectiveness of our attack in analyzing the robustness of GNN-based CF more practically.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robust Average-Reward Markov Decision Processes | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26775), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26775/26547), [keywords](General), [abstract](Abstract
In robust Markov decision processes (MDPs), the uncertainty in the transition kernel is addressed by finding a policy that optimizes the worst-case performance over an uncertainty set of MDPs. While much of the literature has focused on discounted MDPs, robust average-reward MDPs remain largely unexplored. In this paper, we focus on robust average-reward MDPs, where the goal is to find a policy that optimizes the worst-case average reward over an uncertainty set. We first take an approach that approximates average-reward MDPs using discounted MDPs. We prove that the robust discounted value function converges to the robust average-reward as the discount factor goes to 1, and moreover when it is large, any optimal policy of the robust discounted MDP is also an optimal policy of the robust average-reward. We further design a robust dynamic programming approach, and theoretically characterize its convergence to the optimum. Then, we investigate robust average-reward MDPs directly without using discounted MDPs as an intermediate step. We derive the robust Bellman equation for robust average-reward MDPs, prove that the optimal policy can be derived from its solution, and further design a robust relative value iteration algorithm that provably finds its solution, or equivalently, the optimal robust policy.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robust Graph Meta-Learning via Manifold Calibration with Proxy Subgraphs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26776), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26776/26548), [keywords](General), [abstract](Abstract
Graph meta-learning has become a preferable paradigm for graph-based node classification with long-tail distribution, owing to its capability of capturing the intrinsic manifold of support and query nodes. Despite the remarkable success, graph meta-learning suffers from severe performance degradation when training on graph data with structural noise. In this work, we observe that the structural noise may impair the smoothness of the intrinsic manifold supporting the support and query nodes, leading to the poor transferable priori of the meta-learner. To address the issue, we propose a new approach for graph meta-learning that is robust against structural noise, called Proxy subgraph-based Manifold Calibration method (Pro-MC). Concretely, a subgraph generator is designed to generate proxy subgraphs that can calibrate the smoothness of the manifold. The proxy subgraph compromises two types of subgraphs with two biases, thus preventing the manifold from being rugged and straightforward. By doing so, our proposed meta-learner can obtain generalizable and transferable prior knowledge. In addition, we provide a theoretical analysis to illustrate the effectiveness of Pro-MC. Experimental results have demonstrated that our approach can achieve state-of-the-art performance under various structural noises.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
HOTCOLD Block- Fooling Thermal Infrared Detectors with a Novel Wearable Design | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26777), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26777/26549), [keywords](General), [abstract](Abstract
Adversarial attacks on thermal infrared imaging expose the risk of related applications. Estimating the security of these systems is essential for safely deploying them in the real world. In many cases, realizing the attacks in the physical space requires elaborate special perturbations. These solutions are often impractical and attention-grabbing. To address the need for a physically practical and stealthy adversarial attack, we introduce HotCold Block, a novel physical attack for infrared detectors that hide persons utilizing the wearable Warming Paste and Cooling Paste. By attaching these readily available temperature-controlled materials to the body, HotCold Block evades human eyes efficiently. Moreover, unlike existing methods that build adversarial patches with complex texture and structure features, HotCold Block utilizes an SSP-oriented adversarial optimization algorithm that enables attacks with pure color blocks and explores the influence of size, shape, and position on attack performance. Extensive experimental results in both digital and physical environments demonstrate the performance of our proposed HotCold Block. Code is available: https://github.com/weihui1308/HOTCOLDBlock.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Beyond NaN- Resiliency of Optimization Layers in the Face of Infeasibility | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26778), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26778/26550), [keywords](General), [abstract](Abstract
Prior work has successfully incorporated optimization layers as the last layer in neural networks for various problems, thereby allowing joint learning and planning in one neural network forward pass. In this work, we identify a weakness in such a set-up where inputs to the optimization layer lead to undefined output of the neural network. Such undefined decision outputs can lead to possible catastrophic outcomes in critical real time applications. We show that an adversary can cause such failures by forcing rank deficiency on the matrix fed to the optimization layer which results in the optimization failing to produce a solution. We provide a defense for the failure cases by controlling the condition number of the input matrix. We study the problem in the settings of synthetic data, Jigsaw Sudoku, and in speed planning for autonomous driving. We show that our proposed defense effectively prevents the framework from failing with undefined output. Finally, we surface a number of edge cases which lead to serious bugs in popular optimization solvers which can be abused as well.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
DeepGemini- Verifying Dependency Fairness for Deep Neural Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26779), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26779/26551), [keywords](General), [abstract](Abstract
Deep neural networks (DNNs) have been widely adopted in many decision-making industrial applications. Their fairness issues, i.e., whether there exist unintended biases in the DNN, receive much attention and become critical concerns, which can directly cause negative impacts in our daily life and potentially undermine the fairness of our society, especially with their increasing deployment at an unprecedented speed. Recently, some early attempts have been made to provide fairness assurance of DNNs, such as fairness testing, which aims at finding discriminatory samples empirically, and fairness certification, which develops sound but not complete analysis to certify the fairness of DNNs. Nevertheless, how to formally compute discriminatory samples and fairness scores (i.e., the percentage of fair input space), is still largely uninvestigated. In this paper, we propose DeepGemini, a novel fairness formal analysis technique for DNNs, which contains two key components: discriminatory sample discovery and fairness score computation. To uncover discriminatory samples, we encode the fairness of DNNs as safety properties and search for discriminatory samples by means of state-of-the-art verification techniques for DNNs. This reduction enables us to be the first to formally compute discriminatory samples. To compute the fairness score, we develop counterexample guided fairness analysis, which utilizes four heuristics to efficiently approximate a lower bound of fairness score. Extensive experimental evaluations demonstrate the effectiveness and efficiency of DeepGemini on commonly-used benchmarks, and DeepGemini outperforms state-of-the-art DNN fairness certification approaches in terms of both efficiency and scalability.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26780), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26780/26552), [keywords](General), [abstract](Abstract
This paper makes two key contributions. First, it argues that highly specialized rare content classifiers trained on small data typically have limited exposure to the richness and topical diversity of the negative class (dubbed anticontent) as observed in the wild. As a result, these classifiers' strong performance observed on the test set may not translate into real-world settings. In the context of COVID-19 misinformation detection, we conduct an in-the-wild audit of multiple datasets and demonstrate that models trained with several prominently cited recent datasets are vulnerable to anticontent when evaluated in the wild. Second, we present a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent, robustifying these classifiers.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
User-Oriented Robust Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26781), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26781/26553), [keywords](General), [abstract](Abstract
Recently, improving the robustness of policies across different environments attracts increasing attention in the reinforcement learning (RL) community. Existing robust RL methods mostly aim to achieve the max-min robustness by optimizing the policy’s performance in the worst-case environment. However, in practice, a user that uses an RL policy may have different preferences over its performance across environments. Clearly, the aforementioned max-min robustness is oftentimes too conservative to satisfy user preference. Therefore, in this paper, we integrate user preference into policy learning in robust RL, and propose a novel User-Oriented Robust RL (UOR-RL) framework. Specifically, we define a new User-Oriented Robustness (UOR) metric for RL, which allocates different weights to the environments according to user preference and generalizes the max-min robustness metric. To optimize the UOR metric, we develop two different UOR-RL training algorithms for the scenarios with or without a priori known environment distribution, respectively. Theoretically, we prove that our UOR-RL training algorithms converge to near-optimal policies even with inaccurate or completely no knowledge about the environment distribution. Furthermore, we carry out extensive experimental evaluations in 6 MuJoCo tasks. The experimental results demonstrate that UOR-RL is comparable to the state-of-the-art baselines under the average-case and worst-case performance metrics, and more importantly establishes new state-of-the-art performance under the UOR metric.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Safety Verification of Nonlinear Systems with Bayesian Neural Network Controllers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26782), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26782/26554), [keywords](General), [abstract](Abstract
Bayesian neural networks (BNNs) retain NN structures with a probability distribution placed over their weights. With the introduced uncertainties and redundancies, BNNs are proper choices of robust controllers for safety-critical control systems. This paper considers the problem of verifying the safety of nonlinear closed-loop systems with BNN controllers over unbounded-time horizon. In essence, we compute a safe weight set such that as long as the BNN controller is always applied with weights sampled from the safe weight set, the controlled system is guaranteed to be safe. We propose a novel two-phase method for the safe weight set computation. First, we construct a reference safe control set that constraints the control inputs, through polynomial approximation to the BNN controller followed by polynomial-optimization-based barrier certificate generation. Then, the computation of safe weight set is reduced to a range inclusion problem of the BNN on the system domain w.r.t. the safe control set, which can be solved incrementally and the set of safe weights can be extracted. Compared with the existing method based on invariant learning and mixed-integer linear programming, we could compute safe weight sets with larger radii on a series of linear benchmarks. Moreover, experiments on a series of widely used nonlinear control tasks show that our method can synthesize large safe weight sets with probability measure as high as 95% even for a large-scale system of dimension 7.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Reachability Analysis of Neural Network Control Systems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26783), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26783/26555), [keywords](General), [abstract](Abstract
Neural network controllers (NNCs) have shown great promise in autonomous and cyber-physical systems. Despite the various verification approaches for neural networks, the safety analysis of NNCs remains an open problem. Existing verification approaches for neural network control systems (NNCSs) either can only work on a limited type of activation functions, or result in non-trivial over-approximation errors with time evolving. This paper proposes a verification framework for NNCS based on Lipschitzian optimisation, called DeepNNC. We first prove the Lipschitz continuity of closed-loop NNCSs by unrolling and eliminating the loops. We then reveal the working principles of applying Lipschitzian optimisation on NNCS verification and illustrate it by verifying an adaptive cruise control model. Compared to state-of-the-art verification approaches, DeepNNC shows superior performance in terms of efficiency and accuracy over a wide range of NNCs. We also provide a case study to demonstrate the capability of DeepNNC to handle a real-world, practical, and complex system. Our tool DeepNNC is available at https://github.com/TrustAI/DeepNNC.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
BIFRNet- A Brain-Inspired Feature Restoration DNN for Partially Occluded Image Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26784), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26784/26556), [keywords](General), [abstract](Abstract
The partially occluded image recognition (POIR) problem has been a challenge for artificial intelligence for a long time. A common strategy to handle the POIR problem is using the non-occluded features for classification. Unfortunately, this strategy will lose effectiveness when the image is severely occluded, since the visible parts can only provide limited information. Several studies in neuroscience reveal that feature restoration which fills in the occluded information and is called amodal completion is essential for human brains to recognize partially occluded images. However, feature restoration is commonly ignored by CNNs, which may be the reason why CNNs are ineffective for the POIR problem. Inspired by this, we propose a novel brain-inspired feature restoration network (BIFRNet) to solve the POIR problem. It mimics a ventral visual pathway to extract image features and a dorsal visual pathway to distinguish occluded and visible image regions. In addition, it also uses a knowledge module to store classification prior knowledge and uses a completion module to restore occluded features based on visible features and prior knowledge. Thorough experiments on synthetic and real-world occluded image datasets show that BIFRNet outperforms the existing methods in solving the POIR problem. Especially for severely occluded images, BIRFRNet surpasses other methods by a large margin and is close to the human brain performance. Furthermore, the brain-inspired design makes BIFRNet more interpretable.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Robustness to Spurious Correlations Improves Semantic Out-of-Distribution Detection | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26785), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26785/26557), [keywords](General), [abstract](Abstract
Methods which utilize the outputs or feature representations of predictive models have emerged as promising approaches for out-of-distribution (OOD) detection of image inputs. However, as demonstrated in previous work, these methods struggle to detect OOD inputs that share nuisance values (e.g. background) with in-distribution inputs. The detection of shared-nuisance OOD (SN-OOD) inputs is particularly relevant in real-world applications, as anomalies and in-distribution inputs tend to be captured in the same settings during deployment. In this work, we provide a possible explanation for these failures and propose nuisance-aware OOD detection to address them. Nuisance-aware OOD detection substitutes a classifier trained via Empirical Risk Minimization (ERM) with one that 1. approximates a distribution where the nuisance-label relationship is broken and 2. yields representations that are independent of the nuisance under this distribution, both marginally and conditioned on the label. We can train a classifier to achieve these objectives using Nuisance-Randomized Distillation (NuRD), an algorithm developed for OOD generalization under spurious correlations. Output- and feature-based nuisance-aware OOD detection perform substantially better than their original counterparts, succeeding even when detection based on domain generalization algorithms fails to improve performance.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Evaluating Model-Free Reinforcement Learning toward Safety-Critical Tasks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26786), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26786/26558), [keywords](General), [abstract](Abstract
Safety comes first in many real-world applications involving autonomous agents. Despite a large number of reinforcement learning (RL) methods focusing on safety-critical tasks, there is still a lack of high-quality evaluation of those algorithms that adheres to safety constraints at each decision step under complex and unknown dynamics. In this paper, we revisit prior work in this scope from the perspective of state-wise safe RL and categorize them as projection-based, recovery-based, and optimization-based approaches, respectively.  Furthermore, we propose Unrolling Safety Layer (USL), a joint method that combines safety optimization and safety projection. This novel technique explicitly enforces hard constraints via the deep unrolling architecture and enjoys structural advantages in navigating the trade-off between reward improvement and constraint satisfaction. To facilitate further research in this area,  we reproduce related algorithms in a unified pipeline and incorporate them into SafeRL-Kit, a toolkit that provides off-the-shelf interfaces and evaluation utilities for safety-critical tasks. We then perform a comparative study of the involved algorithms on six benchmarks ranging from robotic control to autonomous driving. The empirical results provide an insight into their applicability and robustness in learning zero-cost-return policies without task-dependent handcrafting. The project page is available at https://sites.google.com/view/saferlkit.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Video-Audio Domain Generalization via Confounder Disentanglement | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26787), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26787/26559), [keywords](General), [abstract](Abstract
Existing video-audio understanding models are trained and evaluated in an intra-domain setting, facing performance degeneration in real-world applications where multiple domains and distribution shifts naturally exist. The key to video-audio domain generalization (VADG) lies in  alleviating spurious correlations over multi-modal features. To achieve this goal, we resort to causal theory and attribute such correlation to confounders affecting both video-audio features and labels. We propose a DeVADG framework that conducts uni-modal and cross-modal deconfounding through back-door adjustment. DeVADG performs cross-modal disentanglement and obtains fine-grained confounders at both class-level and domain-level using half-sibling regression and unpaired domain transformation, which essentially identifies domain-variant factors and class-shared factors that cause spurious correlations between features and false labels. To promote VADG research, we collect a VADG-Action dataset for video-audio action recognition with over 5,000 video clips across four domains (e.g., cartoon and game) and ten action classes (e.g., cooking and riding). We conduct extensive experiments, i.e., multi-source DG, single-source DG, and qualitative analysis, validating the rationality of our causal analysis and the effectiveness of the DeVADG framework.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Rethinking Safe Control in the Presence of Self-Seeking Humans | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26788), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26788/26560), [keywords](General), [abstract](Abstract
Safe control methods are often designed to behave safely even in worst-case human uncertainties. Such design can cause more aggressive human behaviors that exploit its conservatism and result in greater risk for everyone. However, this issue has not been systematically investigated previously. This paper uses an interaction-based payoff structure from evolutionary game theory to model humans’ short-sighted, self-seeking behaviors. The model captures how prior human-machine interaction experience causes behavioral and strategic changes in humans in the long term. We then show that deterministic worst-case safe control techniques and equilibrium-based stochastic methods can have worse safety and performance trade-offs than a basic method that mediates human strategic changes. This finding suggests an urgent need to fundamentally rethink the safe control framework used in human-technology interaction in pursuit of greater safety for all.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)
Towards Safe AI- Sandboxing DNNs-Based Controllers in Stochastic Games | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26789), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26789/26561), [keywords](General), [abstract](Abstract
Nowadays, AI-based techniques, such as deep neural networks (DNNs), are widely deployed in autonomous systems for complex mission requirements (e.g., motion planning in robotics). However, DNNs-based controllers are typically very complex, and it is very hard to formally verify their correctness, potentially causing severe risks for safety-critical autonomous systems. In this paper, we propose a construction scheme for a so-called Safe-visor architecture to sandbox DNNs-based controllers. Particularly, we consider the construction under a stochastic game framework to provide a system-level safety guarantee which is robust to noises and disturbances. A supervisor is built to check the control inputs provided by a DNNs-based controller and decide whether to accept them.  Meanwhile, a safety advisor is running in parallel to provide fallback control inputs in case the DNN-based controller is rejected. We demonstrate the proposed approaches on a quadrotor employing an unverified DNNs-based controller.), [group](Special Tracks: AAAI Special Track on Safe and Robust AI)Generalized Category Discovery with Decoupled Prototypical Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26475), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26475/26247), [keywords](SNLP: Text Mining, SNLP: Text Classification), [abstract](Abstract
Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Structured Case-Based Reasoning for Inference-Time Adaptation of Text-to-SQL Parsers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26476), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26476/26248), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Question Answering), [abstract](Abstract
Inference-time adaptation methods for semantic parsing are useful for leveraging examples from newly-observed domains without repeated fine-tuning. Existing approaches typically bias the decoder by simply concatenating input-output example pairs (cases) from the new domain at the encoder’s input in a Seq-to-Seq model. Such methods cannot adequately leverage the structure of logical forms in the case examples. We propose StructCBR, a structured case-based reasoning approach, which leverages subtree-level similarity between logical forms of cases and candidate outputs, resulting in better decoder decisions. For the task of adapting Text-to-SQL models to unseen schemas, we show that exploiting case examples in a structured manner via StructCBR offers consistent performance improvements over prior inference-time adaptation methods across five different databases. To the best of our knowledge, we are the first to attempt inference-time adaptation of Text-to-SQL models, and harness trainable structured similarity between subqueries.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SegFormer- A Topic Segmentation Model with Controllable Range of Attention | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26477), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26477/26249), [keywords](SNLP: Applications, SNLP: Information Extraction, SNLP: Language Models, SNLP: Machine Translation & Multilinguality, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Summarization, SNLP: Text Classification, SNLP: Text Mining), [abstract](Abstract
Topic segmentation aims to reveal the latent structure of a document and divide it into multiple parts. However, current neural solutions are limited in the context modeling of sentences and feature representation of candidate boundaries. This causes the model to suffer from inefficient sentence context encoding and noise information interference. In this paper, we design a new text segmentation model SegFormer with unidirectional attention blocks to better model sentence representations. To alleviate the problem of noise information interference, SegFormer uses a novel additional context aggregator and a topic classification loss to guide the model to aggregate the information within the appropriate range.  In addition, SegFormer applies an iterative prediction algorithm to search for optimal boundaries progressively. We evaluate SegFormer's generalization ability, multilingual ability, and application ability on multiple challenging real-world datasets. Experiments show that our model significantly improves the performance by 7.5% on the benchmark WIKI-SECTION compared to several strong baselines. The application of SegFormer to a real-world dataset to separate normal and advertisement segments in product marketing essays also achieves superior performance in the evaluation with other cutting-edge models.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Rich Event Modeling for Script Event Prediction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26478), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26478/26250), [keywords](SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Information Extraction), [abstract](Abstract
Script is a kind of structured knowledge extracted from texts, which contains a sequence of events. Based on such knowledge, script event prediction aims to predict the subsequent event. To do so, two aspects should be considered for events, namely, event description (i.e., what the events should contain) and event encoding (i.e., how they should be encoded). Most existing methods describe an event by a verb together with a few core arguments (i.e., subject, object, and indirect object), which are not precise enough. In addition, existing event encoders are limited to a fixed number of arguments, which are not flexible enough to deal with extra information. Thus, in this paper, we propose the Rich Event Prediction (REP) framework for script event prediction. Fundamentally, it is based on the proposed rich event description, which enriches the existing ones with three kinds of important information, namely, the senses of verbs, extra semantic roles, and types of participants. REP contains an event extractor to extract such information from texts. Based on the extracted rich information, a predictor then selects the most probable subsequent event. The core component of the predictor is a transformer-based event encoder that integrates the above information flexibly. Experimental results on the widely used Gigaword Corpus show the effectiveness of the proposed framework.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Avocodo- Generative Adversarial Network for Artifact-Free Vocoder | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26479), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26479/26251), [keywords](SNLP: Speech and Multimodality, SNLP: Generation), [abstract](Abstract
Neural vocoders based on the generative adversarial neural network (GAN) have been widely used due to their fast inference speed and lightweight networks while generating high-quality speech waveforms. Since the perceptually important speech components are primarily concentrated in the low-frequency bands, most GAN-based vocoders perform multi-scale analysis that evaluates downsampled speech waveforms. This multi-scale analysis helps the generator improve speech intelligibility. However, in preliminary experiments, we discovered that the multi-scale analysis which focuses on the low-frequency bands causes unintended artifacts, e.g., aliasing and imaging artifacts, which degrade the synthesized speech waveform quality. Therefore, in this paper, we investigate the relationship between these artifacts and GAN-based vocoders and propose a GAN-based vocoder, called Avocodo, that allows the synthesis of high-fidelity speech with reduced artifacts. We introduce two kinds of discriminators to evaluate speech waveforms in various perspectives: a collaborative multi-band discriminator and a sub-band discriminator. We also utilize a pseudo quadrature mirror filter bank to obtain downsampled multi-band speech waveforms while avoiding aliasing. According to experimental results, Avocodo outperforms baseline GAN-based vocoders, both objectively and subjectively, while reproducing speech with fewer artifacts.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
End-to-End Deep Reinforcement Learning for Conversation Disentanglement | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26480), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26480/26252), [keywords](SNLP: Conversational AI/Dialogue Systems, ML: Reinforcement Learning Algorithms), [abstract](Abstract
Collaborative Communication platforms (e.g., Slack) support multi-party conversations which contain a large number of messages on shared channels. Multiple conversations intermingle within these messages. The task of conversation disentanglement is to cluster these intermingled messages into conversations. Existing approaches are trained using loss functions that optimize only local decisions, i.e. predicting reply-to links for each message and thereby creating clusters of conversations. In this work, we propose an end-to-end reinforcement learning (RL) approach that directly optimizes a global metric. We observe that using existing global metrics such as variation of information and adjusted rand index as a reward for the RL agent deteriorates its performance. This behaviour is because these metrics completely ignore the reply-to links between messages (local decisions) during reward computation. Therefore, we propose a novel thread-level reward function that captures the global metric without ignoring the local decisions. Through experiments on the Ubuntu IRC dataset, we demonstrate that the proposed RL model improves the performance on both link-level and conversation-level metrics.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Self-Supervised Logic Induction for Explainable Fuzzy Temporal Commonsense Reasoning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26481), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26481/26253), [keywords](SNLP: Applications, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Understanding temporal commonsense concepts, such as times of occurrence and durations is crucial for event-centric language understanding. Reasoning about such temporal concepts in a complex context requires reasoning over both the stated context and the world knowledge that underlines it. A recent study shows massive pre-trained LM still struggle with such temporal reasoning under complex contexts (e.g., dialog) because they only implicitly encode the relevant contexts and fail to explicitly uncover the underlying logical compositions for complex inference, thus may not be robust enough. In this work, we propose to augment LMs with the temporal logic induction ability, which frames the temporal reasoning by defining three modular components: temporal dependency inducer and temporal concept defuzzifier and logic validator. The former two components disentangle the explicit/implicit dependency between temporal concepts across context (before, after, ...) and the specific meaning of fuzzy temporal concepts, respectively, while the validator combines the intermediate reasoning clues for robust contextual reasoning about the temporal concepts. Extensive experimental results on TIMEDIAL, a challenging dataset for temporal reasoning over dialog, show that our method, Logic Induction Enhanced Contextualized TEmporal Reasoning (LECTER), can yield great improvements over the traditional language model for temporal reasoning.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Zero-Shot Cross-Lingual Event Argument Extraction with Language-Oriented Prefix-Tuning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26482), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26482/26254), [keywords](SNLP: Information Extraction), [abstract](Abstract
Event argument extraction (EAE) aims to identify the arguments of a given event, and classify the roles that those arguments play. Due to high data demands of training EAE models, zero-shot cross-lingual EAE has attracted increasing attention, as it greatly reduces human annotation effort. Some prior works indicate that generation-based methods have achieved promising performance for monolingual EAE. However, when applying existing generation-based methods to zero-shot cross-lingual EAE, we find two critical challenges, including Language Discrepancy and Template Construction. In this paper, we propose a novel method termed as Language-oriented Prefix-tuning Network (LAPIN) to address the above challenges. Specifically, we devise a Language-oriented Prefix Generator module to handle the discrepancies between source and target languages. Moreover, we leverage a Language-agnostic Template Constructor module to design templates that can be adapted to any language. Extensive experiments demonstrate that our proposed method achieves the best performance, outperforming the previous state-of-the-art model by 4.8% and 2.3% of the average F1-score on two multilingual EAE datasets.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
RPA- Reasoning Path Augmentation in Iterative Retrieving for Multi-Hop QA | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26483), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26483/26255), [keywords](SNLP: Question Answering, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Multi-hop questions are associated with a series of justifications, and one needs to obtain the answers by following the reasoning path (RP) that orders the justifications adequately. So reasoning path retrieval becomes a critical preliminary stage for multi-hop Question Answering (QA). Within the RP, two fundamental challenges emerge for better performance: (i) what the order of the justifications in the RP should be, and (ii) what if the wrong justification has been in the path. In this paper, we propose Reasoning Path Augmentation (RPA), which uses reasoning path reordering and augmentation to handle the above two challenges, respectively. Reasoning path reordering restructures the reasoning by targeting the easier justification first but difficult one later, in which the difficulty is determined by the overlap between query and justifications since the higher overlap means more lexical relevance and easier searchable. Reasoning path augmentation automatically generates artificial RPs, in which the distracted justifications are inserted to aid the model recover from the wrong justification. We build RPA with a naive pre-trained model and evaluate RPA on the QASC and MultiRC datasets. The evaluation results demonstrate that RPA outperforms previously published reasoning path retrieval methods, showing the effectiveness of the proposed methods. Moreover, we present detailed experiments on how the orders of justifications and the percent of augmented paths affect the question- answering performance, revealing the importance of polishing RPs and the necessity of augmentation.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Leveraging Modality-Specific Representations for Audio-Visual Speech Recognition via Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26484), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26484/26256), [keywords](SNLP: Speech and Multimodality, SNLP: Applications), [abstract](Abstract
Audio-visual speech recognition (AVSR) has gained remarkable success for ameliorating the noise-robustness of speech recognition. Mainstream methods focus on fusing audio and visual inputs to obtain modality-invariant representations. However, such representations are prone to over-reliance on audio modality as it is much easier to recognize than video modality in clean conditions. As a result, the AVSR model underestimates the importance of visual stream in face of noise corruption. To this end, we leverage visual modality-specific representations to provide stable complementary information for the AVSR task. Specifically, we propose a reinforcement learning (RL) based framework called MSRL, where the agent dynamically harmonizes modality-invariant and modality-specific representations in the auto-regressive decoding process. We customize a reward function directly related to task-specific metrics (i.e., word error rate), which encourages the MSRL to effectively explore the optimal integration strategy. Experimental results on the LRS3 dataset show that the proposed method achieves state-of-the-art in both clean and various noisy conditions. Furthermore, we demonstrate the better generality of MSRL system than other baselines when test set contains unseen noises.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Converge to the Truth- Factual Error Correction via Iterative Constrained Editing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26485), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26485/26257), [keywords](SNLP: Applications, APP: Misinformation & Fake News, SNLP: Generation, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Given a possibly false claim sentence, how can we automatically correct it with minimal editing? Existing methods either require a large number of pairs of false and corrected claims for supervised training or do not handle well errors spanning over multiple tokens within an utterance. In this paper, we propose VENCE, a novel method for factual error correction (FEC) with minimal edits. VENCE formulates the FEC problem as iterative sampling editing actions with respect to a target density function. We carefully design the target function with predicted truthfulness scores from an offline trained fact verification model. VENCE samples the most probable editing positions based on back-calculated gradients of the truthfulness score concerning input tokens and the editing actions using a distantly-supervised language model (T5). Experiments on a public dataset show that VENCE improves the well-adopted SARI metric by 5.3 (or a relative improvement of 11.8%) over the previous best distantly-supervised methods.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Adversarial Word Dilution as Text Data Augmentation in Low-Resource Regime | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26486), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26486/26258), [keywords](SNLP: Text Classification, SNLP: Adversarial Attacks & Robustness), [abstract](Abstract
Data augmentation is widely used in text classification, especially in the low-resource regime where a few examples for each class are available during training. Despite the success, generating data augmentations as hard positive examples that may increase their effectiveness is under-explored. This paper proposes an Adversarial Word Dilution (AWD) method that can generate hard positive examples as text data augmentations to train the low-resource text classification model efficiently. Our idea of augmenting the text data is to dilute the embedding of strong positive words by weighted mixing with unknown-word embedding, making the augmented inputs hard to be recognized as positive by the classification model. We adversarially learn the dilution weights through a constrained min-max optimization process with the guidance of the labels. Empirical studies on three benchmark datasets show that AWD can generate more effective data augmentations and outperform the state-of-the-art text data augmentation methods. The additional analysis demonstrates that the data augmentations generated by AWD are interpretable and can flexibly extend to new examples without further training.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
CP-Rec- Contextual Prompting for Conversational Recommender Systems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26487), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26487/26259), [keywords](SNLP: Conversational AI/Dialogue Systems), [abstract](Abstract
The conversational recommender system (CRS) aims to provide high-quality recommendations through interactive dialogues. However, previous CRS models have no effective mechanisms for task planning and topic elaboration, and thus they hardly maintain coherence in multi-task recommendation dialogues. Inspired by recent advances in prompt-based learning, we propose a novel contextual prompting framework for dialogue management, which optimizes prompts based on context, topics, and user profiles. Specifically, we develop a topic controller to sequentially plan the subtasks, and a prompt search module to construct context-aware prompts. We further adopt external knowledge to enrich user profiles and make knowledge-aware recommendations. Incorporating these techniques, we propose a conversational recommender system with contextual prompting, namely CP-Rec. Experimental results demonstrate that it achieves state-of-the-art recommendation accuracy and generates more coherent and informative conversations.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26488), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26488/26260), [keywords](SNLP: Generation, SNLP: Speech and Multimodality, ML: Deep Neural Architectures, SNLP: Applications, ML: Applications), [abstract](Abstract
Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26489), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26489/26261), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Generation, SNLP: Question Answering), [abstract](Abstract
Maintaining engagement and consistency is particularly important in dialogue systems. Existing works have improved the performance of dialogue systems by intentionally learning interlocutor personas with sophisticated network structures. One issue with this approach is that it requires more personal corpora with annotations. Additionally, these models typically perform the next utterance prediction to generate a response but neglect the discourse coherence in the entire conversation. To address these issues, this study proposes a method of learning to memorize entailment and discourse relations for persona-consistent dialogue tasks. Entailment text pairs in natural language inference dataset were applied to learn latent entailment relations as external memories by premise-to-hypothesis generation task. Furthermore, an internal memory with a similar architecture was applied to the discourse information in the dialogue. Placing orthogonality restrictions on these two memory spaces ensures that the latent entailment relations remain dialogue-independent. Both memories collaborate to obtain entailment and discourse representation for the generation, allowing a deeper understanding of both consistency and coherence. Experiments on two large public datasets, PersonaChat and DSTC7-AVSD, demonstrated the effectiveness of the proposed method. Both automatic and human evaluations indicate that the proposed model outperforms several strong baselines in terms of both persona consistency and response coherence. Our source code is availabled at https://github.com/Chenrj233/LMEDR.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Preference-Controlled Multi-Objective Reinforcement Learning for Conditional Text Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26490), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26490/26262), [keywords](SNLP: Generation, SNLP: Applications), [abstract](Abstract
Conditional text generation is to generate text sequences conditioning on linguistic or non-linguistic data. The main line of existing work proposed deterministic models to improve the fidelity of the generated text but often ignored the diversity. Another line relied on conditional variational auto-encoders (CVAEs), which increased the diversity over their deterministic backbones. However, CVAEs regard diversity as an implicit objective and may not be optimal. In this paper, we raise two questions:  i) Can diversity be further improved with an explicit objective? ii) Since fidelity and diversity are two conflicting objectives, how can we obtain different multi-objective optimal solutions according to user preferences? To answer question i), we propose a multi-objective reinforcement learning (MORL) method which explicitly takes CIDEr and Self-CIDEr scores as the fidelity-oriented and diversity-oriented rewards respectively. To answer question ii), we propose a preference-controlled MORL method, which can obtain infinite multi-objective optimal solutions by tuning the preference variable. We conduct extensive experiments on paraphrasing and image captioning tasks, which show that in the fidelity-diversity trade-off space, our model outperforms both deterministic and CVAE-based baselines.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learning towards Selective Data Augmentation for Dialogue Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26491), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26491/26263), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Generation), [abstract](Abstract
As it is cumbersome and expensive to acquire a huge amount of data for training neural dialog models, data augmentation is proposed to effectively utilize existing training samples.
However, current data augmentation techniques on the dialog generation task mostly augment all cases in the training dataset without considering the intrinsic attributes between different cases.
We argue that not all cases are beneficial for augmentation task, and the cases suitable for augmentation should obey the following two attributes: 
(1) low-quality (the dialog model cannot generate a high-quality response for the case),
(2) representative (the case should represent the property of the whole dataset).
Herein, we explore this idea by proposing a Selective Data Augmentation framework (SDA) for the response generation task.
SDA employs a dual adversarial network to select the lowest quality and most representative data points for augmentation in one stage. 
Extensive experiments conducted on two publicly available datasets, i.e., DailyDialog and OpenSubtitles, show that our framework can improve the response generation performance with respect to various metrics), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learn from Yesterday- A Semi-supervised Continual Learning Method for Supervision-Limited Text-to-SQL Task Streams | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26492), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26492/26264), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing, ML: Lifelong and Continual Learning, ML: Semi-Supervised Learning, SNLP: Question Answering), [abstract](Abstract
Conventional text-to-SQL studies are limited to a single task with a fixed-size training and test set. When confronted with a stream of tasks common in real-world applications, existing methods struggle with the problems of insufficient supervised data and high retraining costs. The former tends to cause overfitting on unseen databases for the new task, while the latter makes a full review of instances from past tasks impractical for the model, resulting in forgetting of learned SQL structures and database schemas. To address the problems, this paper proposes integrating semi-supervised learning (SSL) and continual learning (CL) in a stream of text-to-SQL tasks and offers two promising solutions in turn. The first solution Vanilla is to perform self-training, augmenting the supervised training data with predicted pseudo-labeled instances of the current task, while replacing the full volume retraining with episodic memory replay to balance the training efficiency with the performance of previous tasks. The improved solution SFNet takes advantage of the intrinsic connection between CL and SSL. It uses in-memory past information to help current SSL, while adding high-quality pseudo instances in memory to improve future replay.  The experiments on two datasets shows that SFNet outperforms the widely-used SSL-only and CL-only baselines on multiple metrics.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken Language Understanding | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26493), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26493/26265), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Speech and Multimodality), [abstract](Abstract
Multi-Intent Spoken Language Understanding (SLU), a novel and more complex scenario of SLU, is attracting increasing attention. Unlike traditional SLU, each intent in this scenario has its specific scope. Semantic information outside the scope even hinders the prediction, which tremendously increases the difficulty of intent detection. More seriously, guiding slot filling with these inaccurate intent labels suffers error propagation problems, resulting in unsatisfied overall performance. To solve these challenges, in this paper, we propose a novel Scope-Sensitive Result Attention Network (SSRAN) based on Transformer, which contains a Scope Recognizer (SR) and a Result Attention Network (RAN). SR assignments scope information to each token, reducing the distraction of out-of-scope tokens. RAN effectively utilizes the bidirectional interaction between SF and ID results, mitigating the error propagation problem. Experiments on two public datasets indicate that our model significantly improves SLU performance (5.4% and 2.1% on Overall accuracy) over the state-of-the-art baseline.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Unsupervised Explanation Generation via Correct Instantiations | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26494), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26494/26266), [keywords](SNLP: Interpretability & Analysis of NLP Models), [abstract](Abstract
While large pre-trained language models (PLM) have shown their great skills at solving discriminative tasks, a significant gap remains when compared with humans for explanation-related tasks. Among them, explaining the reason why a statement is wrong (e.g., against commonsense) is incredibly challenging. 
The major difficulty is finding the conflict point, where the statement contradicts our real world. This paper proposes Neon, a two-phrase, unsupervised explanation generation framework. Neon first generates corrected instantiations of the statement (phase I), then uses them to prompt large PLMs to find the conflict point and complete the explanation (phase II). We conduct extensive experiments on two standard explanation benchmarks, i.e., ComVE and e-SNLI. According to both automatic and human evaluations, Neon outperforms baselines, even for those with human-annotated instantiations. In addition to explaining a negative prediction, we further demonstrate that Neon remains effective when generalizing to different scenarios. The resources of Neon are available at: https://github.com/Shark-NLP/Neon.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Prompt-Augmented Linear Probing- Scaling beyond the Limit of Few-Shot In-Context Learners | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26495), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26495/26267), [keywords](SNLP: Language Models, SNLP: Text Classification), [abstract](Abstract
Through in-context learning (ICL), large-scale language models are effective few-shot learners without additional model fine-tuning.  However, the ICL performance does not scale well with the number of available training sample as it is limited by the inherent input length constraint of the underlying language model. Meanwhile, many studies have revealed that language models are also powerful feature extractors, allowing them to be utilized in a black-box manner and enabling the linear probing paradigm, where lightweight discriminators are trained on top of the pre-extracted input representations. This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear probing and ICL, which leverages the best of both worlds. PALP inherits the scalability of linear probing and the capability of enforcing language models to derive more meaningful representations via tailoring input into a more conceivable form. Throughout in-depth investigations on various datasets, we verified that PALP significantly closes the gap between ICL in the data-hungry scenario and fine-tuning in the data-abundant scenario with little training overhead, potentially making PALP a strong alternative in a black-box scenario.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Neural Dynamic Focused Topic Model | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26496), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26496/26268), [keywords](SNLP: Text Mining, ML: Deep Generative Models & Autoencoders, ML: Probabilistic Methods, SNLP: Applications), [abstract](Abstract
Topic models and all their variants analyse text by learning meaningful representations through word co-occurrences. As pointed out by previous work, such models implicitly assume that the probability of a topic to be active and its proportion within each document are positively correlated. This correlation can be strongly detrimental in the case of documents created over time, simply because recent documents are likely better described by new and hence rare topics. In this work we leverage recent advances in neural variational inference and present an alternative neural approach to the dynamic Focused Topic Model. Indeed, we develop a neural model for topic evolution which exploits sequences of Bernoulli random variables in order to track the appearances of topics, thereby decoupling their activities from their proportions. We evaluate our model on three different datasets (the UN general debates, the collection of NeurIPS papers, and the ACL Anthology dataset) and show that it (i) outperforms state-of-the-art topic models in generalization tasks and (ii) performs comparably to them on prediction tasks, while employing roughly the same number of parameters, and converging about two times faster.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Improving Simultaneous Machine Translation with Monolingual Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26497), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26497/26269), [keywords](SNLP: Machine Translation & Multilinguality), [abstract](Abstract
Simultaneous machine translation (SiMT) is usually done via sequence-level knowledge distillation (Seq-KD) from a full-sentence neural machine translation (NMT) model. However, there is still a significant performance gap between NMT and SiMT. In this work, we propose to leverage monolingual data to improve SiMT, which trains a SiMT student on the combination of bilingual data and external monolingual data distilled by Seq-KD. Preliminary experiments on En-Zh and En-Ja news domain corpora demonstrate that monolingual data can significantly improve translation quality (e.g., +3.15 BLEU on En-Zh). Inspired by the behavior of human simultaneous interpreters, we propose a novel monolingual sampling strategy for SiMT, considering both chunk length and monotonicity. Experimental results show that our sampling strategy consistently outperforms the random sampling strategy (and other conventional typical NMT monolingual sampling strategies) by avoiding the key problem of SiMT -- hallucination, and has better scalability. We achieve +0.72 BLEU improvements on average against random sampling on En-Zh and En-Ja. Data and codes can be found at https://github.com/hexuandeng/Mono4SiMT.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Domain-Adapted Dependency Parsing for Cross-Domain Named Entity Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26498), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26498/26270), [keywords](SNLP: Syntax -- Tagging, Chunking & Parsing, SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Other Foundations of Speech & Natural Language Processing, SNLP: Phonology, Morphology, Word Segmentation, SNLP: Text Mining), [abstract](Abstract
In recent years, many researchers have leveraged structural information from dependency trees to improve Named Entity Recognition (NER). Most of their methods take dependency-tree labels as input features for NER model training. However, such dependency information is not inherently provided in most NER corpora, making the methods with low usability in practice. To effectively exploit the potential of word-dependency knowledge, motivated by the success of Multi-Task Learning on cross-domain NER, we investigate a novel NER learning method incorporating cross-domain Dependency Parsing (DP) as its auxiliary learning task. Then, considering the high consistency of word-dependency relations across domains, we present an unsupervised domain-adapted method to transfer word-dependency knowledge from high-resource domains to low-resource ones. With the help of cross-domain DP to bridge different domains, both useful cross-domain and cross-task knowledge can be learned by our model to considerably benefit cross-domain NER. To make better use of the cross-task knowledge between NER and DP, we unify both tasks in a shared network architecture for joint learning, using Maximum Mean Discrepancy(MMD). Finally, through extensive experiments, we show our proposed method can not only effectively take advantage of word-dependency knowledge, but also significantly outperform other Multi-Task Learning methods on cross-domain NER. Our code is open-source and available at https://github.com/xianghuisun/DADP.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
MultiSpider- Towards Benchmarking Multilingual Text-to-SQL Semantic Parsing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26499), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26499/26271), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Question Answering, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Syntax -- Tagging, Chunking & Parsing), [abstract](Abstract
Text-to-SQL semantic parsing is an important NLP task, which facilitates the interaction between users and the database. Much recent progress in text-to-SQL has been driven by large-scale datasets, but most of them are centered on English. In this work, we present MultiSpider, the largest multilingual text-to-SQL semantic parsing dataset which covers seven languages (English, German, French, Spanish, Japanese, Chinese, and Vietnamese). Upon MultiSpider we further identify the lexical and structural challenges of text-to-SQL  (caused by specific language properties and dialect sayings) and their intensity across different languages. Experimental results under various settings (zero-shot, monolingual and multilingual) reveal a 6.1% absolute drop in accuracy in non-English languages. Qualitative and quantitative analyses are conducted to understand the reason for the performance drop of each language. Besides the dataset, we also propose a simple schema augmentation framework SAVe (Schema-Augmentation-with-Verification), which significantly boosts the overall performance by about 1.8% and closes the 29.5% performance gap across languages.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learning to Select from Multiple Options | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26500), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26500/26272), [keywords](SNLP: Applications, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Text Classification), [abstract](Abstract
Many NLP tasks can be regarded as a selection problem from a set of options, such as classification tasks, multi-choice question answering, etc. Textual entailment (TE) has been shown as the state-of-the-art (SOTA) approach to dealing with those selection problems. TE treats input texts as premises (P), options as hypotheses (H), then handles the selection problem by modeling (P, H) pairwise. Two limitations: first, the pairwise modeling is unaware of other options, which is less intuitive since humans often determine the best options by comparing competing candidates; second, the inference process of pairwise TE is time-consuming, especially when the option space is large. To deal with the two issues, this work first proposes a contextualized TE model (Context-TE) by appending other k options as the context of the current (P, H) modeling. Context-TE is able to learn more reliable decision for the H since it considers various context. Second, we speed up Context-TE by coming up with Parallel-TE, which learns the decisions of multiple options simultaneously. Parallel-TE significantly improves the inference speed while keeping comparable performance with Context-TE. Our methods are evaluated on three tasks (ultra-fine entity typing, intent detection and multi-choice QA) that are typical selection problems with different sizes of options. Experiments show our models set new SOTA performance; particularly, Parallel-TE is faster than the pairwise TE by k times in inference.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Real or Fake Text-- Investigating Human Ability to Detect Boundaries between Human-Written and Machine-Generated Text | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26501), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26501/26273), [keywords](SNLP: Interpretability & Analysis of NLP Models, SNLP: Language Models, HAI: Learning Human Values and Preferences, SNLP: Generation, SNLP: Bias, Fairness, Transparency & Privacy), [abstract](Abstract
As text generated by large language models proliferates, it becomes vital to understand how humans engage with such text, and whether or not they are able to detect when the text they are reading did not originate with a human writer. Prior work on human detection of generated text focuses on the case where an entire passage is either human-written or machine-generated. In this paper, we study a more realistic setting where text begins as human-written and transitions to being generated by state-of-the-art neural language models. We show that, while annotators often struggle at this task, there is substantial variance in annotator skill and that given proper incentives, annotators can improve at this task over time. Furthermore, we conduct a detailed comparison study and analyze how a variety of variables (model size, decoding strategy, fine-tuning, prompt genre, etc.) affect human detection performance. Finally, we collect error annotations from our participants and use them to show that certain textual genres influence models to make different types of errors and that certain sentence-level features correlate highly with annotator selection. We release the RoFT dataset: a collection of over 21,000 human annotations paired with error classifications to encourage future work in human detection and evaluation of generated text.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Diffuser- Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26502), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26502/26274), [keywords](SNLP: Language Models, ML: Classification and Regression, ML: Deep Neural Network Algorithms, ML: Graph-based Machine Learning, SNLP: Question Answering, SNLP: Text Classification), [abstract](Abstract
Efficient Transformers have been developed for long sequence modeling, due to their subquadratic memory and time complexity. Sparse Transformer is a popular approach to improving the efficiency of Transformers by restricting self-attention to locations specified by the predefined sparse patterns. However, leveraging sparsity may sacrifice expressiveness compared to full-attention, when important token correlations are multiple hops away. To combine advantages of both the efficiency of sparse transformer and the expressiveness of full-attention Transformer, we propose Diffuser, a new state-of-the-art efficient Transformer. Diffuser incorporates all token interactions within one attention layer while maintaining low computation and memory costs. The key idea is to expand the receptive field of sparse attention using Attention Diffusion, which computes multi-hop token correlations based on all paths between corresponding disconnected tokens, besides attention among neighboring tokens. Theoretically, we show the expressiveness of Diffuser as a universal sequence approximator for sequence-to-sequence modeling, and investigate its ability to approximate full-attention by analyzing the graph expander property from the spectral perspective. Experimentally, we investigate the effectiveness of Diffuser with extensive evaluations, including language modeling, image modeling, and Long Range Arena (LRA).  Evaluation results show that Diffuser achieves improvements by an average of 0.94% on text classification tasks and 2.30% on LRA, with 1.67x memory savings compared to state-of-the-art benchmarks, which demonstrates superior performance of Diffuser in both expressiveness and efficiency aspects.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Cogito Ergo Summ- Abstractive Summarization of Biomedical Papers via Semantic Parsing Graphs and Consistency Rewards | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26503), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26503/26275), [keywords](SNLP: Summarization, APP: Bioinformatics, ML: Deep Neural Architectures, ML: Reinforcement Learning Algorithms, SNLP: Generation, SNLP: Language Grounding, SNLP: Language Models, SNLP: Learning & Optimization for SNLP, SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Sentence-Level Semantics and Textual Inference, KRR: Other Foundations of Knowledge Representation & Reasoning), [abstract](Abstract
The automatic synthesis of biomedical publications catalyzes a profound research interest elicited by literature congestion. Current sequence-to-sequence models mainly rely on the lexical surface and seldom consider the deep semantic interconnections between the entities mentioned in the source document. Such superficiality translates into fabricated, poorly informative, redundant, and near-extractive summaries that severely restrict their real-world application in biomedicine, where the specialized jargon and the convoluted facts further emphasize task complexity. To fill this gap, we argue that the summarizer should acquire semantic interpretation over input, exploiting structured and unambiguous representations to capture and conserve the most relevant parts of the text content. This paper presents CogitoErgoSumm, the first framework for biomedical abstractive summarization equipping large pre-trained language models with rich semantic graphs. Precisely, we infuse graphs from two complementary semantic parsing techniques with different goals and granularities—Event Extraction and Abstract Meaning Representation, also designing a reward signal to maximize information content preservation through reinforcement learning. Extensive quantitative and qualitative evaluations on the CDSR dataset show that our solution achieves competitive performance according to multiple metrics, despite using 2.5x fewer parameters. Results and ablation studies indicate that our joint text-graph model generates more enlightening, readable, and consistent summaries. Code available at: https://github.com/disi-unibo-nlp/cogito-ergo-summ.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
MIGA- A Unified Multi-Task Generation Framework for Conversational Text-to-SQL | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26504), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26504/26276), [keywords](SNLP: Generation, ML: Transfer, Domain Adaptation, Multi-Task Learning, SNLP: Conversational AI/Dialogue Systems, SNLP: Language Models), [abstract](Abstract
Conversational text-to-SQL is designed to translate multi-turn natural language questions into their corresponding SQL queries. Most advanced conversational text-to-SQL methods are incompatible with generative pre-trained language models (PLMs), such as T5. In this paper, we present a two-stage unified MultI-task Generation frAmework (MIGA) that leverages PLMs’ ability to tackle conversational text-to-SQL. In the pre-training stage, MIGA first decomposes the main task into several related sub-tasks and then unifies them into the same sequence-to-sequence (Seq2Seq) paradigm with task-specific natural language prompts to boost the main task from multi-task training. Later in the fine-tuning stage, we propose four SQL perturbations to alleviate the error propagation problem. MIGA tends to achieve state-of-the-art performance on two benchmarks (SparC and CoSQL). We also provide extensive analyses and discussions to shed light on some new perspectives for conversational text-to-SQL.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
On the Effectiveness of Parameter-Efficient Fine-Tuning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26505), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26505/26277), [keywords](SNLP: Interpretability & Analysis of NLP Models, SNLP: Adversarial Attacks & Robustness, SNLP: Other Foundations of Speech & Natural Language Processing), [abstract](Abstract
Fine-tuning pre-trained models has been ubiquitously proven to be effective in a wide range of NLP tasks. However, fine-tuning the whole model is parameter inefficient as it always yields an entirely new model for each task. Currently, many research works propose to only fine-tune a small portion of the parameters while keeping most of the parameters shared across different tasks. These methods achieve surprisingly good performance and are shown to be more stable than their corresponding fully fine-tuned counterparts. However, such kind of methods is still not well understood. Some natural questions arise: How does the parameter sparsity lead to promising performance? Why is the model more stable than the fully fine-tuned models? How to choose the tunable parameters? In this paper, we first categorize the existing methods into random approaches, rule-based approaches, and projection-based approaches based on how they choose which parameters to tune. Then, we show that all of the methods are actually sparse fine-tuned models and conduct a novel theoretical analysis of them. We indicate that the sparsity is actually imposing a regularization on the original model by controlling the upper bound of the stability. Such stability leads to better generalization capability which has been empirically observed in a lot of recent research works. Despite the effectiveness of sparsity grounded by our theory, it still remains an open problem of how to choose the tunable parameters. Currently, the random and rule-based methods do not utilize task-specific data information while the projection-based approaches suffer from the projection discontinuity problem. To better choose the tunable parameters, we propose a novel Second-order Approximation Method (SAM) which approximates the original problem with an analytically solvable optimization function. The tunable parameters are determined by directly optimizing the approximation function. We conduct extensive experiments on several tasks. The experimental results show that our proposed SAM model outperforms many strong baseline models and it also verifies our theoretical analysis. The source code of this paper can be obtained from https://github.com/fuzihaofzh/AnalyzeParameterEff\/icientFinetune .), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SumREN- Summarizing Reported Speech about Events in News | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26506), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26506/26278), [keywords](SNLP: Summarization, SNLP: Applications, SNLP: Generation, SNLP: Question Answering), [abstract](Abstract
A primary objective of news articles is to establish the factual record for an event, frequently achieved by conveying both the details of the specified event (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and how people reacted to it (i.e., reported statements). However, existing work on news summarization almost exclusively focuses on the event details. In this work, we propose the novel task of summarizing the reactions of different speakers, as expressed by their reported statements, to a given event. To this end, we create a new multi-document summarization benchmark, SumREN, comprising 745 summaries of reported statements from various public figures obtained from 633 news articles discussing 132 events. We propose an automatic silver-training data generation approach for our task, which helps smaller models like BART achieve GPT-3 level performance on this task. Finally, we introduce a pipeline-based framework for summarizing reported speech, which we empirically show to generate summaries that are more abstractive and factual than baseline query-focused summarization approaches.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
ProKD- An Unsupervised Prototypical Knowledge Distillation Network for Zero-Resource Cross-Lingual Named Entity Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26507), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26507/26279), [keywords](SNLP: Applications, SNLP: Information Extraction), [abstract](Abstract
For named entity recognition (NER) in zero-resource languages, utilizing knowledge distillation methods to transfer language-independent knowledge from the rich-resource source languages to zero-resource languages is an effective means. Typically, these approaches adopt a teacher-student architecture, where the teacher network is trained in the source language, and the student network seeks to learn knowledge from the teacher network and is expected to perform well in the target language. Despite the impressive performance achieved by these methods, we argue that they have two limitations. Firstly, the teacher network fails to effectively learn language-independent knowledge shared across languages due to the differences in the feature distribution between the source and target languages. Secondly,  the student network acquires all of its knowledge from the teacher network and ignores the learning of target language-specific knowledge.
Undesirably, these limitations would hinder the model's performance in the target language. This paper proposes an unsupervised prototype knowledge distillation network (ProKD) to address these issues. Specifically, ProKD presents a contrastive learning-based prototype alignment method to achieve class feature alignment by adjusting the prototypes' distance from the source and target languages, boosting the teacher network's capacity to acquire language-independent knowledge. In addition, ProKD introduces a prototype self-training method to learn the intrinsic structure of the language by retraining the student network on the target data using samples' distance information from prototypes, thereby enhancing the student network's ability to acquire language-specific knowledge. Extensive experiments on three benchmark cross-lingual NER datasets demonstrate the effectiveness of our approach.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Denoising Pre-training for Machine Translation Quality Estimation with Curriculum Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26508), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26508/26280), [keywords](SNLP: Machine Translation & Multilinguality), [abstract](Abstract
Quality estimation (QE) aims to assess the quality of machine translations when reference translations are unavailable. QE plays a crucial role in many real-world applications of machine translation. Because labeled QE data are usually limited in scale, recent research, such as DirectQE, pre-trains QE models with pseudo QE data and obtains remarkable performance. However, there tends to be inevitable noise in the pseudo data, hindering models from learning QE accurately. Our study shows that the noise mainly comes from the differences between pseudo and real translation outputs. To handle this problem, we propose CLQE, a denoising pre-training framework for QE based on curriculum learning. More specifically, we propose to measure the degree of noise in the pseudo QE data with some metrics based on statistical or distributional features. With the guidance of these metrics, CLQE gradually pre-trains the QE model using data from cleaner to noisier. Experiments on various benchmarks reveal that CLQE outperforms DirectQE and other strong baselines. We also show that with our framework, pre-training converges faster than directly using the pseudo data. We make our CLQE code available (https://github.com/NJUNLP/njuqe).), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Generating Coherent Narratives by Learning Dynamic and Discrete Entity States with a Contrastive Framework | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26509), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26509/26281), [keywords](SNLP: Generation), [abstract](Abstract
Despite advances in generating fluent texts, existing pretraining models tend to attach incoherent event sequences to involved entities when generating narratives such as stories and news. We conjecture that such issues result from representing entities as static embeddings of superficial words, while neglecting to model their ever-changing states, i.e., the information they carry, as the text unfolds. Therefore, we extend the Transformer model to dynamically conduct entity state updates and sentence realization for narrative generation. We propose a contrastive framework to learn the state representations in a discrete space, and insert additional attention layers into the decoder to better exploit these states. Experiments on two narrative datasets show that our model can generate more coherent and diverse narratives than strong baselines with the guidance of meaningful entity states.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learning to Imagine- Distillation-Based Interactive Context Exploitation for Dialogue State Tracking | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26510), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26510/26282), [keywords](SNLP: Conversational AI/Dialogue Systems), [abstract](Abstract
In dialogue state tracking (DST), the exploitation of dialogue history is a crucial research direction, and the existing DST models can be divided into two categories: full-history models and partial-history models. Since the “select first, use later” mechanism explicitly filters the distracting information being passed to the downstream state prediction, the partial-history models have recently achieved a performance advantage over the full-history models. However, besides the redundant information, some critical dialogue context information was inevitably filtered out by the partial-history models simultaneously. To reconcile the contextual consideration with avoiding the introduction of redundant information, we propose DICE-DST, a model-agnostic module widely applicable to the partial-history DST models, which aims to strengthen the ability of context exploitation for the encoder of each DST model. Specifically, we first construct a teacher encoder and devise two contextual reasoning tasks to train it to acquire extensive dialogue contextual knowledge. Then we transfer the contextual knowledge from the teacher encoder to the student encoder via a novel turn-level attention-alignment distillation. Experimental results show that our approach extensively improves the performance of partial-history DST models and thereby achieves new state-of-the-art performance on multiple mainstream datasets while keeping high efficiency.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
RenewNAT- Renewing Potential Translation for Non-autoregressive Transformer | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26511), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26511/26283), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Generation), [abstract](Abstract
Non-autoregressive neural machine translation (NAT) models are proposed to accelerate the inference process while maintaining relatively high performance. However, existing NAT models are difficult to achieve the desired efficiency-quality trade-off. For one thing, fully NAT models with efficient inference perform inferior to their autoregressive counterparts. For another, iterative NAT models can, though, achieve comparable performance while diminishing the advantage of speed. In this paper, we propose RenewNAT, a flexible framework with high efficiency and effectiveness, to incorporate the merits of fully and iterative NAT models. RenewNAT first generates the potential translation results and then renews them in a single pass. It can achieve significant performance improvements at the same expense as traditional NAT models (without introducing additional model parameters and decoding latency). Experimental results on various translation benchmarks (e.g., 4 WMT) show that our framework consistently improves the performance of strong fully NAT methods (e.g., GLAT and DSLP) without additional speed overhead.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26512), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26512/26284), [keywords](SNLP: Text Classification), [abstract](Abstract
Contrastive learning-based methods, such as unsup-SimCSE, have achieved state-of-the-art (SOTA) performances in learning unsupervised sentence embeddings. However, in previous studies, each embedding used for contrastive learning only
derived from one sentence instance, and we call these embeddings instance-level embeddings. In other words, each embedding is regarded as a unique class of its own, which may hurt the generalization performance. In this study, we propose IS-CSE (instance smoothing contrastive sentence embedding) to smooth the boundaries of embeddings in the feature space. Specifically, we retrieve embeddings from a dynamic memory buffer according to the semantic similarity to get a positive embedding group. Then embeddings in the group are aggregated by a self-attention operation to produce a smoothed instance embedding for further analysis. We evaluate our method on standard semantic text similarity (STS) tasks and achieve an average of 78.30%, 79.47%, 77.73%, and 79.42% Spearman’s correlation on the base of BERT-base, BERT-large, RoBERTa-base, and RoBERTa-large respectively, a 2.05%, 1.06%, 1.16% and 0.52% improvement compared to unsup-SimCSE.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Competition or Cooperation- Exploring Unlabeled Data via Challenging Minimax Game for Semi-supervised Relation Extraction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26513), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26513/26285), [keywords](SNLP: Information Extraction, ML: Semi-Supervised Learning), [abstract](Abstract
Semi-Supervised Relation Extraction aims at learning well-performed RE models with limited labeled and large-scale unlabeled data. Existing methods mainly suffer from semantic drift and insufficient supervision, which severely limit the performance. To address these problems, recent work tends to design dual modules to work cooperatively for mutual enhancement. However, the consensus of two modules greatly restricts the model from exploring diverse relation expressions in unlabeled set, which hinders the performance as well as model generalization. To tackle this problem, in this paper, we propose a novel competition-based method AdvSRE. We set up a challenging minimax game on unlabeled data between two modules, Generator and Discriminator, and assign them with conflicting objectives. During the competition game, one module may find any possible chance to beat the other, which develops two modules' abilities until relation expressions cannot be further explored. To exploit label information, Discriminator is further asked to predict specific relation for each sentence. Experiment results on two benchmarks show new state-of-the-art performance over baselines, demonstrating the effectiveness of proposed AdvSRE.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Feature Normalization and Cartography-Based Demonstrations for Prompt-Based Fine-Tuning on Emotion-Related Tasks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26514), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26514/26286), [keywords](SNLP: Applications, SNLP: Text Classification), [abstract](Abstract
To train a model in a traditional supervised learning classification system for natural language processing (NLP) tasks, it is essential to have labeled data, which is not present in large amounts for many tasks. Prompt-based learning methods attempt to combat the supervised learning need for labeled data by directly adapting pre-trained language models and modeling the probability of text itself. In this paper, we propose a novel data-agnostic strategy for prompt-based fine-tuning that leverages feature moments (a.k.a., mean and standard deviation) as a data augmentation technique and employs training dynamics (i.e., confidence and variability) to allow more informative samples to be concatenated for generating demonstrations as input context. Our approach is a strong method for few-shot learning that forces the language model to pay special attention to the feature moments and allows more informative samples to be concatenated for generating demonstrations as input context by selecting high confidence and low variance samples. To demonstrate its effectiveness given limited training data, we conduct extensive experiments in different few-shot settings on three empathy and emotion classification datasets (from various domains).  We further evaluate our method's robustness by introducing noise to our few-shot input data and labels and show that exchanging moments between samples and incorporating cartography-based demonstrations are beneficial when the available data is limited and noisy.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Simple Yet Effective Subsequence-Enhanced Approach for Cross-Domain NER | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26515), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26515/26287), [keywords](SNLP: Information Extraction, ML: Transfer, Domain Adaptation, Multi-Task Learning), [abstract](Abstract
Cross-domain named entity recognition (NER), aiming to address the limitation of labeled resources in the target domain, is a challenging yet important task. Most existing studies alleviate the data discrepancy across different domains at the coarse level via combing NER with language modelings or introducing domain-adaptive pre-training (DAPT). Notably, source and target domains tend to share more fine-grained local information within denser subsequences than global information within the whole sequence, such that subsequence features are easier to transfer, which has not been explored well. Besides, compared to token-level representation, subsequence-level information can help the model distinguish different meanings of the same word in different domains. In this paper, we propose to incorporate subsequence-level features for promoting the cross-domain NER. In detail, we first utilize a pre-trained encoder to extract the global information. Then, we re-express each sentence as a group of subsequences and propose a novel bidirectional memory recurrent unit (BMRU) to capture features from the subsequences. Finally, an adaptive coupling unit (ACU) is proposed to combine global information and subsequence features for predicting entity labels. Experimental results on several benchmark datasets illustrate the effectiveness of our model, which achieves considerable improvements.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Question-Answering Approach to Key Value Pair Extraction from Form-Like Document Images | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26516), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26516/26288), [keywords](SNLP: Information Extraction), [abstract](Abstract
In this paper, we present a new question-answering (QA) based key-value pair extraction approach, called KVPFormer, to robustly extracting key-value relationships between entities from form-like document images. Specifically, KVPFormer first identifies key entities from all entities in an image with a Transformer encoder, then takes these key entities as questions and feeds them into a Transformer decoder to predict their corresponding answers (i.e., value entities) in parallel. To achieve higher answer prediction accuracy, we propose a coarse-to-fine answer prediction approach further, which first extracts multiple answer candidates for each identified question in the coarse stage and then selects the most likely one among these candidates in the fine stage. In this way, the learning difficulty of answer prediction can be effectively reduced so that the prediction accuracy can be improved. Moreover, we introduce a spatial compatibility attention bias into the self-attention/cross-attention mechanism for KVPFormer to better model the spatial interactions between entities. With these new techniques, our proposed KVPFormer achieves state-of-the-art results on FUNSD and XFUND datasets, outperforming the previous best-performing method by 7.2% and 13.2% in F1 score, respectively.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SEAT- Stable and Explainable Attention | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26517), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26517/26289), [keywords](SNLP: Interpretability & Analysis of NLP Models, ML: Transparent, Interpretable, Explainable ML), [abstract](Abstract
Attention mechanism has become a standard fixture in many state-of-the-art natural language processing (NLP) models, not only due to its outstanding performance, but also because it provides plausible innate explanations for neural architectures. However, recent studies show that attention is unstable against randomness and perturbations during training or testing, such as random seeds and slight perturbation of embeddings, which impedes it from being a faithful explanation tool. Thus, a natural question is whether we can find an alternative to vanilla attention, which is more stable and could keep the key characteristics of the explanation. In this paper, we provide a rigorous definition of such an attention method named SEAT (Stable and Explainable ATtention). Specifically, SEAT has the following three properties: (1) Its prediction distribution is close to the prediction of the vanilla attention; (2) Its top-k indices largely overlap with those of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any slight perturbation on SEAT will not change the attention and prediction distribution too much, which implicitly indicates that it is stable to randomness and perturbations. Furthermore, we propose an optimization method for obtaining SEAT, which could be considered as revising the vanilla attention. Finally, through intensive experiments on various datasets, we compare our SEAT with other baseline methods using RNN, BiLSTM and BERT architectures, with different evaluation metrics on model interpretation, stability and accuracy. Results show that, besides preserving the original explainability and model performance, SEAT is more stable against input perturbations and training randomness, which indicates it is a more faithful explanation.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Personalized Dialogue Generation with Persona-Adaptive Attention | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26518), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26518/26290), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Applications), [abstract](Abstract
Persona-based dialogue systems aim to generate consistent responses based on historical context and predefined persona. Unlike conventional dialogue generation, the persona-based dialogue needs to consider both dialogue context and persona, posing a challenge for coherent training. Specifically, this requires a delicate weight balance between context and persona. To achieve that, in this paper, we propose an effective framework with Persona-Adaptive Attention (PAA), which adaptively integrates the weights from the persona and context information via our designed attention. In addition, a dynamic masking mechanism is applied to the PAA to not only drop redundant information in context and persona but also serve as a regularization mechanism to avoid overfitting. Experimental results demonstrate the superiority of the proposed PAA framework compared to the strong baselines in both automatic and human evaluation. Moreover, the proposed PAA approach can perform equivalently well in a low-resource regime compared to models trained in a full-data setting, which achieve a similar result with only 20% to 30% of data compared to the larger models trained in the full-data setting. To fully exploit the effectiveness of our design, we designed several variants for handling the weighted information in different ways, showing the necessity and sufficiency of our weighting and masking designs.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Question Decomposition Tree for Answering Complex Questions over Knowledge Bases | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26519), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26519/26291), [keywords](SNLP: Question Answering, KRR: Ontologies and Semantic Web, SNLP: Syntax -- Tagging, Chunking & Parsing), [abstract](Abstract
Knowledge base question answering (KBQA) has attracted a lot of interest in recent years, especially for complex questions which require multiple facts to answer. Question decomposition is a promising way to answer complex questions. Existing decomposition methods split the question into sub-questions according to a single compositionality type, which is not sufficient for questions involving multiple compositionality types. In this paper, we propose Question Decomposition Tree (QDT) to represent the structure of complex questions. Inspired by recent advances in natural language generation (NLG), we present a two-staged method called Clue-Decipher to generate QDT. It can leverage the strong ability of NLG model and simultaneously preserve the original questions. To verify that QDT can enhance KBQA task, we design a decomposition-based KBQA system called QDTQA. Extensive experiments show that QDTQA outperforms previous state-of-the-art methods on ComplexWebQuestions dataset. Besides, our decomposition method improves an existing KBQA system by 12% and sets a new state-of-the-art on LC-QuAD 1.0.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Hierarchical Text Classification as Sub-hierarchy Sequence Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26520), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26520/26292), [keywords](SNLP: Text Classification, ML: Multi-Class/Multi-Label Learning & Extreme Classification, SNLP: Information Extraction, SNLP: Text Mining), [abstract](Abstract
Hierarchical text classification (HTC) is essential for various real applications. However, HTC models are challenging to develop because they often require processing a large volume of documents and labels with hierarchical taxonomy. Recent HTC models based on deep learning have attempted to incorporate hierarchy information into a model structure. Consequently, these models are challenging to implement when the model parameters increase for a large-scale hierarchy because the model structure depends on the hierarchy size. To solve this problem, we formulate HTC as a sub-hierarchy sequence generation to incorporate hierarchy information into a target label sequence instead of the model structure. Subsequently, we propose the Hierarchy DECoder (HiDEC), which decodes a text sequence into a sub-hierarchy sequence using recursive hierarchy decoding, classifying all parents at the same level into children at once. In addition, HiDEC is trained to use hierarchical path information from a root to each leaf in a sub-hierarchy composed of the labels of a target document via an attention mechanism and hierarchy-aware masking. HiDEC achieved state-of-the-art performance with significantly fewer model parameters than existing models on benchmark datasets, such as RCV1-v2, NYT, and EURLEX57K.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
IndicSUPERB- A Speech Processing Universal Performance Benchmark for Indian Languages | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26521), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26521/26293), [keywords](SNLP: Applications, SNLP: Speech and Multimodality), [abstract](Abstract
A cornerstone in AI research has been the creation and adoption of standardized training and test datasets to earmark the progress of state-of-the-art models. A particularly successful example is the GLUE dataset for training and evaluating Natural Language Understanding (NLU) models for English. The large body of research around self-supervised BERT-based language models revolved around performance improvements on NLU tasks in GLUE. To evaluate language models in other languages, several language-specific GLUE datasets were created. The area of speech language understanding (SLU) has followed a similar trajectory. The success of large self-supervised models such as wav2vec2 enable creation of speech models with relatively easy to access unlabelled data. These models can then be evaluated on SLU tasks, such as the SUPERB benchmark. In this work, we extend this to Indic languages by releasing the IndicSUPERB benchmark. Specifically, we make the following three contributions. (i) We collect Kathbath containing 1,684 hours of labelled speech data across 12 Indian languages from 1,218 contributors located in 203 districts in India. (ii) Using Kathbath, we create benchmarks across 6 speech tasks: Automatic Speech Recognition, Speaker Verification, Speaker Identification (mono/multi), Language Identification, Query By Example, and Keyword Spotting for 12 languages. (iii) On the released benchmarks, we train and evaluate different self-supervised models alongside the a commonly used baseline FBANK. We show that language-specific fine-tuned models are more accurate than baseline on most of the tasks, including a large gap of 76% for Language Identification task. However, for speaker identification, self-supervised models trained on large datasets demonstrate an advantage. We hope IndicSUPERB contributes to the progress of developing speech language understanding models for Indian languages.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SheetPT- Spreadsheet Pre-training Based on Hierarchical Attention Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26522), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26522/26294), [keywords](SNLP: Applications, APP: Business/Marketing/Advertising/E-Commerce, ML: Unsupervised & Self-Supervised Learning), [abstract](Abstract
Spreadsheets are an important and unique type of business document for data storage, analysis and presentation. The distinction between spreadsheets and most other types of digital documents lies in that spreadsheets provide users with high flexibility of data organization on the grid. Existing related techniques mainly focus on the tabular data and are incompetent in understanding the entire sheet. On the one hand, spreadsheets have no explicit separation across tabular data and other information, leaving a gap for the deployment of such techniques. On the other hand, pervasive data dependence and semantic relations across the sheet require comprehensive modeling of all the information rather than only the tables. In this paper, we propose SheetPT, the first pre-training technique on spreadsheets to enable effective representation learning under this scenario. For computational effectiveness and efficiency, we propose the coherent chunk, an intermediate semantic unit of sheet structure; and we accordingly devise a hierarchical attention-based architecture to capture contextual information across different structural granularities. Three pre-training objectives are also designed to ensure sufficient training against millions of spreadsheets. Two representative downstream tasks, formula prediction and sheet structure recognition are utilized to evaluate its capability and the prominent results reveal its superiority over existing state-of-the-art methods.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SeDepTTS- Enhancing the Naturalness via Semantic Dependency and Local Convolution for Text-to-Speech Synthesis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26523), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26523/26295), [keywords](SNLP: Other Foundations of Speech & Natural Language Processing, SNLP: Speech and Multimodality), [abstract](Abstract
Self-attention-based networks have obtained impressive performance in parallel training and global context modeling. However, it is weak in local dependency capturing, especially for data with strong local correlations such as utterances. Therefore, we will mine linguistic information of the original text based on a semantic dependency and the semantic relationship between nodes is regarded as prior knowledge to revise the distribution of self-attention. On the other hand, given the strong correlation between input characters, we introduce a one-dimensional (1-D) convolution neural network (CNN) producing query(Q) and value(V) in the self-attention mechanism for a better fusion of local contextual information. Then, we migrate this variant of the self-attention networks to speech synthesis tasks and propose a non-autoregressive (NAR) neural Text-to-Speech (TTS): SeDepTTS. Experimental results show that our model yields good performance in speech synthesis. Specifically, the proposed method yields significant improvement for the processing of pause, stress, and intonation in speech.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Prototypical Fine-Tuning- Towards Robust Performance under Varying Data Sizes | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26524), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26524/26296), [keywords](SNLP: Text Classification, SNLP: Bias, Fairness, Transparency & Privacy, SNLP: Interpretability & Analysis of NLP Models, SNLP: Language Models), [abstract](Abstract
In this paper, we move towards combining large parametric models with non-parametric prototypical networks. We propose prototypical fine-tuning, a novel prototypical framework for fine-tuning pretrained language models (LM), which automatically learns a bias to improve predictive performance for varying data sizes, especially low-resource settings. Our prototypical fine-tuning approach can automatically adjust the model capacity according to the number of data points and the model's inherent attributes. Moreover, we propose four principles for effective prototype fine-tuning towards the optimal solution. Experimental results across various datasets show that our work achieves significant performance improvements under various low-resource settings, as well as comparable and usually better performances in high-resource scenarios.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Cross-Modal Distillation for Speaker Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26525), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26525/26297), [keywords](SNLP: Speech and Multimodality, CV: Biometrics, Face, Gesture & Pose, CV: Multi-modal Vision, APP: Biometrics, ML: Multimodal Learning, ML: Representation Learning), [abstract](Abstract
Speaker recognition achieved great progress recently, however, it is not easy or efficient to further improve its performance via traditional solutions: collecting more data and designing new neural networks. Aiming at the fundamental challenge of speech data, i.e. low information density, multimodal learning can mitigate this challenge by introducing richer and more discriminative information as input for identity recognition. Specifically, since the face image is more discriminative than the speech for identity recognition, we conduct multimodal learning by introducing a face recognition model (teacher) to transfer discriminative knowledge to a speaker recognition model (student) during training. However, this knowledge transfer via distillation is not trivial because the big domain gap between face and speech can easily lead to overfitting. In this work, we introduce a multimodal learning framework, VGSR (Vision-Guided Speaker Recognition). Specifically, we propose a MKD (Margin-based Knowledge Distillation) strategy for cross-modality distillation by introducing a loose constrain to align the teacher and student, greatly reducing overfitting. Our MKD strategy can easily adapt to various existing knowledge distillation methods. In addition, we propose a QAW (Quality-based Adaptive Weights) module to weight input samples via quantified data quality, leading to a robust model training. Experimental results on the VoxCeleb1 and CN-Celeb datasets show our proposed strategies can effectively improve the accuracy of speaker recognition by a margin of 10% ∼ 15%, and our methods are very robust to different noises.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26526), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26526/26298), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Applications, SNLP: Discourse, Pragmatics & Argument Mining, SNLP: Generation, SNLP: Information Extraction, SNLP: Speech and Multimodality, SNLP: Summarization, SNLP: Text Classification), [abstract](Abstract
Conversations emerge as the primary media for exchanging ideas and conceptions. From the listener’s perspective, identifying various affective qualities, such as sarcasm, humour, and emotions, is paramount for comprehending the true connotation of the emitted utterance. However, one of the major hurdles faced in learning these affect dimensions is the presence of figurative language, viz. irony, metaphor, or sarcasm. We hypothesize that any detection system constituting the exhaustive and explicit presentation of the emitted utterance would improve the overall comprehension of the dialogue. To this end, we explore the task of Sarcasm Explanation in Dialogues, which aims to unfold the hidden irony behind sarcastic utterances. We propose MOSES, a deep neural network which takes a multimodal (sarcastic) dialogue instance as an input and generates a natural language sentence as its explanation. Subsequently, we leverage the generated explanation for various natural language understanding tasks in a conversational dialogue setup, such as sarcasm detection, humour identification, and emotion recognition. Our evaluation shows that MOSES outperforms the state-of-the-art system for SED by an average of ∼2% on different evaluation metrics, such as ROUGE, BLEU, and METEOR. Further, we observe that leveraging the generated explanation advances three downstream tasks for affect classification – an average improvement of ~14% F1-score in the sarcasm detection task and ∼2% in the humour identification and emotion recognition task. We also perform extensive analyses to assess the quality of the results.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
COCA- COllaborative CAusal Regularization for Audio-Visual Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26527), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26527/26299), [keywords](SNLP: Speech and Multimodality, CV: Language and Vision, CV: Multi-modal Vision), [abstract](Abstract
Audio-Visual Question Answering (AVQA) is a sophisticated QA task, which aims at answering textual questions over given video-audio pairs with comprehensive multimodal reasoning. Through detailed causal-graph analyses and careful inspections of their learning processes, we reveal that AVQA models are not only prone to over-exploit prevalent language bias, but also suffer from additional joint-modal biases caused by the shortcut relations between textual-auditory/visual co-occurrences and dominated answers. In this paper, we propose a COllabrative CAusal (COCA) Regularization to remedy this more challenging issue of data biases.
Specifically, a novel Bias-centered Causal Regularization (BCR) is proposed to alleviate specific shortcut biases by intervening bias-irrelevant causal effects, and further introspect the predictions of AVQA models in counterfactual and factual scenarios. Based on the fact that the dominated bias impairing model robustness for different samples tends to be different, we introduce a Multi-shortcut Collaborative Debiasing (MCD) to measure how each sample suffers from different biases, and dynamically adjust their debiasing concentration to different shortcut correlations. Extensive experiments demonstrate the effectiveness as well as backbone-agnostic ability of our COCA strategy, and it achieves state-of-the-art performance on the large-scale MUSIC-AVQA dataset.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Script, Language, and Labels- Overcoming Three Discrepancies for Low-Resource Language Specialization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26528), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26528/26300), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Language Models, SNLP: Learning & Optimization for SNLP, SNLP: Syntax -- Tagging, Chunking & Parsing), [abstract](Abstract
Although multilingual pretrained models (mPLMs) enabled support of various natural language processing in diverse languages, its limited coverage of 100+ languages lets 6500+ languages remain ‘unseen’. One common approach for an unseen language is specializing the model for it as target, by performing additional masked language modeling (MLM) with the target language corpus. However, we argue that, due to the discrepancy from multilingual MLM pretraining, a naive specialization as such can be suboptimal. Specifically, we pose three discrepancies to overcome. Script and linguistic discrepancy of the target language from the related seen languages, hinder a positive transfer, for which we propose to maximize representation similarity, unlike existing approaches maximizing overlaps. In addition, label space for MLM prediction can vary across languages, for which we propose to reinitialize top layers for a more effective adaptation. Experiments over four different language families and three tasks shows that our method improves the task performance of unseen languages with statistical significance, while previous approach fails to.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
LIQUID- A Framework for List Question Answering Dataset Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26529), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26529/26301), [keywords](SNLP: Question Answering), [abstract](Abstract
Question answering (QA) models often rely on large-scale training datasets, which necessitates the development of a data generation framework to reduce the cost of manual annotations. Although several recent studies have aimed to generate synthetic questions with single-span answers, no study has been conducted on the creation of list questions with multiple, non-contiguous spans as answers. To address this gap, we propose LIQUID, an automated framework for generating list QA datasets from unlabeled corpora. We first convert a passage from Wikipedia or PubMed into a summary and extract named entities from the summarized text as candidate answers. This allows us to select answers that are semantically correlated in context and is, therefore, suitable for constructing list questions. We then create questions using an off-the-shelf question generator with the extracted entities and original passage. Finally, iterative filtering and answer expansion are performed to ensure the accuracy and completeness of the answers. Using our synthetic data, we significantly improve the performance of the previous best list QA models by exact-match F1 scores of 5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ benchmarks.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
UniSyn- An End-to-End Unified Model for Text-to-Speech and Singing Voice Synthesis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26530), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26530/26302), [keywords](SNLP: Speech and Multimodality, SNLP: Generation), [abstract](Abstract
Text-to-speech (TTS) and singing voice synthesis (SVS) aim at generating high-quality speaking and singing voice according to textual input and music scores, respectively. Unifying TTS and SVS into a single system is crucial to the applications requiring both of them. Existing methods usually suffer from some limitations, which rely on either both singing and speaking data from the same person or cascaded models of multiple tasks. To address these problems, a simplified elegant framework for TTS and SVS, named UniSyn, is proposed in this paper. It is an end-to-end unified model that can make a voice speak and sing with only singing or speaking data from this person. To be specific, a multi-conditional variational autoencoder (MC-VAE), which constructs two independent latent sub-spaces with the speaker- and style-related (i.e. speak or sing) conditions for flexible control, is proposed in UniSyn. Moreover, supervised guided-VAE and timbre perturbation with the Wasserstein distance constraint are leveraged to further disentangle the speaker timbre and style. Experiments conducted on two speakers and two singers demonstrate that UniSyn can generate natural speaking and singing voice without corresponding training data. The proposed approach outperforms the state-of-the-art end-to-end voice generation work, which proves the effectiveness and advantages of UniSyn.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SoftCorrect- Error Correction with Soft Detection for Automatic Speech Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26531), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26531/26303), [keywords](SNLP: Speech and Multimodality, SNLP: Applications), [abstract](Abstract
Error correction in automatic speech recognition (ASR) aims to correct those incorrect words in sentences generated by ASR models. Since recent ASR models usually have low word error rate (WER), to avoid affecting originally correct tokens, error correction models should only modify incorrect words, and therefore detecting incorrect words is important for error correction. Previous works on error correction either implicitly detect error words through target-source attention or CTC (connectionist temporal classification) loss, or explicitly locate specific deletion/substitution/insertion errors. However, implicit error detection does not provide clear signal about which tokens are incorrect and explicit error detection suffers from low detection accuracy. In this paper, we propose SoftCorrect with a soft error detection mechanism to avoid the limitations of both explicit and implicit error detection. Specifically, we first detect whether a token is correct or not through a probability produced by a dedicatedly designed language model, and then design a constrained CTC loss that only duplicates the detected incorrect tokens to let the decoder focus on the correction of error tokens. Compared with implicit error detection with CTC loss, SoftCorrect provides explicit signal about which words are incorrect and thus does not need to duplicate every token but only incorrect tokens; compared with explicit error detection, SoftCorrect does not detect specific deletion/substitution/insertion errors but just leaves it to CTC loss. Experiments on AISHELL-1 and Aidatatang datasets show that SoftCorrect achieves 26.1% and 9.4% CER reduction respectively, outperforming previous works by a large margin, while still enjoying fast speed of parallel generation.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Sequence Generation with Label Augmentation for Relation Extraction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26532), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26532/26304), [keywords](SNLP: Information Extraction), [abstract](Abstract
Sequence generation demonstrates promising performance in recent information extraction efforts, by incorporating large-scale pre-trained Seq2Seq models. This paper investigates the merits of employing sequence generation in relation extraction, finding that with relation names or synonyms as generation targets, their textual semantics and the correlation (in terms of word sequence pattern) among them affect model performance. We then propose Relation Extraction with Label Augmentation (RELA), a Seq2Seq model with automatic label augmentation for RE. By saying label augmentation, we mean prod semantically synonyms for each relation name as the generation target. Besides, we present an in-depth analysis of the Seq2Seq model's behavior when dealing with RE. Experimental results show that RELA achieves competitive results compared with previous methods on four RE datasets.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Reviewing Labels- Label Graph Network with Top-k Prediction Set for Relation Extraction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26533), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26533/26305), [keywords](SNLP: Information Extraction), [abstract](Abstract
The typical way for relation extraction is fine-tuning large pre-trained language models on task-specific datasets, then selecting the label with the highest probability of the output
distribution as the final prediction. However, the usage of the Top-k prediction set for a given sample is commonly overlooked. In this paper, we first reveal that the Top-k prediction
set of a given sample contains useful information for predicting the correct label. To effectively utilizes the Top-k prediction set, we propose Label Graph Network with Top-k Prediction Set, termed as KLG. Specifically, for a given sample, we build a label graph to review candidate labels in the Top-k prediction set and learn the connections between them. We also design a dynamic k selection mechanism to learn more powerful and discriminative relation representation. Our experiments show that KLG achieves the best performances on three relation extraction datasets. Moreover, we observe thatKLG is more effective in dealing with long-tailed classes.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Online Noisy Continual Relation Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26534), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26534/26306), [keywords](SNLP: Information Extraction), [abstract](Abstract
Recent work for continual relation learning has achieved remarkable progress. However, most existing methods only focus on tackling catastrophic forgetting to improve performance in the existing setup, while continually learning relations in the real-world must overcome many other challenges. One is that the data possibly comes in an online streaming fashion with data distributions gradually changing and without distinct task boundaries. Another is that noisy labels are inevitable in real-world, as relation samples may be contaminated by label inconsistencies or labeled with distant supervision. In this work, therefore, we propose a novel continual relation learning framework that simultaneously addresses both online and noisy relation learning challenges. Our framework contains three key modules: (i) a sample separated online purifying module that divides the online data stream into clean and noisy samples, (ii) a self-supervised online learning module that circumvents inferior training signals caused by noisy data, and (iii) a semi-supervised offline finetuning module that ensures the participation of both clean and noisy samples. Experimental results on FewRel, TACRED and NYT-H with real-world noise demonstrate that our framework greatly outperforms the combinations of the state-of-the-art online continual learning and noisy label learning methods.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
RESDSQL- Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26535), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26535/26307), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Language Models), [abstract](Abstract
One of the recent best attempts at Text-to-SQL is the pre-trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items (i.e., tables and columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase the difficulty of parsing the correct SQL queries especially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole unordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder first generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our proposed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The experimental results show that our framework delivers promising performance and robustness. Our code is available at https://github.com/RUCKBReasoning/RESDSQL.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Graphix-T5- Mixing Pre-trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26536), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26536/26308), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing), [abstract](Abstract
The task of text-to-SQL parsing, which aims at converting natural language questions into executable SQL queries, has garnered increasing attention in recent years. One of the major challenges in text-to-SQL parsing is domain generalization, i.e., how to generalize well to unseen databases. Recently, the pre-trained text-to-text transformer model, namely T5, though not specialized for text-to-SQL parsing, has achieved state-of-the-art performance on standard benchmarks targeting domain generalization. In this work, we explore ways to further augment the pre-trained T5 model with specialized components for text-to-SQL parsing. Such components are expected to introduce structural inductive bias into text-to-SQL parsers thus improving the model’s capacity on (potentially multi-hop) reasoning, which is critical for generating structure-rich SQLs. To this end, we propose a new architecture GRAPHIX-T5, a mixed model with the standard pre-trained transformer model augmented by specially-designed graph-aware layers. Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5 across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5 surpasses all other T5-based parsers with a significant margin, achieving new state-of-the-art performance. Notably, GRAPHIX-T5-large reaches performance superior to the original T5-large by 5.7% on exact match (EM) accuracy and 6.6% on execution accuracy (EX). This even outperforms the T5-3B by 1.2% on EM and 1.5% on EX), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26537), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26537/26309), [keywords](SNLP: Summarization, ML: Graph-based Machine Learning, ML: Transfer, Domain Adaptation, Multi-Task Learning, SNLP: Generation), [abstract](Abstract
Multi-document summarization (MDS) aims to generate a summary for a number of related documents. We propose HGSum — an MDS model that extends an encoder-decoder architecture to incorporate a heterogeneous graph to represent different semantic units (e.g., words and sentences) of the documents. This contrasts with existing MDS models which do not consider different edge types of graphs and as such do not capture the diversity of relationships in the documents. To preserve only key information and relationships of the documents in the heterogeneous graph, HGSum uses graph pooling to compress the input graph. And to guide HGSum to learn the compression, we introduce an additional objective that maximizes the similarity between the compressed graph and the graph constructed from the ground-truth summary during training. HGSum is trained end-to-end with the graph similarity and standard cross-entropy objectives. Experimental results over Multi-News, WCEP-100, and Arxiv show that HGSum outperforms state-of-the-art MDS models. The code for our model and experiments is available at: https://github.com/oaimli/HGSum.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
TrOCR- Transformer-Based Optical Character Recognition with Pre-trained Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26538), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26538/26310), [keywords](SNLP: Applications, CV: Language and Vision), [abstract](Abstract
Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at https://aka.ms/trocr.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Mitigating Negative Style Transfer in Hybrid Dialogue System | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26539), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26539/26311), [keywords](SNLP: Conversational AI/Dialogue Systems), [abstract](Abstract
As the functionality of dialogue systems evolves, hybrid dialogue systems that accomplish user-specific goals and participate in open-topic chitchat with users are attracting growing attention. Existing research learns both tasks concurrently utilizing a multi-task fusion technique but ignores the negative transfer phenomenon induced by the unique textual style differences. Therefore, contrastive learning based on the latent variable model is used to decouple the various textual genres in the latent space. We devise supervised and self-supervised positive and negative sample constructions for diverse datasets. In addition, to capitalize on the style information contained in the decoupled latent variables, we employ a style prefix that incorporates latent variables further to control the generation of responses with varying styles. We performed extensive experiments on three dialogue datasets, including a hybrid dialogue dataset and two task-oriented dialogue datasets. The experimental results demonstrate that our method can mitigate the negative style transfer issue and achieves state-of-the-art performance on multiple dialogue datasets.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Low Resource Quantitative Information Extraction via Structure Searching and Prefix-Based Text Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26540), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26540/26312), [keywords](SNLP: Information Extraction, SNLP: Generation), [abstract](Abstract
Quantitative information plays an important part in the financial and data analysis areas. Prior work relied on pattern-matching methods and complex hand-crafted rules to extract quantitative information due to the lack of labeled data. Such methods can be unstable and difficult to scale to the open domain. In this paper, we study quantitative information extraction in the low-resource setting. We propose a search-based approach by searching from the syntactic structures to acquire basic training data. The search process is simple yet effective. Then, a prefix-based text-to-text generation method is employed to extract the quantitative information. The prefix design can fully leverage pre-trained language models for text generation to serve the information extraction purpose. Experimental results show that our approaches achieves high performance with a limited amount of labeled data. The extraction result could further boost the performance of other tasks such as quantitative reasoning.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SKIER- A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26541), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26541/26313), [keywords](SNLP: Applications, SNLP: Sentiment Analysis and Stylistic Analysis), [abstract](Abstract
Emotion recognition in conversation (ERC) has received increasing attention from the research community. However, the ERC task is challenging, largely due to the complex and unstructured properties of multi-party conversations. Besides, the majority of daily dialogues take place in a specific context or circumstance, which requires rich external knowledge to understand the background of a certain dialogue. In this paper, we address these challenges by explicitly modeling the discourse relations between utterances and incorporating symbolic knowledge into multi-party conversations. We first introduce a dialogue parsing algorithm into ERC and further improve the algorithm through a transfer learning method. Moreover, we leverage different symbolic knowledge graph relations to learn knowledge-enhanced features for the ERC task. Extensive experiments on three benchmarks demonstrate that both dialogue structure graphs and symbolic knowledge are beneficial to the model performance on the task. Additionally, experimental results indicate that the proposed model surpasses baseline models on several indices.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
PGSS- Pitch-Guided Speech Separation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26542), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26542/26314), [keywords](SNLP: Speech and Multimodality, SNLP: Applications, SNLP: Other Foundations of Speech & Natural Language Processing), [abstract](Abstract
Monaural speech separation aims to separate concurrent speakers from a single-microphone mixture recording. Inspired by the effect of pitch priming in auditory scene analysis (ASA) mechanisms, a novel pitch-guided speech separation framework is proposed in this work. The prominent advantage of this framework is that both the permutation problem and the unknown speaker number problem existing in general models can be avoided by using pitch contours as the primary means to guide the target speaker. In addition, adversarial training is applied, instead of a traditional time-frequency mask, to improve the perceptual quality of separated speech. Specifically, the proposed framework can be divided into two phases: pitch extraction and speech separation. The former aims to extract pitch contour candidates for each speaker from the mixture, modeling the bottom-up process in ASA mechanisms. Any pitch contour can be selected as the condition in the second phase to separate the corresponding speaker, where a conditional generative adversarial network (CGAN) is applied. The second phase models the effect of pitch priming in ASA. Experiments on the WSJ0-2mix corpus reveal that the proposed approaches can achieve higher pitch extraction accuracy and better separation performance, compared to the baseline models, and have the potential to be applied to SOTA architectures.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
DyRRen- A Dynamic Retriever-Reranker-Generator Model for Numerical Reasoning over Tabular and Textual Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26543), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26543/26315), [keywords](SNLP: Question Answering), [abstract](Abstract
Numerical reasoning over hybrid data containing tables and long texts has recently received research attention from the AI community. To generate an executable reasoning program consisting of math and table operations to answer a question, state-of-the-art methods use a retriever-generator pipeline. However, their retrieval results are static, while different generation steps may rely on different sentences. To attend to the retrieved information that is relevant to each generation step, in this paper, we propose DyRRen, an extended retriever-reranker-generator framework where each generation step is enhanced by a dynamic reranking of retrieved sentences. It outperforms existing baselines on the FinQA dataset.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Heterogeneous-Branch Collaborative Learning for Dialogue Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26544), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26544/26316), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Generation), [abstract](Abstract
With the development of deep learning, advanced dialogue generation methods usually require a greater amount of computational resources. One promising approach to obtaining a high-performance and lightweight model is knowledge distillation, which relies heavily on the pre-trained powerful teacher. Collaborative learning, also known as online knowledge distillation, is an effective way to conduct one-stage group distillation in the absence of a well-trained large teacher model. However, previous work has a severe branch homogeneity problem due to the same training objective and the independent identical training sets.  To alleviate this problem, we consider the dialogue attributes in the training of network branches. Each branch learns the attribute-related features based on the selected subset. Furthermore, we propose a dual group-based knowledge distillation method, consisting of positive distillation and negative distillation, to further diversify the features of different branches in a steadily and interpretable way. The proposed approach significantly improves branch heterogeneity and outperforms state-of-the-art collaborative learning methods on two widely used open-domain dialogue datasets.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learning to Know Myself- A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26545), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26545/26317), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Generation), [abstract](Abstract
A critical challenge for open-domain dialogue agents is to generate persona-relevant and consistent responses. Due to the nature of persona sparsity in conversation scenarios, previous persona-based dialogue agents trained with Maximum Likelihood Estimation tend to overlook the given personas and generate responses irrelevant or inconsistent with personas. To address this problem, we propose a two-stage coarse-to-fine persona-aware training framework to improve the persona consistency of a dialogue agent progressively. Specifically, our framework first trains the dialogue agent to answer the constructed persona-aware questions, making it highly sensitive to the personas to generate persona-relevant responses. Then the dialogue agent is further trained with a contrastive learning paradigm by explicitly perceiving the difference between the consistent and the generated inconsistent responses, forcing it to pay more attention to the key persona information to generate consistent responses. By applying our proposed training framework to several representative baseline models, experimental results show significant boosts on both automatic and human evaluation metrics, especially the consistency of generated responses.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
WIERT- Web Information Extraction via Render Tree | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26546), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26546/26318), [keywords](SNLP: Information Extraction, KRR: Knowledge Engineering, SNLP: Applications, SNLP: Language Models, SNLP: Question Answering, SNLP: Speech and Multimodality, SNLP: Text Mining), [abstract](Abstract
Web information extraction (WIE) is a fundamental problem in web document understanding, with a significant impact on various applications. Visual information plays a crucial role in WIE tasks as the nodes containing relevant information are often visually distinct, such as being in a larger font size or having a brighter color, from the other nodes. However, rendering visual information of a web page can be computationally expensive. Previous works have mainly focused on the Document Object Model (DOM) tree, which lacks visual information. To efficiently exploit visual information, we propose leveraging the render tree, which combines the DOM tree and Cascading Style Sheets Object Model (CSSOM) tree, and contains not only content and layout information but also rich visual information at a little additional acquisition cost compared to the DOM tree. In this paper, we present WIERT, a method that effectively utilizes the render tree of a web page based on a pretrained language model. We evaluate WIERT on the Klarna product page dataset, a manually labeled dataset of renderable e-commerce web pages, demonstrating its effectiveness and robustness.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
STAGE- Span Tagging and Greedy Inference Scheme for Aspect Sentiment Triplet Extraction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26547), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26547/26319), [keywords](SNLP: Sentiment Analysis and Stylistic Analysis, SNLP: Information Extraction), [abstract](Abstract
Aspect Sentiment Triplet Extraction (ASTE) has become an emerging task in sentiment analysis research, aiming to extract triplets of the aspect term, its corresponding opinion term, and its associated sentiment polarity from a given sentence. Recently, many neural networks based models with different tagging schemes have been proposed, but almost all of them have their limitations: heavily relying on 1) prior assumption that each word is only associated with a single role (e.g., aspect term, or opinion term, etc. ) and 2) word-level interactions and treating each opinion/aspect as a set of independent words. Hence, they perform poorly on the complex ASTE task, such as a word associated with multiple roles or an aspect/opinion term with multiple words. Hence, we propose a novel approach, Span TAgging and Greedy infErence (STAGE), to extract sentiment triplets in span-level, where each span may consist of multiple words and play different roles simultaneously. To this end, this paper formulates the ASTE task as a multi-class span classification problem. Specifically, STAGE generates more accurate aspect sentiment triplet extractions via exploring span-level information and constraints, which consists of two components, namely, span tagging scheme and greedy inference strategy. The former tag all possible candidate spans based on a newly-defined tagging set. The latter retrieves the aspect/opinion term with the maximum length from the candidate sentiment snippet to output sentiment triplets. Furthermore, we propose a simple but effective model based on the STAGE, which outperforms the state-of-the-arts by a large margin on four widely-used datasets. Moreover, our STAGE can be easily generalized to other pair/triplet extraction tasks, which also demonstrates the superiority of the proposed scheme STAGE.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Generalizing Math Word Problem Solvers via Solution Diversification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26548), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26548/26320), [keywords](SNLP: Question Answering, KRR: Argumentation, ML: Applications, ML: Probabilistic Methods, SNLP: Applications), [abstract](Abstract
Current math word problem (MWP) solvers are usually Seq2Seq models  trained by the (one-problem; one-solution) pairs, each of which is made of a problem description and a solution showing reasoning flow to get the correct answer. However, one MWP problem naturally has multiple solution equations. The training of an MWP solver with (one-problem; one-solution) pairs excludes other correct solutions, and thus limits the generalizability of the MWP solver. One feasible solution to this limitation is to augment multiple solutions to a given problem. However, it is difficult to collect diverse and accurate augment solutions through human efforts. In this paper, we design a new training framework for an MWP solver by introducing a solution buffer and a solution discriminator. The buffer includes solutions generated by an MWP solver to encourage  the training data diversity.  The discriminator controls the quality of buffered solutions to participate in training. Our framework is flexibly applicable to a wide setting of fully, semi-weakly and weakly supervised training for all Seq2Seq MWP solvers. We conduct extensive experiments on a benchmark dataset Math23k and a new dataset named Weak12k, and show that our framework improves the performance of various MWP solvers under different settings by generating correct and diverse solutions.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
On Grounded Planning for Embodied Tasks with Language Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26549), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26549/26321), [keywords](SNLP: Generation, SNLP: Language Grounding, ML: Applications, SNLP: Applications), [abstract](Abstract
Language models (LMs) have demonstrated their capability in possessing commonsense knowledge of the physical world, a crucial aspect of performing tasks in everyday life. However, it remains unclear whether they have the capacity to generate grounded, executable plans for embodied tasks. This is a challenging task as LMs lack the ability to perceive the environment through vision and feedback from the physical environment. In this paper, we address this important research question and present the first investigation into the topic. Our novel problem formulation, named G-PlanET, inputs a high-level goal and a data table about objects in a specific environment, and then outputs a step-by-step actionable plan for a robotic agent to follow. To facilitate the study, we establish an evaluation protocol and design a dedicated metric, KAS, to assess the quality of the plans. Our experiments demonstrate that the use of tables for encoding the environment and an iterative decoding strategy can significantly enhance the LMs' ability in grounded planning. Our analysis also reveals interesting and non-trivial findings.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
DeAR- A Deep-Learning-Based Audio Re-recording Resilient Watermarking | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26550), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26550/26322), [keywords](SNLP: Applications), [abstract](Abstract
Audio watermarking is widely used for leaking source tracing. The robustness of the watermark determines the traceability of the algorithm. With the development of digital technology, audio re-recording (AR) has become an efficient and covert means to steal secrets. AR process could drastically destroy the watermark signal while preserving the original information. This puts forward a new requirement for audio watermarking at this stage, that is, to be robust to AR distortions. Unfortunately, none of the existing algorithms can effectively resist AR attacks due to the complexity of the AR process. To address this limitation, this paper proposes DeAR, a deep-learning-based audio re-recording resistant watermarking. Inspired by DNN-based image watermarking, we pioneer a deep learning framework for audio carriers, based on which the watermark signal can be effectively embedded and extracted. Meanwhile, in order to resist the AR attack, we delicately analyze the distortions that occurred in the AR process and design the corresponding distortion layer to cooperate with the proposed watermarking framework. Extensive experiments show that the proposed algorithm can resist not only common electronic channel distortions but also AR distortions. Under the premise of high-quality embedding (SNR=25.86dB), in the case of a common re-recording distance (20cm), the algorithm can effectively achieve an average bit recovery accuracy of 98.55%.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Detecting and Grounding Important Characters in Visual Stories | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26551), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26551/26323), [keywords](SNLP: Language Grounding, CV: Language and Vision, HAI: Procedural Content Generation & Storytelling), [abstract](Abstract
Characters are essential to the plot of any story. Establishing the characters before writing a story can improve the clarity of the plot and the overall flow of the narrative. However, previous work on visual storytelling tends to focus on detecting objects in images and discovering relationships between them. In this approach, characters are not distinguished from other objects when they are fed into the generation pipeline. The result is a coherent sequence of events rather than a character-centric story. In order to address this limitation, we introduce the VIST-Character dataset, which provides rich character-centric annotations, including visual and textual co-reference chains and importance ratings for characters. Based on this dataset, we propose two new tasks: important character detection and character grounding in visual stories. For both tasks, we develop simple, unsupervised models based on distributional similarity and pre-trained vision-and-language models. Our new dataset, together with these models, can serve as the foundation for subsequent work on analysing and generating stories from a character-centric perspective.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Boosting Few-Shot Text Classification via Distribution Estimation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26552), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26552/26324), [keywords](SNLP: Text Classification), [abstract](Abstract
Distribution estimation has been demonstrated as one of the most effective approaches in dealing with few-shot image classification, as the low-level patterns and underlying representations can be easily transferred across different tasks in computer vision domain. However, directly applying this approach to few-shot text classification is challenging, since leveraging the statistics of known classes with sufficient samples to calibrate the distributions of novel classes may cause negative effects due to serious category difference in text domain. To alleviate this issue, we propose two simple yet effective strategies to estimate the distributions of the novel classes by utilizing unlabeled query samples, thus avoiding the potential negative transfer issue. Specifically, we first assume a class or sample follows the Gaussian distribution, and use the original support set and the nearest few query samples to estimate the corresponding mean and covariance. Then, we augment the labeled samples by sampling from the estimated distribution, which can provide sufficient supervision for training the classification model. Extensive experiments on eight few-shot text classification datasets show that the proposed method outperforms state-of-the-art baselines significantly.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SSPAttack- A Simple and Sweet Paradigm for Black-Box Hard-Label Textual Adversarial Attack | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26553), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26553/26325), [keywords](SNLP: Adversarial Attacks & Robustness), [abstract](Abstract
Hard-label textual adversarial attack is a challenging task, as only the predicted label information is available, and the text space is discrete and non-differentiable. Relevant research work is still in fancy and just a handful of methods are proposed. However, existing methods suffer from either the high complexity of genetic algorithms or inaccurate gradient estimation, thus are arduous to obtain adversarial examples with high semantic similarity and low perturbation rate under the tight-budget scenario. In this paper, we propose a simple and sweet paradigm for hard-label textual adversarial attack, named SSPAttack. Specifically, SSPAttack first utilizes initialization to generate an adversarial example, and removes unnecessary replacement words to reduce the number of changed words. Then it determines the replacement order and searches for an anchor synonym, thus avoiding going through all the synonyms. Finally, it pushes substitution words towards original words until an appropriate adversarial example is obtained. The core idea of SSPAttack is just swapping words whose mechanism is simple. Experimental results on eight benchmark datasets and two real-world APIs have shown that the performance of SSPAttack is sweet in terms of similarity, perturbation rate and query efficiency.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
LADA-Trans-NER- Adaptive Efficient Transformer for Chinese Named Entity Recognition Using Lexicon-Attention and Data-Augmentation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26554), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26554/26326), [keywords](SNLP: Information Extraction, KRR: Knowledge Acquisition, KRR: Knowledge Engineering, KRR: Knowledge Representation Languages, ML: Multi-Class/Multi-Label Learning & Extreme Classification, SNLP: Applications, SNLP: Interpretability & Analysis of NLP Models, SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Ontology Induction From Text, SNLP: Text Classification, SNLP: Text Mining), [abstract](Abstract
Recently, word enhancement has become very popular for Chinese Named Entity Recognition (NER), reducing segmentation errors and increasing the semantic and boundary information of Chinese words. However, these methods tend to ignore the semantic relationship before and after the sentence after integrating lexical information. Therefore, the regularity of word length information has not been fully explored in various word-character fusion methods. In this work, we propose a Lexicon-Attention and Data-Augmentation (LADA) method for Chinese NER. We discuss the challenges of using existing methods in incorporating word information for NER and show how our proposed methods could be leveraged to overcome those challenges. LADA is based on a Transformer Encoder that utilizes lexicon to construct a directed graph and fuses word information through updating the optimal edge of the graph. Specially, we introduce the advanced data augmentation method to obtain the optimal representation for the NER task. Experimental results show that the augmentation done using LADA can considerably boost the performance of our NER system and achieve significantly better results than previous state-of-the-art methods and variant models in the literature on four publicly available NER datasets, namely Resume, MSRA, Weibo, and OntoNotes v4. We also observe better generalization and application to a real-world setting from LADA on multi-source complex entities.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26555), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26555/26327), [keywords](SNLP: Machine Translation & Multilinguality), [abstract](Abstract
Benefiting from the sequence-level knowledge distillation, the Non-Autoregressive Transformer (NAT) achieves great success in neural machine translation tasks. 
However, existing knowledge distillation has side effects, such as propagating errors from the teacher to NAT students, which may limit further improvements of NAT models and are rarely discussed in existing research.
In this paper, we introduce selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn.
In addition, we introduce a simple yet effective progressive distillation method to boost NAT performance. 
Experiment results on multiple WMT language directions and several representative NAT models show that our approach can realize a flexible trade-off between the quality and complexity of training data for NAT models, achieving strong performances.
Further analysis shows that distilling only 5% of the raw translations can help an NAT outperform its counterpart trained on raw data by about 2.4 BLEU.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26556), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26556/26328), [keywords](SNLP: Generation), [abstract](Abstract
Endowing dialogue agents with personas is the key to delivering more human-like conversations. However, existing persona-grounded dialogue systems still lack informative details of human conversations and tend to reply with inconsistent and generic responses. One of the main underlying causes is that pre-defined persona sentences are generally short and merely superficial descriptions of personal attributes, making appropriate persona selection and understanding non-trivial. Another challenge is that it is crucial to consider the context and the conversation flow to dynamically determine when to invoke different types of persona signals. To address these problems, we propose a disentangled-attention based pre-training architecture, which incorporates persona-aware prompt learning to bridge the connection between the selected persona and response generation. Our model first exploits the conversation flow to select context-relevant personas, and subsequently enriches the superficial persona descriptions with extra personality traits through persona-aware prompting. Finally, the decoder leverages a disentangled-attention mechanism to flexibly control the reliance on personas and dialogue contexts, and incorporates A*-like keyword-based heuristic estimates for controllable generation. Extensive experiments show that our approach can outperform strong baselines and deliver more consistent and engaging responses on the PERSONA-CHAT dataset.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26557), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26557/26329), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Interpretability & Analysis of NLP Models), [abstract](Abstract
Evaluating open-domain conversation models has been an open challenge due to the open-ended nature of conversations. In addition to static evaluations, recent work has started to explore a variety of per-turn and per-dialog interactive evaluation mechanisms and provide advice on the best setup. In this work, we adopt the interactive evaluation framework and further apply to multiple models with a focus on per-turn evaluation techniques. Apart from the widely used setting where participants select the best response among different candidates at each turn, one more novel per-turn evaluation setting is adopted, where participants can select all appropriate responses with different fallback strategies to continue the conversation when no response is selected. We evaluate these settings based on sensitivity and consistency using four GPT2-based models that differ in model sizes or fine-tuning data. To better generalize to any model groups with no prior assumptions on their rankings and control evaluation costs for all setups, we also propose a methodology to estimate the required sample size given a minimum performance gap of interest before running most experiments. Our comprehensive human evaluation results shed light on how to conduct credible human evaluations of open domain dialog systems using the interactive setup, and suggest additional future directions.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Unsupervised Paraphrasing under Syntax Knowledge | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26558), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26558/26330), [keywords](SNLP: Generation, SNLP: Other Foundations of Speech & Natural Language Processing), [abstract](Abstract
The soundness of syntax is an important issue for the paraphrase generation task. 
Most methods control the syntax of paraphrases by embedding the syntax and semantics in the generation process, which cannot guarantee the syntactical correctness of the results. 
Different from them, in this paper we investigate the structural patterns of word usages termed as the word composable knowledge and integrate it into the paraphrase generation to control the syntax in an explicit way.
This syntax knowledge is pretrained on a large corpus with the dependency relationships and formed as the probabilistic functions on the word-level syntactical soundness.
For the sentence-level correctness, we design a hierarchical syntax structure loss to quantitatively verify the syntactical soundness of the paraphrase against the given dependency template. 
Thus, the generation process can select the appropriate words with consideration on both semantics and syntax. 
The proposed method is evaluated on a few paraphrase datasets.
The experimental results show that the quality of paraphrases by our proposed method outperforms the compared methods, especially in terms of syntax correctness.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Adjective Scale Probe- Can Language Models Encode Formal Semantics Information- | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26559), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26559/26331), [keywords](SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Interpretability & Analysis of NLP Models, SNLP: Lexical & Frame Semantics, Semantic Parsing), [abstract](Abstract
It is an open question what semantic representations transformer-based language models can encode and whether they have access to more abstract aspects of semantic meaning. Here, we propose a diagnostic dataset to investigate how well language models understand the degree semantics of adjectives. In the dataset, referred as the Adjective Scale Probe (ASP), we semi-automatically generate 8 tests of Natural Language Inference (NLI) questions to test 8 key capabilities of adjective interpretation. We apply the ASP dataset to evaluate the performance of 3 language models, i.e., BERT, DeBERTa, and T0. It is found that language models perform below the majority baseline for most tests of the ASP, even when the models have been fine-tuned to achieve high performance on the large-scale MNLI dataset. But after we fine-tune the pre-trained models on a subset of the ASP, DeBERTa can achieve high performance on the untrained adjectives and untrained tests, suggesting that DeBERTa may have captured degree semantic information of adjectives through pre-training but it needs specific training data to learn how to apply such information to the current tasks. In sum, the ASP provides an easy-to-use method to test fine-grained formal semantic properties of adjectives, and reveals language models' abilities to access formal semantic information.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26560), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26560/26332), [keywords](SNLP: Text Classification), [abstract](Abstract
Open intent classification, which aims to correctly classify the known intents into their corresponding classes while identifying the new unknown (open) intents, is an essential but challenging task in dialogue systems. In this paper, we introduce novel K-center contrastive learning and adjustable decision boundary learning (CLAB) to improve the effectiveness of open intent classification. First, we pre-train a feature encoder on the labeled training instances, which transfers knowledge from known intents to unknown intents. Specifically, we devise a K-center contrastive learning algorithm to learn discriminative and balanced intent features, improving the generalization of the model for recognizing open intents. Second, we devise an adjustable decision boundary learning method with expanding and shrinking (ADBES) to determine the suitable decision conditions. Concretely, we learn a decision boundary for each known intent class, which consists of a decision center and the radius of the decision boundary. We then expand the radius of the decision boundary to accommodate more in-class instances if the out-of-class instances are far from the decision boundary; otherwise, we shrink the radius of the decision boundary. Extensive experiments on three benchmark datasets clearly demonstrate the effectiveness of our method for open intent classification.For reproducibility, we submit the code at: https://github.com/lxk00/CLAP), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Learning Compositional Tasks from Language Instructions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26561), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26561/26333), [keywords](SNLP: Language Grounding, ML: Representation Learning), [abstract](Abstract
The ability to combine learned knowledge and skills to solve novel tasks is a key aspect of generalization in humans that allows us to understand and perform tasks described by novel language utterances. While progress has been made in supervised learning settings, no work has yet studied compositional generalization of a reinforcement learning agent following natural language instructions in an embodied environment. We develop a set of tasks in a photo-realistic simulated kitchen environment that allow us to study the degree to which a behavioral policy captures the systematicity in language by studying its zero-shot generalization performance on held out natural language instructions. We show that our agent which leverages a novel additive action-value decomposition in tandem with attention based subgoal prediction is able to exploit composition in text instructions to generalize to unseen tasks.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SPRING- Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26562), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26562/26334), [keywords](SNLP: Conversational AI/Dialogue Systems, CV: Multi-modal Vision, SNLP: Generation, SNLP: Language Models, SNLP: Question Answering), [abstract](Abstract
Existing multimodal conversation agents have shown impressive abilities to locate absolute positions or retrieve attributes in simple scenarios, but they fail to perform well when complex relative positions and information alignments are involved, which poses a bottleneck in response quality. In this paper, we propose a Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph (SPRING) with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios. Specifically, we design two types of Multimodal Question Answering (MQA) tasks to pretrain the agent. All QA pairs utilized during pretraining are generated from novel Increment Layout Graphs (ILG). QA pair difficulty labels automatically annotated by ILG are used to promote MQA-based Curriculum Learning. Experimental results verify the SPRING's effectiveness, showing that it significantly outperforms state-of-the-art approaches on both SIMMC 1.0 and SIMMC 2.0 datasets. We release our code and data at https://github.com/LYX0501/SPRING.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Universal Information Extraction as Unified Semantic Matching | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26563), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26563/26335), [keywords](SNLP: Information Extraction), [abstract](Abstract
The challenge of information extraction (IE) lies in the diversity of label schemas and the heterogeneity of structures.
Traditional methods require task-specific model design and rely heavily on expensive supervision, making them difficult to generalize to new schemas.
In this paper, we decouple IE into two basic abilities, structuring and conceptualizing, which are shared by different tasks and schemas.
Based on this paradigm, we propose to universally model various IE tasks with Unified Semantic Matching (USM) framework, which introduces three unified token linking operations to model the abilities of structuring and conceptualizing.
In this way, USM can jointly encode schema and input text, uniformly extract substructures in parallel, and controllably decode target structures on demand.
Empirical evaluation on 4 IE tasks shows that the proposed method achieves state-of-the-art performance under the supervised experiments and shows strong generalization ability in zero/few-shot transfer settings.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
PUnifiedNER- A Prompting-Based Unified NER System for Diverse Datasets | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26564), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26564/26336), [keywords](SNLP: Information Extraction, SNLP: Applications, SNLP: Generation, SNLP: Language Models, SNLP: Text Mining), [abstract](Abstract
Much of named entity recognition (NER) research focuses on developing dataset-specific models based on data from the domain of interest, and a limited set of related entity types. This is frustrating as each new dataset requires a new model to be trained and stored. In this work, we present a ``versatile'' model---the Prompting-based Unified NER system (PUnifiedNER)---that works with data from different domains and can recognise up to 37 entity types simultaneously, and theoretically it could be as many as possible. By using prompt learning, PUnifiedNER is a novel approach that is able to jointly train across multiple corpora, implementing intelligent on-demand entity recognition. Experimental results show that PUnifiedNER leads to significant prediction benefits compared to dataset-specific models with impressively reduced model deployment costs. Furthermore, the performance of PUnifiedNER can achieve competitive or even better performance than state-of-the-art domain-specific methods for some datasets. We also perform comprehensive pilot and ablation studies to support in-depth analysis of each component in PUnifiedNER.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
KICE- A Knowledge Consolidation and Expansion Framework for Relation Extraction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26565), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26565/26337), [keywords](SNLP: Information Extraction, DMKM: Rule Mining & Pattern Mining, HAI: Human-in-the-Loop Machine Learning, ML: Classification and Regression), [abstract](Abstract
Machine Learning is often challenged by insufficient labeled data. Previous methods employing implicit commonsense knowledge of pre-trained language models (PLMs) or pattern-based symbolic knowledge have achieved great success in mitigating manual annotation efforts. In this paper, we focus on the collaboration among different knowledge sources and present KICE, a Knowledge-evolving framework by Iterative Consolidation and Expansion with the guidance of PLMs and rule-based patterns. Specifically, starting with limited labeled data as seeds, KICE first builds a Rule Generator by prompt-tuning to stimulate the rich knowledge distributed in PLMs, generate seed rules, and initialize the rules set. Afterwards, based on the rule-labeled data, the task model is trained in a self-training pipeline where the knowledge in rules set is consolidated with self-learned high-confidence rules. Finally, for the low-confidence rules, KICE solicits human-enlightened understanding and expands the knowledge coverage for better task model training. Our framework is verified on relation extraction (RE) task, and the experiments on TACRED show that the model performance (F1) grows from 33.24% to 79.84% with the enrichment of knowledge, outperforming all the baselines including other knowledgeable methods.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Zero-Shot Slot Filling with Slot-Prefix Prompting and Attention Relationship Descriptor | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26566), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26566/26338), [keywords](SNLP: Information Extraction, SNLP: Language Models), [abstract](Abstract
This paper addresses zero-shot slot filling, which tries to build a system that can generalize to unseen slot types without any training data. The key to zero-shot slot-filling is to match the tokens from the utterance with the semantic definition of the slot without training data in the target domain. This paper tackles this problem by devising a scheme to fully leverage pre-trained language models (PLMs). To this end, we propose a new prompting scheme that utilizes both learnable tokens and slot names to guide the model to focus on the relevant text spans for a given slot. Furthermore, we use attention values between tokens to form a feature descriptor for each token, which is motivated by the fact that the attention value in a PLM naturally characterizes various relationships, e.g., syntactic or semantic, between tokens. By further consolidating those features with an additional transformer-based aggregation module, we create a simple-but-effective zero-shot slot filling system that can achieve significantly better performance than the previous methods, as demonstrated by our experimental studies.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Feature-Level Debiased Natural Language Understanding | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26567), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26567/26339), [keywords](SNLP: Adversarial Attacks & Robustness, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Text Classification), [abstract](Abstract
Natural language understanding (NLU) models often rely on dataset biases rather than intended task-relevant features to achieve high performance on specific datasets. As a result, these models perform poorly on datasets outside the training distribution. Some recent studies address this issue by reducing the weights of biased samples during the training process. However, these methods still encode biased latent features in representations and neglect the dynamic nature of bias, which hinders model prediction. We propose an NLU debiasing method, named debiasing contrastive learning (DCT), to simultaneously alleviate the above problems based on contrastive learning. We devise a debiasing, positive sampling strategy to mitigate biased latent features by selecting the least similar biased positive samples. We also propose a dynamic negative sampling strategy to capture the dynamic influence of biases by employing a bias-only model to dynamically select the most similar biased negative samples. We conduct experiments on three NLU benchmark datasets. Experimental results show that DCT outperforms state-of-the-art baselines on out-of-distribution datasets while maintaining in-distribution performance. We also verify that DCT can reduce biased latent features from the model's representation.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Graph Component Contrastive Learning for Concept Relatedness Estimation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26568), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26568/26340), [keywords](SNLP: Text Classification, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Concept relatedness estimation (CRE) aims to determine whether two given concepts are related. Existing methods only consider the pairwise relationship between concepts, while overlooking the higher-order relationship that could be encoded in a concept-level graph structure. We discover that this underlying graph satisfies a set of intrinsic properties of CRE, including reflexivity, commutativity, and transitivity. In this paper, we formalize the CRE properties and introduce a graph structure named ConcreteGraph. To address the data scarcity issue in CRE, we introduce a novel data augmentation approach to sample new concept pairs from the graph. As it is intractable for data augmentation to fully capture the structural information of the ConcreteGraph due to a large amount of potential concept pairs, we further introduce a novel Graph Component Contrastive Learning framework to implicitly learn the complete structure of the ConcreteGraph. Empirical results on three datasets show significant improvement over the state-of-the-art model. Detailed ablation studies demonstrate that our proposed approach can effectively capture the high-order relationship among concepts.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
HybridPrompt- Bridging Language Models and Human Priors in Prompt Tuning for Visual Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26569), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26569/26341), [keywords](SNLP: Question Answering), [abstract](Abstract
Visual Question Answering (VQA) aims to answer the natural language question about a given image by understanding multimodal content. However, the answer quality of most existing visual-language pre-training (VLP) methods is still limited, mainly due to: (1) Incompatibility. Upstream pre-training tasks are generally incompatible with downstream question answering tasks, which makes the knowledge from the language model not well transferable to downstream tasks, and greatly limits their performance in few-shot scenarios; (2) Under-fitting. They generally do not integrate human priors to compensate for universal knowledge from language models, so as to fit the challenging VQA problem and generate reliable answers. To address these issues, we propose HybridPrompt, a cloze- and verify-style hybrid prompt framework with bridging language models and human priors in prompt tuning for VQA. Specifically, we first modify the input questions into the cloze-style prompts to narrow the gap between upstream pre-training tasks and downstream VQA task, which ensures that the universal knowledge in the language model can be better transferred to subsequent human prior-guided prompt tuning. Then, we imitate the cognitive process of human brain to introduce topic and sample related priors to construct a dynamic learnable prompt template for human prior-guided prompt learning. Finally, we add fixed-length learnable free-parameters to further enhance the generalizability and scalability of prompt learning in the VQA model. Experimental results verify the effectiveness of HybridPrompt, showing that it achieves competitive performance against previous methods on widely-used VQAv2 dataset and obtains new state-of-the-art results. Our code is released at: https://github.com/zhizhi111/hybrid.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Inferential Knowledge-Enhanced Integrated Reasoning for Video Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26570), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26570/26342), [keywords](SNLP: Question Answering), [abstract](Abstract
Recently, video question answering has attracted growing attention. It involves answering a question based on a fine-grained understanding of video multi-modal information. Most existing methods have successfully explored the deep understanding of visual modality. We argue that a deep understanding of linguistic modality is also essential for answer reasoning, especially for videos that contain character dialogues. To this end, we propose an Inferential Knowledge-Enhanced Integrated Reasoning method. Our method consists of two main components: 1) an Inferential Knowledge Reasoner to generate inferential knowledge for linguistic modality inputs that reveals deeper semantics, including the implicit causes, effects, mental states, etc. 2) an Integrated Reasoning Mechanism to enhance video content understanding and answer reasoning by leveraging the generated inferential knowledge. Experimental results show that our method achieves significant improvement on two mainstream datasets. The ablation study further demonstrates the effectiveness of each component of our approach.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
AUC Maximization for Low-Resource Named Entity Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26571), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26571/26343), [keywords](SNLP: Syntax -- Tagging, Chunking & Parsing, SNLP: Learning & Optimization for SNLP), [abstract](Abstract
Current work in named entity recognition (NER) uses either cross entropy (CE) or conditional random fields (CRF) as the objective/loss functions to optimize the underlying NER model. Both of these traditional objective functions for the NER problem generally produce adequate performance when the data distribution is balanced and there are sufficient annotated training examples. But since NER is inherently an imbalanced tagging problem, the model performance under the low-resource settings could suffer using these standard objective functions. Based on  recent advances in area under the ROC curve (AUC) maximization, we propose to optimize the NER model by maximizing the AUC score. We give evidence that by simply combining two binary-classifiers that maximize the AUC score, significant performance improvement over traditional loss functions is achieved under low-resource NER settings. We also conduct extensive experiments to demonstrate the advantages of our method under the low-resource and highly-imbalanced data distribution settings. To the best of our knowledge, this is the first work that brings AUC maximization to the NER setting. Furthermore, we show that our method is agnostic to different types of NER embeddings, models and domains. The code of this work is available at https://github.com/dngu0061/NER-AUC-2T.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Unveiling the Black Box of PLMs with Semantic Anchors- Towards Interpretable Neural Semantic Parsing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26572), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26572/26344), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Interpretability & Analysis of NLP Models, SNLP: Language Models, SNLP: Question Answering), [abstract](Abstract
The recent prevalence of pretrained language models (PLMs) has dramatically shifted the paradigm of semantic parsing, where the mapping from natural language utterances to structured logical forms is now formulated as a Seq2Seq task. Despite the promising performance, previous PLM-based approaches often suffer from hallucination problems due to their negligence of the structural information contained in the sentence, which essentially constitutes the key semantics of the logical forms. Furthermore, most works treat PLM as a black box in which the generation process of the target logical form is hidden beneath the decoder modules, which greatly hinders the model's intrinsic interpretability. To address these two issues, we propose to incorporate the current PLMs with a hierarchical decoder network. By taking the first-principle structures as the semantic anchors, we propose two novel intermediate supervision tasks, namely Semantic Anchor Extraction and Semantic Anchor Alignment, for training the hierarchical decoders and probing the model intermediate representations in a self-adaptive manner alongside the fine-tuning process. We conduct intensive experiments on several semantic parsing benchmarks and demonstrate that our approach can consistently outperform the baselines. More importantly, by analyzing the intermediate representations of the hierarchical decoders, our approach also makes a huge step toward the interpretability of PLMs in the domain of semantic parsing.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26573), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26573/26345), [keywords](SNLP: Applications, APP: Education), [abstract](Abstract
Understanding mathematical questions effectively is a crucial task, which can benefit many applications, such as difficulty estimation. Researchers have drawn much attention to designing pre-training models for question representations due to the scarcity of human annotations (e.g., labeling difficulty). However, unlike general free-format texts (e.g., user comments), mathematical questions are generally designed with explicit purposes and mathematical logic, and usually consist of more complex content, such as formulas, and related mathematical knowledge (e.g., Function). Therefore, the problem of holistically representing mathematical questions remains underexplored. To this end, in this paper, we propose a novel contrastive pre-training approach for mathematical question representations, namely QuesCo, which attempts to bring questions with more similar purposes closer. Specifically, we first design two-level question augmentations, including content-level and structure-level, which generate literally diverse question pairs with similar purposes. Then, to fully exploit hierarchical information of knowledge concepts, we propose a knowledge hierarchy-aware rank strategy (KHAR), which ranks the similarities between questions in a fine-grained manner. Next, we adopt a ranking contrastive learning task to optimize our model based on the augmented and ranked questions. We conduct extensive experiments on two real-world mathematical datasets. The experimental results demonstrate the effectiveness of our model.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Improving the Cross-Lingual Generalisation in Visual Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26574), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26574/26346), [keywords](SNLP: Question Answering, CV: Language and Vision, SNLP: Language Grounding, SNLP: Machine Translation & Multilinguality), [abstract](Abstract
While several benefits were realized for multilingual vision-language pretrained models, recent benchmarks across various tasks and languages showed poor cross-lingual generalisation when multilingually pre-trained vision-language models are applied to non-English data, with a large gap between (supervised) English performance and (zero-shot) cross-lingual transfer. In this work, we explore the poor performance of these models on a zero-shot cross-lingual visual question answering (VQA) task, where models are fine-tuned on English visual-question data and evaluated on 7 typologically diverse languages. We improve cross-lingual transfer with three strategies: (1) we introduce a linguistic prior objective to augment the cross-entropy loss with a similarity-based loss to guide the model during training, (2) we learn a task-specific subnetwork that improves cross-lingual generalisation and reduces variance without model modification, (3) we augment training examples using synthetic code-mixing to promote alignment of embeddings between source and target languages. Our experiments on xGQA using the pretrained multilingual multimodal transformers UC2 and M3P demonstrates the consistent effectiveness of the proposed fine-tuning strategy for 7 languages, outperforming existing transfer methods with sparse models.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
RWEN-TTS- Relation-Aware Word Encoding Network for Natural Text-to-Speech Synthesis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26575), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26575/26347), [keywords](SNLP: Speech and Multimodality, SNLP: Generation, SNLP: Language Models, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Syntax -- Tagging, Chunking & Parsing), [abstract](Abstract
With the advent of deep learning, a huge number of text-to-speech (TTS) models which produce human-like speech have emerged. Recently, by introducing syntactic and semantic information w.r.t the input text, various approaches have been proposed to enrich the naturalness and expressiveness of TTS models. Although these strategies showed impressive results, they still have some limitations in utilizing language information. First, most approaches only use graph networks to utilize syntactic and semantic information without considering linguistic features. Second, most previous works do not explicitly consider adjacent words when encoding syntactic and semantic information, even though it is obvious that adjacent words are usually meaningful when encoding the current word. To address these issues, we propose Relation-aware Word Encoding Network (RWEN), which effectively allows syntactic and semantic information based on two modules (i.e., Semantic-level Relation Encoding and Adjacent Word Relation Encoding). Experimental results show substantial improvements compared to previous works.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Hierarchical Event Grounding | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26576), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26576/26348), [keywords](SNLP: Information Extraction), [abstract](Abstract
Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
RINK- Reader-Inherited Evidence Reranker for Table-and-Text Open Domain Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26577), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26577/26349), [keywords](SNLP: Question Answering, SNLP: Applications), [abstract](Abstract
Most approaches used in open-domain question answering on hybrid data that comprises both tabular-and-textual contents are based on a Retrieval-Reader pipeline in which the retrieval module finds relevant  “heterogenous” evidence for a given question and the reader module generates an answer from the retrieved evidence. In this paper, we present a Retriever-Reranker-Reader framework by newly proposing a Reader-INherited evidence reranKer (RINK) where a reranker module is designed by finetuning the reader’s neural architecture based on a simple prompting method. Our underlying assumption of reusing the reader’s module for the reranker is that the reader’s ability to generating an answer from evidence contains the knowledge required for the reranking, because the reranker needs to “read” in-depth a question and evidences more carefully and elaborately than a baseline retriever. Furthermore, we present a simple and effective pretraining method by extensively deploying the commonly used data augmentation methods of cell corruption and cell reordering based on the pretraining tasks - tabular-and-textual entailment and cross-modal masked language modeling. Experimental results on OTT-QA, a large-scale table-and-text open-domain question answering dataset, show that the proposed RINK armed with our pretraining procedure makes improvements over the baseline reranking method and leads to state-of-the-art performance.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Relation-Aware Language-Graph Transformer for Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26578), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26578/26350), [keywords](SNLP: Question Answering, KRR: Common-Sense Reasoning, ML: Graph-based Machine Learning), [abstract](Abstract
Question Answering (QA) is a task that entails reasoning over natural language contexts, and many relevant works augment language models (LMs) with graph neural networks (GNNs) to encode the Knowledge Graph (KG) information. However, most existing GNN-based modules for QA do not take advantage of rich relational information of KGs and depend on limited information interaction between the LM and the KG. To address these issues, we propose Question Answering Transformer (QAT), which is designed to jointly reason over language and graphs with respect to entity relations in a unified manner. Specifically, QAT constructs Meta-Path tokens, which learn relation-centric embeddings based on diverse structural and semantic relations. Then, our Relation-Aware Self-Attention module comprehensively integrates different modalities via the Cross-Modal Relative Position Bias, which guides information exchange between relevant entities of different modalities. We validate the effectiveness of QAT on commonsense question answering datasets like CommonsenseQA and OpenBookQA, and on a medical question answering dataset, MedQA-USMLE. On all the datasets, our method achieves state-of-the-art performance. Our code is available at http://github.com/mlvlab/QAT.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Multi-Mask Label Mapping for Prompt-Based Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26579), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26579/26351), [keywords](SNLP: Text Classification, SNLP: Applications, SNLP: Language Models), [abstract](Abstract
Prompt-based Learning has shown significant success in few-shot classification. The mainstream approach is to concatenate a template for the input text to transform the classification task into a cloze-type task where label mapping plays an important role in finding the ground-truth labels.  While current label mapping methods only use the contexts in one single input, it could be crucial if wrong information is contained in the text. Specifically, it is proved in recent work that even the large language models like BERT/RoBERTa make classification decisions heavily dependent on a specific keyword regardless of the task or the context. Such a word is referred to as a lexical cue and if a misleading lexical cue is included in the instance it will lead the model to make a wrong prediction. We propose a multi-mask prompt-based approach with Multi-Mask Label Mapping (MMLM) to reduce the impact of misleading lexical cues by allowing the model to exploit multiple lexical cues. To satisfy the conditions of few-shot learning, an instance augmentation approach for the cloze-type model is proposed and the misleading cues are gradually excluded through training. We demonstrate the effectiveness of MMLM by both theoretical analysis and empirical studies, and show that MMLM outperforms other existing label mapping approaches.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SSMI- Semantic Similarity and Mutual Information Maximization Based Enhancement for Chinese NER | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26580), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26580/26352), [keywords](SNLP: Syntax -- Tagging, Chunking & Parsing, SNLP: Text Classification), [abstract](Abstract
The Chinese NER task consists of two steps, first determining entity boundaries and then labeling them. Some previous work incorporating related words from pre-trained vocabulary into character-based models has been demonstrated to be effective. However, the number of words that characters can match in the vocabulary is large, and their meanings vary widely. It is unreasonable to concatenate all the matched words into the character's representation without making semantic distinctions. This is because words with different semantics also have distinct vectors by the distributed representation. Moreover, mutual information maximization (MIM) provides a unified way to characterize the correction between different granularity of embeddings, we find it can be used to enhance the features in our task. Consequently, this paper introduces a novel Chinese NER model named SSMI based on semantic similarity and MIM. We first match all the potential word boundaries of the input characters from the pre-trained vocabulary and employ BERT to segment the input sentence to get the segmentation containing these characters. After computing their cosine similarity, we obtain the word boundary with the highest similarity and the word group with similarity score larger than a specific threshold. Then, we concatenate the most relevant word boundaries with character vectors. We further calculate the mutual information maximization of group, character and sentence, respectively. Finally, we feed the result from the above steps to our novel network. The results on four Chinese public NER datasets show that our SSMI achieves state-of-the-art performance.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Towards Complex Scenarios- Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26581), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26581/26353), [keywords](SNLP: Conversational AI/Dialogue Systems), [abstract](Abstract
With the success of the sequence-to-sequence model, end-to-end task-oriented dialogue systems (EToDs) have obtained remarkable progress. However, most existing EToDs are limited to single KB settings where dialogues can be supported by a single KB, which is still far from satisfying the requirements of some complex applications (multi-KBs setting). In this work, we first empirically show that the existing single-KB EToDs fail to work on multi-KB settings that require models to reason across various KBs. To solve this issue, we take the first step to consider the multi-KBs scenario in EToDs and introduce a KB-over-KB Heterogeneous Graph Attention Network (KoK-HAN) to facilitate model to reason over multiple KBs. The core module is a triple-connection graph interaction layer that can model different granularity levels of interaction information across different KBs (i.e., intra-KB connection, inter-KB connection and dialogue-KB connection). Experimental results confirm the superiority of our model for multiple KBs reasoning.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
BERT-ERC- Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26582), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26582/26354), [keywords](SNLP: Sentiment Analysis and Stylistic Analysis, SNLP: Conversational AI/Dialogue Systems, SNLP: Language Models, SNLP: Text Classification), [abstract](Abstract
Previous works on emotion recognition in conversation (ERC) follow a two-step paradigm, which can be summarized as first producing context-independent features via fine-tuning pretrained language models (PLMs) and then analyzing contextual information and dialogue structure information among the extracted features. However, we discover that this paradigm has several limitations. Accordingly, we propose a novel paradigm, i.e., exploring contextual information and dialogue structure information in the fine-tuning step, and adapting the PLM to the ERC task in terms of input text, classification structure, and training strategy. Furthermore, we develop our model BERT-ERC according to the proposed paradigm, which improves ERC performance in three aspects, namely suggestive text, fine-grained classification module, and two-stage training. Compared to existing methods, BERT-ERC achieves substantial improvement on four datasets, indicating its effectiveness and generalization capability. Besides, we also set up the limited resources scenario and the online prediction scenario to approximate real-world scenarios. Extensive experiments demonstrate that the proposed paradigm significantly outperforms the previous one and can be adapted to various scenes.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-Grained Student Ensemble | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26583), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26583/26355), [keywords](SNLP: Information Extraction), [abstract](Abstract
Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the data scarcity problem in NER by automatically generating training samples. Unfortunately, the distant supervision may induce noisy labels, thus undermining the robustness of the learned models and restricting the practical application. 
To relieve this problem, recent works adopt self-training teacher-student frameworks to gradually refine the training labels and improve the generalization ability of NER models. However, we argue that the performance of the current self-training frameworks for DS-NER is severely underestimated by their plain designs, including both inadequate student learning and coarse-grained teacher updating. Therefore, in this paper, we make the first attempt to alleviate these issues by proposing:  
(1) adaptive teacher learning comprised of joint training of two teacher-student networks and considering both consistent and inconsistent predictions between two teachers, thus promoting comprehensive student learning. 
(2) fine-grained student ensemble that updates each fragment of the teacher model with a temporal moving average of the corresponding fragment of the student, which enhances consistent predictions on each model fragment against noise. 
To verify the effectiveness of our proposed method, we conduct experiments on four DS-NER datasets. The experimental results demonstrate that our method significantly surpasses previous SOTA methods. The code is available at https://github.com/zenhjunpro/ATSEN.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26584), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26584/26356), [keywords](SNLP: Text Mining, SNLP: Information Extraction, SNLP: Language Models, SNLP: Text Classification), [abstract](Abstract
Massive rumors usually appear along with breaking news or trending topics, seriously hindering the truth. Existing rumor detection methods are mostly focused on the same domain, thus have poor performance in cross-domain scenarios due to domain shift. In this work, we propose an end-to-end instance-wise and prototype-wise contrastive learning model with cross-attention mechanism for cross-domain rumor detection. The model not only performs cross-domain
feature alignment, but also enforces target samples to align with the corresponding prototypes of a given source domain. Since target labels in a target domain are unavailable, we use a clustering-based approach with carefully initialized centers
by a batch of source domain samples to produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair of source data and target data with the same labels to learn domain-invariant representations. Because the samples in a
domain pair tend to express similar semantic patterns especially on the people’s attitudes (e.g., supporting or denying) towards the same category of rumors, the discrepancy between a pair of source domain and target domain will be decreased. We conduct experiments on four groups of cross-domain datasets and show that our proposed model achieves state-of-the-art performance.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Prompting Neural Machine Translation with Translation Memories | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26585), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26585/26357), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Generation, SNLP: Other Foundations of Speech & Natural Language Processing), [abstract](Abstract
Improving machine translation (MT) systems with translation memories (TMs) is of great interest to practitioners in the MT community. However, previous approaches require either a significant update of the model architecture and/or additional training efforts to make the models well-behaved when TMs are taken as additional input. In this paper, we present a simple but effective method to introduce TMs into neural machine translation (NMT) systems. Specifically, we treat TMs as prompts to the NMT model at test time, but leave the training process unchanged. The result is a slight update of an existing NMT system, which can be implemented in a few hours by anyone who is familiar with NMT. Experimental results on several datasets demonstrate that our system significantly outperforms strong baselines.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Improving Interpretability via Explicit Word Interaction Graph Layer | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26586), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26586/26358), [keywords](SNLP: Interpretability & Analysis of NLP Models, ML: Graph-based Machine Learning), [abstract](Abstract
Recent NLP literature has seen growing interest in improving model interpretability. Along this direction, we propose a trainable neural network layer that learns a global interaction graph between words and then selects more informative words using the learned word interactions. Our layer, we call WIGRAPH, can plug into any neural network-based NLP text classifiers right after its word embedding layer. Across multiple SOTA NLP models and various NLP datasets, we demonstrate that adding the WIGRAPH layer substantially improves NLP models' interpretability and enhances models' prediction performance at the same time.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Rephrasing the Reference for Non-autoregressive Machine Translation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26587), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26587/26359), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Generation), [abstract](Abstract
Non-autoregressive neural machine translation (NAT) models suffer from the multi-modality problem that there may exist multiple possible translations of a source sentence, so the reference sentence may be inappropriate for the training when the NAT output is closer to other translations. In response to this problem, we introduce a rephraser to provide a better training target for NAT by rephrasing the reference sentence according to the NAT output. As we train NAT based on the rephraser output rather than the reference sentence, the rephraser output should fit well with the NAT output and not deviate too far from the reference, which can be quantified as reward functions and optimized by reinforcement learning. Experiments on major WMT benchmarks and NAT baselines show that our approach consistently improves the translation quality of NAT. Specifically, our best variant achieves comparable performance to the autoregressive Transformer, while being 14.7 times more efficient in inference.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Drop Clause- Enhancing Performance, Robustness and Pattern Recognition Capabilities of the Tsetlin Machine | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26588), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26588/26360), [keywords](SNLP: Interpretability & Analysis of NLP Models, KRR: Logic Programming, ML: Adversarial Learning & Robustness, ML: Distributed Machine Learning & Federated Learning, ML: Ensemble Methods, ML: Optimization, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Logic-based machine learning has the crucial advantage of transparency. However, despite significant recent progress, further research is needed to close the accuracy gap between logic-based architectures and deep neural network ones. This paper introduces a novel variant of the Tsetlin machine (TM) that randomly drops clauses, the logical learning element of TMs. In effect, TM with Drop Clause ignores a random selection of the clauses in each epoch, selected according to a predefined probability. In this way, the TM learning phase becomes more diverse. To explore the effects that Drop Clause has on accuracy, training time and robustness, we conduct extensive experiments on nine benchmark datasets in natural language processing (IMDb, R8, R52, MR, and TREC) and image classification (MNIST, Fashion MNIST, CIFAR-10, and CIFAR-100). Our proposed model outperforms baseline machine learning algorithms by a wide margin and achieves competitive performance compared with recent deep learning models, such as BERT-Large and AlexNet-DFA. In brief, we observe up to +10% increase in accuracy and 2x to 4x faster learning than for the standard TM. We visualize the patterns learnt by Drop Clause TM in the form of heatmaps and show evidence of the ability of drop clause to learn more unique and discriminative patterns. We finally evaluate how Drop Clause affects learning robustness by introducing corruptions and alterations in the image/language test data, which exposes increased learning robustness.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
CoP- Factual Inconsistency Detection by Controlling the Preference | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26589), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26589/26361), [keywords](SNLP: Summarization), [abstract](Abstract
Abstractive summarization is the process of generating a summary given a document as input. Although significant progress has been made, the factual inconsistency between the document and the generated summary still limits its practical applications. Previous work found that the probabilities assigned by the generation model reflect its preferences for the generated summary, including the preference for factual consistency, and the preference for the language or knowledge prior as well. To separate the preference for factual consistency, we propose an unsupervised framework named CoP by controlling the preference of the generation model with the help of prompt. More specifically, the framework performs an extra inference step in which a text prompt is introduced as an additional input. In this way, another preference is described by the generation probability of this extra inference process. The difference between the above two preferences, i.e. the difference between the probabilities, could be used as measurements for detecting factual inconsistencies. Interestingly, we found that with the properly designed prompt, our framework could evaluate specific preferences and serve as measurements for fine-grained categories of inconsistency, such as entity-related inconsistency, coreference-related inconsistency, etc. Moreover, our framework could also be extended to the supervised setting to learn better prompt from the labeled data as well. Experiments show that our framework achieves new SOTA results on three factual inconsisency detection tasks.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Which Shortcut Solution Do Question Answering Models Prefer to Learn- | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26590), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26590/26362), [keywords](SNLP: Question Answering, SNLP: Adversarial Attacks & Robustness, SNLP: Bias, Fairness, Transparency & Privacy, SNLP: Interpretability & Analysis of NLP Models), [abstract](Abstract
Question answering (QA) models for reading comprehension tend to exploit spurious correlations in training sets and thus learn shortcut solutions rather than the solutions intended by QA datasets.
QA models that have learned shortcut solutions can achieve human-level performance in shortcut examples where shortcuts are valid, but these same behaviors degrade generalization potential on anti-shortcut examples where shortcuts are invalid.
Various methods have been proposed to mitigate this problem, but they do not fully take the characteristics of shortcuts themselves into account.
We assume that the learnability of shortcuts, i.e., how easy it is to learn a shortcut, is useful to mitigate the problem.
Thus, we first examine the learnability of the representative shortcuts on extractive and multiple-choice QA datasets.
Behavioral tests using biased training sets reveal that shortcuts that exploit answer positions and word-label correlations are preferentially learned for extractive and multiple-choice QA, respectively.
We find that the more learnable a shortcut is, the flatter and deeper the loss landscape is around the shortcut solution in the parameter space.
We also find that the availability of the preferred shortcuts tends to make the task easier to perform from an information-theoretic viewpoint.
Lastly, we experimentally show that the learnability of shortcuts can be utilized to construct an effective QA training set; the more learnable a shortcut is, the smaller the proportion of anti-shortcut examples required to achieve comparable performance on shortcut and anti-shortcut examples.
We claim that the learnability of shortcuts should be considered when designing mitigation methods.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Exploring Faithful Rationale for Multi-Hop Fact Verification via Salience-Aware Graph Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26591), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26591/26363), [keywords](SNLP: Discourse, Pragmatics & Argument Mining, SNLP: Interpretability & Analysis of NLP Models, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Sentiment Analysis and Stylistic Analysis, SNLP: Text Classification), [abstract](Abstract
The opaqueness of the multi-hop fact verification model imposes imperative requirements for explainability. One feasible way is to extract rationales, a subset of inputs, where the performance of prediction drops dramatically when being removed. Though being explainable, most rationale extraction methods for multi-hop fact verification explore the semantic information within each piece of evidence individually, while ignoring the topological information interaction among different pieces of evidence. Intuitively, a faithful rationale bears complementary information being able to extract other rationales through the multi-hop reasoning process. To tackle such disadvantages, we cast explainable multi-hop fact verification as subgraph extraction, which can be solved based on graph convolutional network (GCN) with salience-aware graph learning. In specific, GCN is utilized to incorporate the topological interaction information among multiple pieces of evidence for learning evidence representation. Meanwhile, to alleviate the influence of noisy evidence, the salience-aware graph perturbation is induced into the message passing of GCN. Moreover, the multi-task model with three diagnostic properties of rationale is elaborately designed to improve the quality of an explanation without any explicit annotations. Experimental results on the FEVEROUS benchmark show significant gains over previous state-of-the-art methods for both rationale extraction and fact verification.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User Satisfaction Estimation and Sentiment Analysis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26592), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26592/26364), [keywords](SNLP: Sentiment Analysis and Stylistic Analysis, SNLP: Text Classification), [abstract](Abstract
User Satisfaction Estimation is an important task and increasingly being applied in goal-oriented dialogue systems to estimate whether the user is satisfied with the service. It is observed that whether the user’s needs are met often triggers various sentiments, which can be pertinent to the successful estimation of user satisfaction, and vice versa. Thus, User Satisfaction Estimation (USE) and Sentiment Analysis (SA) should be treated as a joint, collaborative effort, considering the strong connections between the sentiment states of speakers and the user satisfaction. Existing joint learning frameworks mainly unify the two highly pertinent tasks over cascade or shared-bottom implementations, however they fail to distinguish task-specific and common features, which will produce sub-optimal utterance representations for downstream tasks. In this paper, we propose a novel Speaker Turn-Aware Multi-Task Adversarial Network (STMAN) for dialogue-level USE and utterance-level SA. Specifically, we first introduce a multi-task adversarial strategy which trains a task discriminator to make utterance representation more task-specific, and then utilize a speaker-turn aware multi-task interaction strategy to extract the common features which are complementary to each task. Extensive experiments conducted on two real-world service dialogue datasets show that our model outperforms several state-of-the-art methods.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Latent-Variable Model for Intrinsic Probing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26593), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26593/26365), [keywords](SNLP: Interpretability & Analysis of NLP Models, SNLP: Machine Translation & Multilinguality), [abstract](Abstract
The success of pre-trained contextualized representations has prompted researchers to analyze them for the presence of linguistic information. 
Indeed, it is natural to assume that these pre-trained representations do encode some level of linguistic knowledge as they have brought about large empirical improvements on a wide variety of NLP tasks, which suggests they are learning true linguistic generalization.
In this work, we focus on intrinsic probing, an analysis technique where the goal is not only to identify whether a representation encodes a linguistic attribute but also to pinpoint where this attribute is encoded.
We propose a novel latent-variable formulation for constructing intrinsic probes and derive a tractable variational approximation to the log-likelihood.
Our results show that our model is versatile and yields tighter mutual information estimates than two intrinsic probes previously proposed in the literature.
Finally, we find empirical evidence that pre-trained representations 
develop a cross-lingually entangled notion of morphosyntax.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26594), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26594/26366), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Generation), [abstract](Abstract
Conditional variational models, using either continuous or discrete latent variables, are powerful for open-domain dialogue response generation. However, previous works show that continuous latent variables tend to reduce the coherence of generated responses. In this paper, we also found that discrete latent variables have difficulty capturing more diverse expressions. To tackle these problems, we combine the merits of both continuous and discrete latent variables and propose a Hybrid Latent Variable (HLV) method. Specifically, HLV constrains the global semantics of responses through discrete latent variables and enriches responses with continuous latent variables. Thus, we diversify the generated responses while maintaining relevance and coherence. In addition, we propose Conditional Hybrid Variational Transformer (CHVT) to construct and to utilize HLV with transformers for dialogue generation. Through fine-grained symbolic-level semantic information and additive Gaussian mixing, we construct the distribution of continuous variables, prompting the generation of diverse expressions. Meanwhile, to maintain the relevance and coherence, the discrete latent variable is optimized by self-separation training. Experimental results on two dialogue generation datasets (DailyDialog and Opensubtitles) show that CHVT is superior to traditional transformer-based variational mechanism w.r.t. diversity, relevance and coherence metrics. Moreover, we also demonstrate the benefit of applying HLV to fine-tuning two pre-trained dialogue models (PLATO and BART-base).), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
ConvNTM- Conversational Neural Topic Model | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26595), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26595/26367), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Text Mining), [abstract](Abstract
Topic models have been thoroughly investigated for multiple years due to their great potential in analyzing and understanding texts. Recently, researchers combine the study of topic models with deep learning techniques, known as Neural Topic Models (NTMs). However, existing NTMs are mainly tested based on general document modeling without considering different textual analysis scenarios. We assume that there are different characteristics to model topics in different textual analysis tasks. In this paper, we propose a Conversational Neural Topic Model (ConvNTM) designed in particular for the conversational scenario. Unlike the general document topic modeling, a conversation session lasts for multiple turns: each short-text utterance complies with a single topic distribution and these topic distributions are dependent across turns. Moreover, there are roles in conversations, a.k.a., speakers and addressees. Topic distributions are partially determined by such roles in conversations. We take these factors into account to model topics in conversations via the multi-turn and multi-role formulation. We also leverage the word co-occurrence relationship as a new training objective to further improve topic quality. Comprehensive experimental results based on the benchmark datasets demonstrate that our proposed ConvNTM achieves the best performance both in topic modeling and in typical downstream tasks within conversational research (i.e., dialogue act classification and dialogue response generation).), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Contrastive Learning Reduces Hallucination in Conversations | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26596), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26596/26368), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Applications, SNLP: Generation, SNLP: Language Models), [abstract](Abstract
Pre-trained language models (LMs) store knowledge in their parameters and can generate informative responses when used in conversational systems. However, LMs suffer from the problem of “hallucination:” they may generate plausible-looking statements that are irrelevant or factually incorrect. To address this problem, we propose a contrastive learning scheme, named MixCL. A novel mixed contrastive objective is proposed to explicitly optimize the implicit knowledge elicitation process of LMs, and thus reduce their hallucination in conversations. We also examine negative sampling strategies of retrieved hard negatives and model-generated negatives. We conduct experiments on Wizard-of-Wikipedia, a public, open-domain knowledge-grounded dialogue benchmark, and assess the effectiveness of MixCL. MixCL effectively reduces the hallucination of LMs in conversations and achieves the highest performance among LM-based dialogue agents in terms of relevancy and factuality. We show that MixCL achieves comparable performance to state-of-the-art KB-based approaches while enjoying notable advantages in terms of efficiency and scalability.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Revisiting Denoising Diffusion Probabilistic Models for Speech Enhancement- Condition Collapse, Efficiency and Refinement | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26597), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26597/26369), [keywords](SNLP: Speech and Multimodality, SNLP: Other Foundations of Speech & Natural Language Processing), [abstract](Abstract
Recent literature has shown that denoising diffusion probabilistic models (DDPMs) can be used to synthesize high-fidelity samples with a competitive (or sometimes better) quality than previous state-of-the-art approaches. However, few attempts have been made to apply DDPM for the speech enhancement task. The reported performance of the existing works is relatively poor and significantly inferior to other generative methods. In this work, we first reveal the difficulties in applying existing diffusion models to the field of speech enhancement. Then we introduce DR-DiffuSE, a simple and effective framework for speech enhancement using conditional diffusion models. We present three strategies (two in diffusion training and one in reverse sampling) to tackle the condition collapse and guarantee the sufficient use of condition information. For efficiency, we introduce the fast sampling technique to reduce the sampling process into several steps and exploit a refinement network to calibrate the defective speech. Our proposed method achieves the state-of-the-art performance to the GAN-based model and shows a significant improvement over existing DDPM-based algorithms.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
SlideVQA- A Dataset for Document Visual Question Answering on Multiple Images | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26598), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26598/26370), [keywords](SNLP: Question Answering, CV: Language and Vision), [abstract](Abstract
Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering as a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Reducing Sentiment Bias in Pre-trained Sentiment Classification via Adaptive Gumbel Attack | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26599), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26599/26371), [keywords](SNLP: Sentiment Analysis and Stylistic Analysis, SNLP: Language Models), [abstract](Abstract
Pre-trained language models (PLMs) have recently enabled rapid progress on sentiment classification under the pre-train and fine-tune paradigm, where the fine-tuning phase aims to transfer the factual knowledge learned by PLMs to sentiment classification. However, current fine-tuning methods ignore the risk that PLMs cause the problem of sentiment bias, that is, PLMs tend to inject positive or negative sentiment from the contextual information of certain entities (or aspects) into their word embeddings, leading them to establish spurious correlations with labels. In this paper, we propose an adaptive Gumbel-attacked classifier that immunes sentiment bias from an adversarial-attack perspective. Due to the complexity and diversity of sentiment bias, we construct multiple Gumbel-attack expert networks to generate various noises from mixed Gumbel distribution constrained by mutual information minimization, and design an adaptive training framework to synthesize complex noise by confidence-guided controlling the number of expert networks. Finally, we capture these noises that effectively simulate sentiment bias based on the feedback of the classifier, and then propose a multi-channel parameter updating algorithm to strengthen the classifier to recognize these noises by fusing the parameters between the classifier and each expert network. Experimental results illustrate that our method significantly reduced sentiment bias and improved the performance of sentiment classification.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Latent Constraints on Unsupervised Text-Graph Alignment with Information Asymmetry | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26600), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26600/26372), [keywords](SNLP: Generation, SNLP: Other Foundations of Speech & Natural Language Processing), [abstract](Abstract
Unsupervised text-graph alignment (UTGA) is a fundamental task that bidirectionally generates texts and graphs without parallel data. Most available models of UTGA suffer from information asymmetry, a common phenomenon that texts and graphs include additional information invisible to each other. On the one hand, these models fail to supplement asymmetric information effectively due to the lack of ground truths. On the other hand, it is challenging to indicate asymmetric information with explicit indicators because it cannot be decoupled from the data directly. To address the challenge posed by information asymmetry, we propose the assumption that asymmetric information is encoded in unobservable latent variables and only affects the one-way generation processes. These latent variables corresponding to asymmetric information should obey prior distributions recovered approximately from original data. Therefore, we first propose a taxonomy of the latent variable that classifies the latent variable into transferrable (TV) and non-transferable (NTV) variables and further distinguish NTV as the dependent variable (DV) and the independent variable (IV). Next, we propose three latent VAE-based regularizations on TV, DV, and IV to constrain their distributions to well-designed prior distributions to introduce asymmetric information into models and enhance the preservation of shared contents. Finally, we impose the three proposed constraints on a cycle-consistent learning framework, back-translation (BT), named ConstrainedBT. Experimental results on three UTGA tasks demonstrate the effectiveness of ConstrainedBT on the information-asymmetric challenge.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
M-sense- Modeling Narrative Structure in Short Personal Narratives Using Protagonist’s Mental Representations | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26601), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26601/26373), [keywords](SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Discourse, Pragmatics & Argument Mining, SNLP: Text Classification, KRR: Reasoning with Beliefs, SNLP: Psycholinguistics and Language Learning), [abstract](Abstract
Narrative is a ubiquitous component of human communication. Understanding its structure plays a critical role in a wide variety of applications, ranging from simple comparative analyses to enhanced narrative retrieval, comprehension, or reasoning capabilities. Prior research in narratology has highlighted the importance of studying the links between cognitive and linguistic aspects of narratives for effective comprehension. This interdependence is related to the textual semantics and mental language in narratives, referring to characters' motivations, feelings or emotions, and beliefs. However, this interdependence is hardly explored for modeling narratives. In this work, we propose the task of automatically detecting prominent elements of the narrative structure by analyzing the role of characters' inferred mental state along with linguistic information at the syntactic and semantic levels. We introduce a STORIES dataset of short personal narratives containing manual annotations of key elements of narrative structure, specifically climax and resolution. To this end, we implement a computational model that leverages the protagonist's mental state information obtained from a pre-trained model trained on social commonsense knowledge and integrates their representations with contextual semantic embed-dings using a multi-feature fusion approach. Evaluating against prior zero-shot and supervised baselines, we find that our model is able to achieve significant improvements in the task of identifying climax and resolution.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Taming Continuous Posteriors for Latent Variational Dialogue Policies | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26602), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26602/26374), [keywords](SNLP: Conversational AI/Dialogue Systems, ML: Reinforcement Learning Algorithms, ML: Deep Generative Models & Autoencoders), [abstract](Abstract
Utilizing amortized variational inference for latent-action reinforcement learning (RL) has been shown to be an effective approach in Task-oriented Dialogue (ToD) systems for optimizing dialogue success.Until now, categorical posteriors have been argued to be one of the main drivers of performance. In this work we revisit Gaussian variational posteriors for latent-action RL and show that they can yield even better performance than categoricals. We achieve this by introducing an improved variational inference objective for learning continuous representations without auxiliary learning objectives, which streamlines the training procedure. Moreover, we propose ways to regularize the latent dialogue policy, which helps to retain good response coherence. Using continuous latent representations our model achieves state of the art dialogue success rate on the MultiWOZ benchmark, and also compares well to categorical latent methods in response coherence.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Uncertainty-Aware Self-Training for Low-Resource Neural Sequence Labeling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26603), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26603/26375), [keywords](SNLP: Information Extraction, SNLP: Applications, SNLP: Language Models, SNLP: Text Mining), [abstract](Abstract
Neural sequence labeling (NSL) aims at assigning labels for input language tokens, which covers a broad range of applications, such as named entity recognition (NER) and slot filling, etc. However, the satisfying results achieved by traditional supervised-based approaches heavily depend on the large amounts of human annotation data, which may not be feasible in real-world scenarios due to data privacy and computation efficiency issues. This paper presents SeqUST, a novel uncertain-aware self-training framework for NSL to address the labeled data scarcity issue and to effectively utilize unlabeled data. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation at the token level and then select reliable language tokens from unlabeled data based on the model confidence and certainty. A well-designed masked sequence labeling task with a noise-robust loss supports robust training, which aims to suppress the problem of noisy pseudo labels. In addition, we develop a Gaussian-based consistency regularization technique to further improve the model robustness on Gaussian-distributed perturbed representations. This effectively alleviates the over-fitting dilemma originating from pseudo-labeled augmented data. Extensive experiments over six benchmarks demonstrate that our SeqUST framework effectively improves the performance of self-training, and consistently outperforms strong baselines by a large margin in low-resource scenarios.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Disentangled CVAEs with Contrastive Learning for Explainable Recommendation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26604), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26604/26376), [keywords](SNLP: Generation), [abstract](Abstract
Modern recommender systems are increasingly expected to provide informative explanations that enable users to understand the reason for particular recommendations. However, previous methods struggle to interpret the input IDs of user--item pairs in real-world datasets, failing to extract adequate characteristics for controllable generation. To address this issue, we propose disentangled conditional variational autoencoders (CVAEs) for explainable recommendation, which leverage disentangled latent preference factors and guide the explanation generation with the refined condition of CVAEs via a self-regularization contrastive learning loss. Extensive experiments demonstrate that our method generates high-quality explanations and achieves new state-of-the-art results in diverse domains.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
fmLRE- A Low-Resource Relation Extraction Model Based on Feature Mapping Similarity Calculation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26605), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26605/26377), [keywords](SNLP: Information Extraction, DMKM: Linked Open Data, Knowledge Graphs & KB Completion), [abstract](Abstract
Low-resource relation extraction (LRE) aims to extract relations from limited labeled corpora.  Existing work takes advantages of self-training or distant supervision to expand the limited labeled data in the data-driven approaches, while the selection bias of pseudo labels may cause the error accumulation in subsequent relation classification. To address this issue, this paper proposes fmLRE, an iterative feedback method based on feature mapping similarity calculation to improve the accuracy of pseudo labels. First, it calculates the similarities between pseudo-label and real-label data of the same category in a feature mapping space based on semantic features of labeled dataset after feature projection. Then, it fine-tunes initial model according to the iterative process of reinforcement learning. Finally, the similarity is used as a threshold for screening high-precision pseudo-labels and the basis for setting different rewards, which also acts as a penalty term for the loss function of relation classifier. Experimental results demonstrate that fmLRE achieves the state-of-the-art performance compared with strong baselines on two public datasets.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26606), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26606/26378), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Generation), [abstract](Abstract
Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the output sentence is learned in the inner loop, allowing the NMT model to translate semantically equivalent sentences to the same target sentence. We conduct experiments on the NIST Chinese to English task, three WMT translation tasks, and the TED M2O task. The results demonstrate that CoNMT effectively improves overall translation quality and reliably handles diverse inputs.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Zero-Shot Face-Based Voice Conversion- Bottleneck-Free Speech Disentanglement in the Real-World Scenario | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26607), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26607/26379), [keywords](SNLP: Generation, SNLP: Speech and Multimodality, ML: Multimodal Learning), [abstract](Abstract
Often a face has a voice. Appearance sometimes has a strong relationship with one's voice. In this work, we study how a face can be converted to a voice, which is a face-based voice conversion. Since there is no clean dataset that contains face and speech, voice conversion faces difficult learning and low-quality problems caused by background noise or echo. Too much redundant information for face-to-voice also causes synthesis of a general style of speech. Furthermore, previous work tried to disentangle speech with bottleneck adjustment. However, it is hard to decide on the size of the bottleneck. Therefore, we propose a bottleneck-free strategy for speech disentanglement. To avoid synthesizing the general style of speech, we utilize framewise facial embedding. It applied adversarial learning with a multi-scale discriminator for the model to achieve better quality. In addition, the self-attention module is added to focus on content-related features for in-the-wild data. Quantitative experiments show that our method outperforms previous work.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Adversarial Self-Attention for Language Understanding | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26608), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26608/26380), [keywords](SNLP: Adversarial Attacks & Robustness, SNLP: Language Models), [abstract](Abstract
Deep neural models (e.g. Transformer) naturally learn spurious features, which create a ``shortcut'' between the labels and inputs, thus impairing the generalization and robustness. This paper advances self-attention mechanism to its robust variant for Transformer-based pre-trained language models (e.g. BERT). We propose Adversarial Self-Attention mechanism (ASA), which adversarially biases the attentions to effectively suppress the model reliance on features (e.g. specific keywords) and encourage its exploration of broader semantics. We conduct comprehensive evaluation across a wide range of tasks for both pre-training and fine-tuning stages. For pre-training, ASA unfolds remarkable performance gain compared to naive training for longer steps. For fine-tuning, ASA-empowered models outweigh naive models by a large margin considering both generalization and robustness.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
See How You Read- Multi-Reading Habits Fusion Reasoning for Multi-Modal Fake News Detection | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26609), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26609/26381), [keywords](SNLP: Applications, APP: Humanities & Computational Social Science, SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Text Mining), [abstract](Abstract
The existing approaches based on different neural networks automatically capture and fuse the multimodal semantics of news, which have achieved great success for fake news detection. However, they still suffer from the limitations of both shallow fusion of multimodal features and less attention to the inconsistency between different modalities. To overcome them, we propose multi-reading habits fusion reasoning networks (MRHFR) for multi-modal fake news detection. In MRHFR, inspired by people's different reading habits for multimodal news, we summarize three basic cognitive reading habits and put forward cognition-aware fusion layer to learn the dependencies between multimodal features of news, so as to deepen their semantic-level integration. To explore the inconsistency of different modalities of news, we develop coherence constraint reasoning layer from two perspectives, which first measures the semantic consistency between the comments and different modal features of the news, and then probes the semantic deviation caused by unimodal features to the multimodal news content through constraint strategy. Experiments on two public datasets not only demonstrate that MRHFR not only achieves the excellent performance but also provides a new paradigm for capturing inconsistencies between multi-modal news.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Identify Event Causality with Knowledge and Analogy | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26610), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26610/26382), [keywords](SNLP: Applications, KRR: Applications), [abstract](Abstract
Event causality identification (ECI) aims to identify the
causal relationship between events, which plays a crucial role
in deep text understanding. Due to the diversity of real-world
causality events and difficulty in obtaining sufficient training
data, existing ECI approaches have poor generalizability and
struggle to identify the relation between seldom seen events.
In this paper, we propose to utilize both external knowledge
and internal analogy to improve ECI. On the one hand, we
utilize a commonsense knowledge graph called ConceptNet
to enrich the description of an event sample and reveal the
commonalities or associations between different events. On
the other hand, we retrieve similar events as analogy exam-
ples and glean useful experiences from such analogous neigh-
bors to better identify the relationship between a new event
pair. By better understanding different events through exter-
nal knowledge and making an analogy with similar events, we
can alleviate the data sparsity issue and improve model gener-
alizability. Extensive evaluations on two benchmark datasets
show that our model outperforms other baseline methods by
around 18% on the F1-value on average), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Continual Graph Convolutional Network for Text Classification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26611), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26611/26383), [keywords](SNLP: Text Classification, SNLP: Information Extraction, SNLP: Learning & Optimization for SNLP, SNLP: Ontology Induction From Text, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Graph convolutional network (GCN) has been successfully applied to capture global non-consecutive and long-distance semantic information for text classification. However, while GCN-based methods have shown promising results in offline evaluations, they commonly follow a seen-token-seen-document paradigm by constructing a fixed document-token graph and cannot make inferences on new documents. It is a challenge to deploy them in online systems to infer steaming text data. In this work, we present a continual GCN model (ContGCN) to generalize inferences from observed documents to unobserved documents. Concretely, we propose a new all-token-any-document paradigm to dynamically update the document-token graph in every batch during both the training and testing phases of an online system. Moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update ContGCN in a label-free manner. A 3-month A/B test on Huawei public opinion analysis system shows ContGCN achieves 8.86% performance gain compared with state-of-the-art methods. Offline experiments on five public datasets also show ContGCN can improve inference quality. The source code will be released at https://github.com/Jyonn/ContGCN.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
InfoCTM- A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26612), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26612/26384), [keywords](SNLP: Text Mining, SNLP: Text Classification, SNLP: Machine Translation & Multilinguality), [abstract](Abstract
Cross-lingual topic models have been prevalent for cross-lingual text analysis by revealing aligned latent topics. However, most existing methods suffer from producing repetitive topics that hinder further analysis and performance decline caused by low-coverage dictionaries. In this paper, we propose the Cross-lingual Topic Modeling with Mutual Information (InfoCTM). Instead of the direct alignment in previous work, we propose a topic alignment with mutual information method. This works as a regularization to properly align topics and prevent degenerate topic representations of words, which mitigates the repetitive topic issue. To address the low-coverage dictionary issue, we further propose a cross-lingual vocabulary linking method that finds more linked cross-lingual words for topic alignment beyond the translations of a given dictionary. Extensive experiments on English, Chinese, and Japanese datasets demonstrate that our method outperforms state-of-the-art baselines, producing more coherent, diverse, and well-aligned topics and showing better transferability for cross-lingual classification tasks.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
VideoDubber- Machine Translation with Speech-Aware Length Control for Video Dubbing | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26613), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26613/26385), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Speech and Multimodality), [abstract](Abstract
Video dubbing aims to translate the original speech in a film or television program into the speech in a target language, which can be achieved with a cascaded system consisting of speech recognition, machine translation and speech synthesis. To ensure the translated speech to be well aligned with the corresponding video, the length/duration of the translated speech should be as close as possible to that of the original speech, which requires strict length control. Previous works usually control the number of words or characters generated by the machine translation model to be similar to the source sentence, without considering the isochronicity of speech as the speech duration of words/characters in different languages varies. In this paper, we propose VideoDubber, a machine translation system tailored for the task of video dubbing, which directly considers the speech duration of each token in translation, to match the length of source and target speech. Specifically, we control the speech length of generated sentence by guiding the prediction of each word with the duration information, including the speech duration of itself as well as how much duration is left for the remaining words. We design experiments on four language directions (German -> English, Spanish -> English, Chinese <-> English), and the results show that VideoDubber achieves better length control ability on the generated speech than baseline methods. To make up the lack of real-world datasets, we also construct a real-world test set collected from films to provide comprehensive evaluations on the video dubbing task.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Don’t Be So Sure! Boosting ASR Decoding via Confidence Relaxation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26614), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26614/26386), [keywords](SNLP: Other Foundations of Speech & Natural Language Processing, SNLP: Applications, SNLP: Conversational AI/Dialogue Systems, SNLP: Interpretability & Analysis of NLP Models, SNLP: Language Models), [abstract](Abstract
Automatic Speech Recognition (ASR) systems frequently use a search-based decoding strategy aiming to find the best attainable transcript by considering multiple candidates. One prominent speech recognition decoding heuristic is beam search, which seeks the transcript with the greatest likelihood computed using the predicted distribution. While showing substantial performance gains in various tasks, beam search loses some of its effectiveness when the predicted probabilities are highly confident, i.e., the predicted distribution is massed for a single or very few classes. We show that recently proposed Self-Supervised Learning (SSL)-based ASR models tend to yield exceptionally confident predictions that may hamper beam search from truly considering a diverse set of candidates. We perform a layer analysis to reveal and visualize how predictions evolve, and propose a decoding procedure that improves the performance of fine-tuned ASR models. Our proposed approach does not require further training beyond the original fine-tuning, nor additional model parameters. In fact, we find that our proposed method requires significantly less inference computation than current approaches. We propose aggregating the top M layers, potentially leveraging useful information encoded in intermediate layers, and relaxing model confidence. We demonstrate the effectiveness of our approach by conducting an empirical study on varying amounts of labeled resources and different model sizes, showing consistent improvements in particular when applied to low-resource scenarios.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
AMOM- Adaptive Masking over Masking for Conditional Masked Language Model | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26615), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26615/26387), [keywords](SNLP: Generation, SNLP: Machine Translation & Multilinguality, SNLP: Summarization), [abstract](Abstract
Transformer-based autoregressive (AR) methods have achieved appealing performance for varied sequence-to-sequence generation tasks, e.g., neural machine translation, summarization, and code generation, but suffer from low inference efficiency. To speed up the inference stage, many non-autoregressive (NAR) strategies have been proposed in the past few years. Among them, the conditional masked language model (CMLM) is one of the most versatile frameworks, as it can support many different sequence generation scenarios and achieve very competitive performance on these tasks. In this paper, we further introduce a simple yet effective adaptive masking over masking strategy to enhance the refinement capability of the decoder and make the encoder optimization easier. Experiments on 3 different tasks (neural machine translation, summarization, and code generation) with 15 datasets in total confirm that our proposed simple method achieves significant performance improvement over the strong CMLM model. Surprisingly, our proposed model yields state-of-the-art performance on neural machine translation (34.62 BLEU on WMT16 EN to RO, 34.82 BLEU on WMT16 RO to EN, and 34.84 BLEU on IWSLT De to En) and even better performance than the AR Transformer on 7 benchmark datasets with at least 2.2x speedup. Our code is available at GitHub.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Global Mixup- Eliminating Ambiguity with Clustering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26616), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26616/26388), [keywords](SNLP: Applications, SNLP: Text Classification), [abstract](Abstract
Data augmentation with Mixup has been proven an effective method to regularize the current deep neural networks. Mixup generates virtual samples and corresponding labels simultaneously by linear interpolation. However, the one-stage generation paradigm and the use of linear interpolation have two defects: (1) The label of the generated sample is simply combined from the labels of the original sample pairs without reasonable judgment, resulting in ambiguous labels. (2) Linear combination significantly restricts the sampling space for generating samples. To address these issues, we propose a novel and effective augmentation method, Global Mixup, based on global clustering relationships.
Specifically, we transform the previous one-stage augmentation process into two-stage by decoupling the process of generating virtual samples from the labeling. And for the labels of the generated samples, relabeling is performed based on clustering by calculating the global relationships of the generated samples.
Furthermore, we are no longer restricted to linear relationships, which allows us to generate more reliable virtual samples in a larger sampling space.
Extensive experiments for CNN, LSTM, and BERT on five tasks show that Global Mixup outperforms previous baselines. Further experiments also demonstrate the advantage of Global Mixup in low-resource scenarios.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
MoEC- Mixture of Expert Clusters | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26617), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26617/26389), [keywords](SNLP: Machine Translation & Multilinguality, SNLP: Learning & Optimization for SNLP), [abstract](Abstract
Sparsely Mixture of Experts (MoE) has received great interest due to its promising scaling capability with affordable computational overhead. MoE models convert dense layers into sparse experts, and utilize a gated routing network to make experts conditionally activated. However, as the number of experts grows, MoE with outrageous parameters suffers from overfitting and sparse data allocation. Such problems are especially severe on tasks with limited data, thus hindering the progress towards improving performance by scaling up. We verify that there exists a performance upper bound of scaling up sparse MoE. In this work, we propose Mixture of Expert Clusters — a general approach to enable expert layers to learn more diverse and appropriate knowledge by imposing variance-based constraints on the routing stage. Given this, we could further propose a cluster-level expert dropout strategy specifically designed for the expert cluster structure. Our experiments reveal that MoEC could improve performance on machine translation and natural language understanding tasks. MoEC plays a positive role in mitigating overfitting and sparse data allocation problems, thus fully releasing the potential of large-scale sparse models.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Factual and Informative Review Generation for Explainable Recommendation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26618), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26618/26390), [keywords](SNLP: Generation, DMKM: Recommender Systems, PEAI: Interpretability and Explainability, SNLP: Language Grounding), [abstract](Abstract
Recent models can generate fluent and grammatical synthetic reviews while accurately predicting user ratings. The generated reviews, expressing users' estimated opinions towards related products, are often viewed as natural language ‘rationales’ for the jointly predicted rating. However, previous studies found that existing models often generate repetitive, universally applicable, and generic explanations, resulting in uninformative rationales. Further, our analysis shows that previous models' generated content often contain factual hallucinations. These issues call for novel solutions that could generate both informative and factually grounded explanations. Inspired by recent success in using retrieved content in addition to parametric knowledge for generation, we propose to augment the generator with a personalized retriever, where the retriever's output serves as external knowledge for enhancing the generator. Experiments on Yelp, TripAdvisor, and Amazon Movie Reviews dataset show our model could generate explanations that more reliably entail existing reviews, are more diverse, and are rated more informative by human evaluators.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Dialogue Rewriting via Skeleton-Guided Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26619), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26619/26391), [keywords](SNLP: Conversational AI/Dialogue Systems), [abstract](Abstract
Dialogue rewriting aims to transform multi-turn, context-dependent dialogues into well-formed, context-independent text for most NLP systems. Previous dialogue rewriting benchmarks and systems assume a fluent and informative utterance to rewrite. Unfortunately, dialogue utterances from real-world systems are frequently noisy and with various kinds of errors that can make them almost uninformative. In this paper, we first present Real-world Dialogue Rewriting Corpus (RealDia), a new benchmark to evaluate how well current dialogue rewriting systems can deal with real-world noisy and uninformative dialogue utterances. RealDia contains annotated multi-turn dialogues from real scenes with ASR errors, spelling errors, redundancies and other noises that are ignored by previous dialogue rewriting benchmarks. We show that previous dialogue rewriting approaches are neither effective nor data-efficient to resolve RealDia. Then this paper presents Skeleton-Guided Rewriter (SGR), which can resolve the task of dialogue rewriting via a skeleton-guided generation paradigm. Experiments show that RealDia is a much more challenging benchmark for real-world dialogue rewriting, and SGR can effectively resolve the task and outperform previous approaches by a large margin.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26620), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26620/26392), [keywords](SNLP: Conversational AI/Dialogue Systems), [abstract](Abstract
In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to extract users' intentions from the dialogue history. Currently, most existing approaches suffer from error propagation and are unable to dynamically select relevant information when utilizing previous dialogue states. Moreover, the relations between the updates of different slots provide vital clues for DST. However, the existing approaches rely only on predefined graphs to indirectly capture the relations. In this paper, we propose a Dialogue State Distillation Network (DSDN) to utilize relevant information of previous dialogue states and migrate the gap of utilization between training and testing. Thus, it can dynamically exploit previous dialogue states and avoid introducing error propagation simultaneously. Further, we propose an inter-slot contrastive learning loss to effectively capture the slot co-update relations from dialogue context. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ 2.1 datasets. The experimental results show that our proposed model achieves the state-of-the-art performance for DST.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26621), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26621/26393), [keywords](SNLP: Conversational AI/Dialogue Systems, ML: Lifelong and Continual Learning, ML: Meta Learning), [abstract](Abstract
In real-world scenarios, it is crucial to build a lifelong taskoriented dialogue system (TDS) that continually adapts to new knowledge without forgetting previously acquired experiences. Existing approaches mainly focus on mitigating the catastrophic forgetting in lifelong TDS. However, the transfer ability to generalize the accumulated old knowledge to new tasks is underexplored. In this paper, we propose a two-stage lifelong task-oriented dialogue generation method to mitigate catastrophic forgetting and encourage knowledge transfer simultaneously, inspired by the learning process. In the first stage, we learn task-specific masks which adaptively preserve the knowledge of each visited task so as to mitigate catastrophic forgetting. In this stage, we are expected to learn the task-specific knowledge which is tailored for each task. In the second stage, we bring the knowledge from the encountered tasks together and understand thoroughly. To this end, we devise a balanced meta learning strategy for both forward and backward knowledge transfer in the lifelong learning process. In particular, we perform meta-update with a meta-test set sampled from the current training data for forward knowledge transfer. In addition, we employ an uncertainty-based sampling strategy to select and store representative dialogue samples into episodic memory and perform meta-update with a meta-test set sampled from the memory for backward knowledge transfer. With extensive experiments on 29 tasks, we show that MetaLTDS outperforms the strong baselines in terms of both effectiveness and efficiency. For reproducibility, we submit our code at: https: //github.com/travis-xu/MetaLTDS.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Selector-Enhancer- Learning Dynamic Selection of Local and Non-local Attention Operation for Speech Enhancement | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26622), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26622/26394), [keywords](SNLP: Speech and Multimodality, ML: Reinforcement Learning Algorithms), [abstract](Abstract
Attention mechanisms, such as local and non-local attention, play a fundamental role in recent deep learning based speech enhancement (SE) systems. However, a natural speech contains many fast-changing and relatively briefly acoustic events, therefore, capturing the most informative speech features by indiscriminately using local and non-local attention is challenged. We observe that the noise type and speech feature vary within a sequence of speech and the local and non-local can respectively process different types of corrupted speech regions. To leverage this, we propose Selector-Enhancer, a dual-attention based convolution neural network (CNN) with a feature-filter that can dynamically select regions from low-resolution speech features and feed them to local or non-local attention operations. In particular, the proposed feature-filter is trained by using reinforcement learning (RL) with a developed difficulty-regulated reward that related to network performance, model complexity and “the difficulty of the SE task”. The results show that our method achieves comparable or superior performance to existing approaches. In particular, Selector-Enhancer is effective for real-world denoising, where the number and types of noise are varies on a single noisy mixture.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Graph Fusion Approach for Cross-Lingual Machine Reading Comprehension | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26623), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26623/26395), [keywords](SNLP: Machine Translation & Multilinguality), [abstract](Abstract
Although great progress has been made for Machine Reading Comprehension (MRC) in English, scaling out to a large number of languages remains a huge challenge due to the lack of large amounts of annotated training data in non-English languages. To address this challenge, some recent efforts of cross-lingual MRC employ machine translation to transfer knowledge from English to other languages, through either explicit alignment or implicit attention. For effective knowledge transition, it is beneficial to leverage both semantic and syntactic information. However, the existing methods fail to explicitly incorporate syntax information in model learning. Consequently, the models are not robust to errors in alignment and noises in attention. In this work, we propose a novel approach, which jointly models the cross-lingual alignment information and the mono-lingual syntax information using a graph. We develop a series of algorithms, including graph construction, learning, and pre-training. The experiments on two benchmark datasets for cross-lingual MRC show that our approach outperforms all strong baselines, which verifies the effectiveness of syntax information for cross-lingual MRC.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Improving Biomedical Entity Linking with Cross-Entity Interaction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26624), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26624/26396), [keywords](SNLP: Information Extraction), [abstract](Abstract
Biomedical entity linking (EL) is the task of linking mentions in a biomedical document to corresponding entities in a knowledge base (KB). The challenge in biomedical EL lies in leveraging mention context to select the most appropriate entity among possible candidates. Although some EL models achieve competitive results by retrieving candidate entities and then exploiting context to re-rank them, these re-ranking models concatenate mention context with one candidate at a time. They lack fine-grained interaction among candidates, and potentially cannot handle ambiguous mentions when facing candidates both with high lexical similarity. We cope with this issue using a re-ranking model based on prompt tuning, which represents mention context and all candidates at once, letting candidates in comparison attend to each other. We also propose a KB-enhanced self-supervised pretraining strategy. Instead of large-scale pretraining on biomedical EL data in previous work, we use masked language modeling with synonyms from KB. Our method achieves state-of-the-art results on 3 biomedical EL datasets: NCBI disease, BC5CDR and COMETA, showing the effectiveness of cross-entity interaction and KB-enhanced pretraining strategy. Code is available at https://github.com/HITsz-TMG/Prompt-BioEL.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Nested Named Entity Recognition as Building Local Hypergraphs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26625), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26625/26397), [keywords](SNLP: Information Extraction, SNLP: Applications), [abstract](Abstract
Named entity recognition is a fundamental task in natural language processing. Based on the sequence labeling paradigm for flat named entity recognition, multiple methods have been developed to handle the nested structures. However, they either require fixed recognition order or introduce complex hypergraphs. To tackle this problem, we propose a novel model named Local Hypergraph Builder Network (LHBN) that builds multiple simpler local hypergraphs to capture named entities instead of a single complex full-size hypergraph. The proposed model has three main properties: (1) The named entities that share boundaries are captured in the same local hypergraph. (2) The boundary information is enhanced by building local hypergraphs. (3) The hypergraphs can be built bidirectionally to take advantage of the identification direction preference of different named entities. Experiments illustrate that our model outperforms previous state-of-the-art methods on four widely used nested named entity recognition datasets: ACE04, ACE05, GENIA, and KBP17. The code is available at https://github.com/yanyk13/local-hypergraph-building-network.git.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Domain-Transfer Meta Task Design Paradigm for Few-Shot Slot Tagging | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26626), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26626/26398), [keywords](SNLP: Conversational AI/Dialogue Systems, ML: Meta Learning, SNLP: Text Mining), [abstract](Abstract
Few-shot slot tagging is an important task in dialogue systems and attracts much attention of researchers. Most previous few-shot slot tagging methods utilize meta-learning procedure for training and strive to construct a large number of different meta tasks to simulate the testing situation of insufficient data. However, there is a widespread phenomenon of overlap slot between two domains in slot tagging. Traditional meta tasks ignore this special phenomenon and cannot simulate such realistic few-shot slot tagging scenarios. It violates the basic principle of meta-learning which the meta task is consistent with the real testing task, leading to historical information forgetting problem. In this paper, we introduce a novel domain-transfer meta task design paradigm to tackle this problem. We distribute a basic domain to each target domain based on the coincidence degree of slot labels between these two domains. Unlike classic meta tasks which only rely on small samples of target domain, our meta tasks aim to correctly infer the class of target domain query samples based on both abundant data in basic domain and scarce data in target domain. To accomplish our meta task, we propose a Task Adaptation Network to effectively transfer the historical information from the basic domain to the target domain. We carry out sufficient experiments on the benchmark slot tagging dataset SNIPS and the name entity recognition dataset NER. Results demonstrate that our proposed model outperforms previous methods and achieves the state-of-the-art performance.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Orders Are Unwanted- Dynamic Deep Graph Convolutional Network for Personality Detection | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26627), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26627/26399), [keywords](SNLP: Applications), [abstract](Abstract
Predicting personality traits based on online posts has emerged as an important task in many fields such as social network analysis. One of the challenges of this task is assembling information from various posts into an overall profile for each user. While many previous solutions simply concatenate the posts into a long text and then encode the text by sequential or hierarchical models, they introduce unwarranted orders for the posts, which may mislead the models. In this paper, we propose a dynamic deep graph convolutional network (D-DGCN) to overcome the above limitation. Specifically, we design a learn-to-connect approach that adopts a dynamic multi-hop structure instead of a deterministic structure, and combine it with the DGCN module to automatically learn the connections between posts. The modules of post encoder, learn-to-connect, and DGCN are jointly trained in an end-to-end manner. Experimental results on the Kaggle and Pandora datasets show the superior performance of D-DGCN to state-of-the-art baselines. Our code is available at https://github.com/djz233/D-DGCN.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
What Does Your Face Sound Like- 3D Face Shape towards Voice | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26628), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26628/26400), [keywords](SNLP: Speech and Multimodality, SNLP: Generation), [abstract](Abstract
Face-based speech synthesis provides a practical solution to generate voices from human faces. However, directly using 2D face images leads to the problems of uninterpretability and entanglement. In this paper, to address the issues, we introduce 3D face shape which (1) has an anatomical relationship between voice characteristics, partaking in the "bone conduction" of human timbre production, and (2) is naturally independent of irrelevant factors by excluding the blending process. We devise a three-stage framework to generate speech from 3D face shapes. Fully considering timbre production in anatomical and acquired terms, our framework incorporates three additional relevant attributes including face texture, facial features, and demographics. Experiments and subjective tests demonstrate our method can generate utterances matching faces well, with good audio quality and voice diversity. We also explore and visualize how the voice changes with the face. Case studies show that our method upgrades the face-voice inference to personalized custom-made voice creating, revealing a promising prospect in virtual human and dubbing applications.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
FiTs- Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26629), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26629/26401), [keywords](SNLP: Question Answering), [abstract](Abstract
Knowledge-aware question answering (KAQA) requires the model to answer questions over a knowledge base, which is essential for both open-domain QA and domain-specific QA, especially when language models alone cannot provide all the knowledge needed.
Despite the promising result of recent KAQA systems which tend to integrate linguistic knowledge from pre-trained language models (PLM) and factual knowledge from knowledge graphs (KG) to answer complex questions, a bottleneck exists in effectively fusing the representations from PLMs and KGs because of (i) the semantic and distributional gaps between them, and (ii) the difficulties in joint reasoning over the provided knowledge from both modalities.
To address the above two problems, we propose a Fine-grained Two-stage training framework (FiTs) to boost the KAQA system performance: The first stage aims at aligning representations from the PLM and the KG, thus bridging the modality gaps between them, named knowledge adaptive post-training. The second stage, called knowledge-aware fine-tuning, aims to improve the model's joint reasoning ability based on the aligned representations.
In detail,  we fine-tune the post-trained model via two auxiliary self-supervised tasks in addition to the QA supervision.
Extensive experiments demonstrate that our approach achieves state-of-the-art performance on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMILE) domains.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
On the Calibration and Uncertainty with Pólya-Gamma Augmentation for Dialog Retrieval Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26630), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26630/26402), [keywords](SNLP: Conversational AI/Dialogue Systems, ML: Calibration & Uncertainty Quantification, RU: Applications, SNLP: Question Answering), [abstract](Abstract
Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by Pólya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping R10@1 and MAP performance.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Preserve Context Information for Extract-Generate Long-Input Summarization Framework | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26631), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26631/26403), [keywords](SNLP: Summarization), [abstract](Abstract
The Extract-generate framework has been a classic approach for text summarization. As pretrained language models struggling with long-input summarization for their high memory cost, extract-generate framework regains researchers' interests. However, the cost of its effectiveness in dealing with long-input summarization is the loss of context information. In this paper, we present a context-aware extract-generate framework (CAEG) for long-input text summarization. It focuses on preserving both local and global context information in an extract-generate framework with little cost, and can be applied to most of existing extract-generate summarization models. CAEG generates a set of context-related text spans called context prompts for each text snippet and use them to transfer the context information from the extractor and generator. To find such context prompts, we propose to capture the context information based on the interpretation of the extractor, where the text spans having the highest contribution to the extraction decision are considered as containing the richest context information. We evaluate our approach on both long-document and long-dialogue summarization datasets: arXiv and QMSum. The experiment results show that CAEG achieves the-state-of-art result on QMSum and outperforms other extract-generate based models in arXiv.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Transferable Post-hoc Calibration on Pretrained Transformers in Noisy Text Classification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26632), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26632/26404), [keywords](SNLP: Adversarial Attacks & Robustness, SNLP: Text Classification), [abstract](Abstract
Recent work has demonstrated that pretrained transformers are overconfident in text classification tasks, which can be calibrated by the famous post-hoc calibration method temperature scaling (TS). Character or word spelling mistakes are frequently encountered in real applications and greatly threaten transformer model safety. Research on calibration under noisy settings is rare, and we focus on this direction. Based on a toy experiment, we discover that TS performs poorly when the datasets are perturbed by slight noise, such as swapping the characters, which results in distribution shift. We further utilize two metrics, predictive uncertainty and maximum mean discrepancy (MMD), to measure the distribution shift between clean and noisy datasets, based on which we propose a simple yet effective transferable TS method for calibrating models dynamically. To evaluate the performance of the proposed methods under noisy settings, we construct a benchmark consisting of four noise types and five shift intensities based on the QNLI, AG-News, and Emotion tasks. Experimental results on the noisy benchmark show that (1) the metrics are effective in measuring distribution shift and (2) transferable TS can significantly decrease the expected calibration error (ECE) compared with the competitive baseline ensemble TS by approximately 46.09%.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Quantum-Inspired Representation for Long-Tail Senses of Word Sense Disambiguation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26633), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26633/26405), [keywords](SNLP: Other Foundations of Speech & Natural Language Processing, ML: Quantum Machine Learning, ML: Representation Learning, SNLP: Language Grounding), [abstract](Abstract
Data imbalance, also known as the long-tail distribution of data, is an important challenge for data-driven models. In the Word Sense Disambiguation (WSD) task, the long-tail phenomenon of word sense distribution is more common, making it difficult to effectively represent and identify Long-Tail Senses (LTSs). Therefore exploring representation methods that do not rely heavily on the training sample size is an important way to combat LTSs. Considering that many new states, namely superposition states, can be constructed from several known states in quantum mechanics, superposition states provide the possibility to obtain more accurate representations from inferior representations learned from a small sample size. Inspired by quantum superposition states, a representation method in Hilbert space is proposed to reduce the dependence on large sample sizes and thus combat LTSs. We theoretically prove the correctness of the method, and verify its effectiveness under the standard WSD evaluation framework and obtain state-of-the-art performance. Furthermore, we also test on the constructed LTS and the latest cross-lingual datasets, and achieve promising results.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
MPMQA- Multimodal Question Answering on Product Manuals | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26634), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26634/26406), [keywords](SNLP: Question Answering, CV: Language and Vision), [abstract](Abstract
Visual contents, such as illustrations and images, play a big role in product manual understanding. Existing Product Manual Question Answering (PMQA) datasets tend to ignore visual contents and only retain textual parts. 
In this work, to emphasize the importance of multimodal contents, we propose a Multimodal Product Manual Question Answering (MPMQA) task. For each question, MPMQA requires the model not only to process multimodal contents but also to provide multimodal answers. To support MPMQA, a large-scale dataset PM209 is constructed with human annotations, which contains 209 product manuals from 27 well-known consumer electronic brands. Human annotations include 6 types of semantic regions for manual contents and 22,021 pairs of question and answer. Especially, each answer consists of a textual sentence and related visual regions from manuals. Taking into account the length of product manuals and the fact that a question is always related to a small number of pages, MPMQA can be naturally split into two subtasks: retrieving most related pages and then generating multimodal answers. We further propose a unified model that can perform these two subtasks all together and achieve comparable performance with multiple task-specific models. The PM209 dataset is available at https://github.com/AIM3-RUC/MPMQA.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Exploring Self-Distillation Based Relational Reasoning Training for Document-Level Relation Extraction | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26635), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26635/26407), [keywords](SNLP: Information Extraction, SNLP: Text Mining), [abstract](Abstract
Document-level relation extraction (RE) aims to extract relational triples from a document. One of its primary challenges is to predict implicit relations between entities, which are not explicitly expressed in the document but can usually be extracted through relational reasoning. Previous methods mainly implicitly model relational reasoning through the interaction among entities or entity pairs. However, they suffer from two deficiencies: 1) they often consider only one reasoning pattern, of which coverage on relational triples is limited; 2) they do not explicitly model the process of relational reasoning. In this paper, to deal with the first problem, we propose a document-level RE model with a reasoning module that contains a core unit, the reasoning multi-head self-attention unit. This unit is a variant of the conventional multi-head self-attention and utilizes four attention heads to model four common reasoning patterns, respectively, which can cover more relational triples than previous methods. Then, to address the second issue, we propose a self-distillation training framework, which contains two branches sharing parameters. In the first branch, we first randomly mask some entity pair feature vectors in the document, and then train our reasoning module to infer their relations  by exploiting the feature information of other related entity pairs. By doing so, we can explicitly model the process of relational reasoning. However, because the additional masking operation is not used during testing, it causes an input gap between training and testing scenarios, which would hurt the model performance. To reduce this gap, we perform conventional supervised training without masking operation in the second branch and utilize Kullback-Leibler divergence loss to minimize the difference between the predictions of the two branches. Finally, we conduct comprehensive experiments on three benchmark datasets, of which experimental results demonstrate that our model consistently outperforms all competitive baselines. Our source code is available at https://github.com/DeepLearnXMU/DocRE-SD), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Multi-Action Dialog Policy Learning from Logged User Feedback | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26636), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26636/26408), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Applications), [abstract](Abstract
Multi-action dialog policy (MADP), which generates multiple atomic dialog actions per turn, has been widely applied in task-oriented dialog systems to provide expressive and efficient system responses. Existing MADP models usually imitate action combinations from the labeled multi-action dialog samples. Due to data limitations, they generalize poorly toward unseen dialog flows. While reinforcement learning-based methods are proposed to incorporate the service ratings from real users and user simulators as external supervision signals, they suffer from sparse and less credible dialog-level rewards. To cope with this problem, we explore to improve MADPL with explicit and implicit turn-level user feedback received for historical predictions (i.e., logged user feedback) that are cost-efficient to collect and faithful to real-world scenarios. The task is challenging since the logged user feedback provides only partial label feedback limited to the particular historical dialog actions predicted by the agent. To fully exploit such feedback information, we propose BanditMatch, which addresses the task from a feedback-enhanced semi-supervised learning perspective with a hybrid learning objective of SSL and bandit learning. BanditMatch integrates pseudo-labeling methods to better explore the action space through constructing full label feedback. Extensive experiments show that our BanditMatch improves MADPL over the state-of-the-art methods by generating more concise and informative responses. The source code and the appendix of this paper can be obtained from https://github.com/ShuoZhangXJTU/BanditMatch.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Improving End-to-End Speech Translation by Leveraging Auxiliary Speech and Text Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26637), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26637/26409), [keywords](SNLP: Speech and Multimodality, SNLP: Machine Translation & Multilinguality), [abstract](Abstract
We present a method for introducing a text encoder into pre-trained end-to-end speech translation systems. It enhances the ability of adapting one modality (i.e., source-language speech) to another (i.e., source-language text). Thus, the speech translation model can learn from both unlabeled and labeled data, especially when the source-language text data is abundant. Beyond this, we present a denoising method to build a robust text encoder that can deal with both normal and noisy text data. Our system sets new state-of-the-arts on the MuST-C En-De, En-Fr, and LibriSpeech En-Fr tasks.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Neural Span-Based Continual Named Entity Recognition Model | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26638), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26638/26410), [keywords](SNLP: Information Extraction, ML: Lifelong and Continual Learning), [abstract](Abstract
Named Entity Recognition (NER) models capable of Continual Learning (CL) are realistically valuable in areas where entity types continuously increase (e.g., personal assistants). Meanwhile the learning paradigm of NER advances to new patterns such as the span-based methods. However, its potential to CL has not been fully explored. In this paper, we propose SpanKL, a simple yet effective Span-based model with Knowledge distillation (KD) to preserve memories and multi-Label prediction to prevent conflicts in CL-NER. Unlike prior sequence labeling approaches, the inherently independent modeling in span and entity level with the designed coherent optimization on SpanKL promotes its learning at each incremental step and mitigates the forgetting. Experiments on synthetic CL datasets derived from OntoNotes and Few-NERD show that SpanKL significantly outperforms previous SoTA in many aspects, and obtains the smallest gap from CL to the upper bound revealing its high practiced value. The code is available at https://github.com/Qznan/SpanKL.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Language Model Pre-training on True Negatives | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26639), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26639/26411), [keywords](SNLP: Language Models, SNLP: Interpretability & Analysis of NLP Models, SNLP: Question Answering, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Discriminative pre-trained language models (PrLMs) learn to predict original texts from intentionally corrupted ones. Taking the former text as positive and the latter as negative samples, the PrLM can be trained effectively for contextualized representation. However, the training of such a type of PrLMs highly relies on the quality of the automatically constructed samples. Existing PrLMs simply treat all corrupted texts as equal negative without any examination, which actually lets the resulting model inevitably suffer from the false negative issue where training is carried out on pseudo-negative data and leads to less efficiency and less robustness in the resulting PrLMs. In this work, on the basis of defining the false negative issue in discriminative PrLMs that has been ignored for a long time, we design enhanced pre-training methods to counteract false negative predictions and encourage pre-training language models on true negatives by correcting the harmful gradient updates subject to false negative predictions. Experimental results on GLUE and SQuAD benchmarks show that our counter-false-negative pre-training methods indeed bring about better performance together with stronger robustness.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
MCL- Multi-Granularity Contrastive Learning Framework for Chinese NER | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26640), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26640/26412), [keywords](SNLP: Applications, SNLP: Information Extraction), [abstract](Abstract
Recently, researchers have applied the word-character lattice framework to integrated word information, which has become very popular for  Chinese named entity recognition (NER). However, prior approaches  fuse word  information by different variants of encoders such as Lattice LSTM or Flat-Lattice Transformer, but are still not data-efficient indeed to fully  grasp the depth interaction of cross-granularity and important word information from the lexicon. In this paper, we go beyond the typical lattice structure and propose a novel  Multi-Granularity Contrastive Learning  framework (MCL), that aims to optimize the inter-granularity  distribution distance and emphasize the critical matched words in the lexicon. By carefully combining cross-granularity contrastive learning and bi-granularity contrastive learning, the network can explicitly leverage lexicon information  on the  initial lattice structure, and further provide more dense interactions of across-granularity, thus significantly improving model performance. Experiments on four Chinese NER datasets show that MCL obtains state-of-the-art results while considering model efficiency. The source code of the proposed method is publicly available at https://github.com/zs50910/MCL), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26641), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26641/26413), [keywords](SNLP: Sentiment Analysis and Stylistic Analysis), [abstract](Abstract
Causal Emotion Entailment aims to identify causal utterances that are responsible for the target utterance with a non-neutral emotion in conversations. Previous works are limited in thorough understanding of the conversational context and accurate reasoning of the emotion cause. To this end, we propose Knowledge-Bridged Causal Interaction Network (KBCIN) with commonsense knowledge (CSK) leveraged as three bridges. Specifically, we construct a conversational graph for each conversation and leverage the event-centered CSK as the semantics-level bridge (S-bridge) to capture the deep inter-utterance dependencies in the conversational context via the CSK-Enhanced Graph Attention module. Moreover, social-interaction CSK serves as emotion-level bridge (E-bridge) and action-level bridge (A-bridge) to connect candidate utterances with the target one, which provides explicit causal clues for the Emotional Interaction module and Actional Interaction module to reason the target emotion. Experimental results show that our model achieves better performance over most baseline models. Our source code is publicly available at https://github.com/circle-hit/KBCIN.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Query Your Model with Definitions in FrameNet- An Effective Method for Frame Semantic Role Labeling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26642), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26642/26414), [keywords](SNLP: Lexical & Frame Semantics, Semantic Parsing, SNLP: Information Extraction, SNLP: Language Models), [abstract](Abstract
Frame Semantic Role Labeling (FSRL) identifies arguments and labels them with frame semantic roles defined in FrameNet. Previous researches tend to divide FSRL into argument identification and role classification. Such methods usually model role classification as naive multi-class classification and treat arguments individually, which neglects label semantics and interactions between arguments and thus hindering performance and generalization of models. In this paper, we propose a query-based framework named ArGument Extractor with Definitions in FrameNet (AGED) to mitigate these problems. Definitions of frames and frame elements (FEs) in FrameNet can be used to query arguments in text. Encoding text-definition pairs can guide models in learning label semantics and strengthening argument interactions. Experiments show that AGED outperforms previous state-of-the-art by up to 1.3 F1-score in two FrameNet datasets and the generalization power of AGED in zero-shot and fewshot scenarios. Our code and technical appendix is available at https://github.com/PKUnlp-icler/AGED.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Event Process Typing via Hierarchical Optimal Transport | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26643), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26643/26415), [keywords](SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
Understanding intention behind event processes in texts is important to many applications. One challenging task in this line is event process typing, which aims to tag the process with one action label and one object label describing the overall action of the process and object the process likely affects respectively. To tackle this task, existing methods mainly rely on the matching of the event process level and label level representation, which ignores two important characteristics: Process Hierarchy and Label Hierarchy. In this paper, we propose a Hierarchical Optimal Transport (HOT) method to address the above problem. Specifically, we first explicitly extract the process hierarchy and label hierarchy. Then the HOT optimally matches the two types of hierarchy. Experimental results show that our model outperforms the baseline models, illustrating the effectiveness of our model.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
Improving Distantly Supervised Relation Extraction by Natural Language Inference | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26644), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26644/26416), [keywords](SNLP: Information Extraction, SNLP: Text Mining), [abstract](Abstract
To reduce human annotations for relation extraction (RE) tasks, distantly supervised approaches have been proposed, while struggling with low performance. In this work, we propose a novel DSRE-NLI framework, which considers both distant supervision from existing knowledge bases and indirect supervision from pretrained language models for other tasks. DSRE-NLI energizes an off-the-shelf natural language inference (NLI) engine with a semi-automatic relation verbalization (SARV) mechanism to provide indirect supervision and further consolidates the distant annotations to benefit multi-classification RE models. The NLI-based indirect supervision acquires only one relation verbalization template from humans as a semantically general template for each relationship, and then the template set is enriched by high-quality textual patterns automatically mined from the distantly annotated corpus. With two simple and effective data consolidation strategies, the quality of training data is substantially improved. Extensive experiments demonstrate that the proposed framework significantly improves the SOTA performance (up to 7.73% of F1) on distantly supervised RE benchmark datasets. Our code is available at https://github.com/kangISU/DSRE-NLI.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
A Generative Approach for Script Event Prediction via Contrastive Fine-Tuning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26645), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26645/26417), [keywords](SNLP: Sentence-Level Semantics and Textual Inference, SNLP: Applications), [abstract](Abstract
Script event prediction aims to predict the subsequent event given the context. This requires the capability to infer the correlations between events. Recent works have attempted to improve event correlation reasoning by using pretrained language models and incorporating external knowledge (e.g., discourse relations). Though promising results have been achieved, some challenges still remain. First, the pretrained language models adopted by current works ignore event-level knowledge, resulting in an inability to capture the correlations between events well. Second, modeling correlations between events with discourse relations is limited because it can only capture explicit correlations between events with discourse markers, and cannot capture many implicit correlations. To this end, we propose a novel generative approach for this task, in which a pretrained language model is fine-tuned with an event-centric pretraining objective and predicts the next event within a generative paradigm. Specifically, we first introduce a novel event-level blank infilling strategy as the learning objective to inject event-level knowledge into the pretrained language model, and then design a likelihood-based contrastive loss for fine-tuning the generative model. Instead of using an additional prediction layer, we perform prediction by using sequence likelihoods generated by the generative model. Our approach models correlations between events in a soft way without any external knowledge. The likelihood-based prediction eliminates the need to use additional networks to make predictions and is somewhat interpretable since it scores each word in the event. Experimental results on the multi-choice narrative cloze (MCNC) task demonstrate that our approach achieves better results than other state-of-the-art baselines. Our code will be available at https://github.com/zhufq00/mcnc.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
KPT- Keyword-Guided Pre-training for Grounded Dialog Generation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26646), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26646/26418), [keywords](SNLP: Conversational AI/Dialogue Systems, SNLP: Generation), [abstract](Abstract
Incorporating external knowledge into the response generation process is essential to building more helpful and reliable dialog agents. However, collecting knowledge-grounded conversations is often costly, calling for a better pre-trained model for grounded dialog generation that generalizes well w.r.t. different types of knowledge. In this work, we propose KPT (Keyword-guided Pre-Training), a novel self-supervised pre-training method for grounded dialog generation without relying on extra knowledge annotation. Specifically, we use a pre-trained language model to extract the most uncertain tokens in the dialog as keywords. With these keywords, we construct two kinds of knowledge and pre-train a knowledge-grounded response generation model, aiming at handling two different scenarios: (1) the knowledge should be faithfully grounded; (2) it can be selectively used. For the former, the grounding knowledge consists of keywords extracted from the response. For the latter, the grounding knowledge is additionally augmented with keywords extracted from other utterances in the same dialog. Since the knowledge is extracted from the dialog itself, KPT can be easily performed on a large volume and variety of dialogue data.  We considered three data sources (open-domain, task-oriented, conversational QA) with a total of 2.5M dialogues. We conduct extensive experiments on various few-shot knowledge-grounded generation tasks, including grounding on dialog acts, knowledge graphs, persona descriptions, and Wikipedia passages. Our comprehensive experiments and analyses demonstrate that KPT consistently outperforms state-of-the-art methods on these tasks with diverse grounding knowledge.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)
An Ensemble Distillation Framework for Sentence Embeddings with Multilingual Round-Trip Translation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26647), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26647/26419), [keywords](SNLP: Language Models, SNLP: Applications, SNLP: Sentence-Level Semantics and Textual Inference), [abstract](Abstract
In this work, we propose a novel unsupervised contrastive learning framework to improve state-of-the-art sentence embeddings. First, we train a set of contrastive submodels which take multilingual round-trip translation(RTT) as data augmentation. The RTT naturally changes the length of the same sentence and replaces Synonyms simultaneously. Then we incorporate them into a single model through knowledge distillation. Specifically, it takes an input sentence and predicts the ensemble output of all submodels via a contrastive objective. Thus we preserve nearly the same semantic expressiveness as the ensemble model without increasing the test cost. We evaluate our framework on standard semantic textual similarity (STS) tasks. Experimental results show the advantage of our framework that we achieve an average of 79.27% Spearman's correlation, a 3.02% improvement compared to the previous best results using BERT-base.), [group](Technical Tracks 11: AAAI Technical Track on Speech & Natural Language Processing)Synchronization and Diversity of Solutions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26361), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26361/26133), [keywords](MAS: Coordination and Collaboration, MAS: Multiagent Planning), [abstract](Abstract
A central computational problem in the realm of automata theory is the problem of determining whether a finite automaton A has a synchronizing word. This problem has found applications in a variety of subfields of artificial intelligence, including planning, robotics, and multi-agent systems. In this work, we study this problem within the framework of diversity of solutions, an up-and-coming trend in the field of artificial intelligence where the goal is to compute a set of solutions that are sufficiently distinct from one another. We define a notion of diversity of solutions that is suitable for contexts were solutions are strings that may have distinct lengths. Using our notion of diversity, we show that for each fixed r ∈ N, each fixed finite automaton A, and each finite automaton B given at the input, the problem of determining the existence of a diverse set {w1,w2, . . . ,wr} ⊆ L(B) of words that are synchronizing for A can be solved in polynomial time. Finally, we generalize this result to the realm of conformant planning, where the goal is to devise plans that achieve a goal irrespectively of initial conditions and of nondeterminism that may occur during their execution.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
The Multi-Agent Transportation Problem | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26362), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26362/26134), [keywords](MAS: Multiagent Planning, ROB: Motion and Path Planning, PRS: Optimization of Spatio-Temporal Systems, PRS: Routing), [abstract](Abstract
We introduce the multi-agent transportation (MAT) problem, where agents have to transport containers from their starting positions to their designated goal positions. Movement takes place in a common environment where collisions between agents and between containers must be avoided.
In contrast to other frameworks such as multi-agent pathfinding (MAPF) or multi-agent pickup and delivery (MAPD), the agents are allowed to separate from the containers at any time, which can reduce the makespan and also allows for plans in scenarios that are unsolvable otherwise.
We present a complexity analysis establishing the problem's NP-completeness and show how the problem can be reduced to a sequence of SAT problems when optimizing for makespan.
A MAT solver is empirically evaluated with regard to varying input characteristics and movement constraints and compared to a MAPD solver that utilizes conflict-based search (CBS).), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Emergent Quantized Communication | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26363), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26363/26135), [keywords](MAS: Agent Communication, ML: Applications, ML: Deep Neural Architectures, ML: Representation Learning, MAS: Agent-Based Simulation and Emergent Behavior, MAS: Coordination and Collaboration, MAS: Distributed Problem Solving), [abstract](Abstract
The field of emergent communication aims to understand the characteristics of communication as it emerges from artificial agents solving tasks that require information exchange. Communication with discrete messages is considered a desired characteristic, for scientific and applied reasons. However,  training a multi-agent system with discrete communication is not straightforward, requiring either reinforcement learning algorithms or relaxing the discreteness requirement via a continuous approximation such as the Gumbel-softmax. Both these solutions result in poor performance compared to fully continuous communication. In this work, we propose an alternative approach to achieve discrete communication -- quantization of communicated message. Using message quantization allows us to train the model end-to-end, achieving superior performance in multiple setups. Moreover, quantization is a natural framework that runs the gamut from continuous to discrete communication. Thus,  it sets the ground for a broader view of multi-agent communication in the deep learning era.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Learning Explicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning via Polarization Policy Gradient | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26364), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26364/26136), [keywords](MAS: Multiagent Learning, MAS: Coordination and Collaboration, ML: Reinforcement Learning Algorithms, GTEP: Cooperative Game Theory), [abstract](Abstract
Cooperative multi-agent policy gradient (MAPG) algorithms have recently attracted wide attention and are regarded as a general scheme for the multi-agent system. Credit assignment plays an important role in MAPG and can induce cooperation among multiple agents. However, most MAPG algorithms cannot achieve good credit assignment because of the game-theoretic pathology known as centralized-decentralized mismatch. To address this issue, this paper presents a novel method, Multi-Agent Polarization Policy Gradient (MAPPG). MAPPG takes a simple but efficient polarization function to transform the optimal consistency of joint and individual actions into easily realized constraints, thus enabling efficient credit assignment in MAPPG. Theoretically, we prove that individual policies of MAPPG can converge to the global optimum. Empirically, we evaluate MAPPG on the well-known matrix game and differential game, and verify that MAPPG can converge to the global optimum for both discrete and continuous action spaces. We also evaluate MAPPG on a set of StarCraft II micromanagement tasks and demonstrate that MAPPG outperforms the state-of-the-art MAPG algorithms.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Zero-Shot Assistance in Sequential Decision Problems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26365), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26365/26137), [keywords](MAS: Multiagent Learning, ML: Imitation Learning & Inverse Reinforcement Learning, HAI: Human-in-the-Loop Machine Learning, ML: Bayesian Learning), [abstract](Abstract
We consider the problem of creating assistants that can help agents solve new sequential decision problems, assuming the agent is not able to specify the reward function explicitly to the assistant. Instead of acting in place of the agent as in current automation-based approaches, we give the assistant an advisory role and keep the agent in the loop as the main decision maker. The difficulty is that we must account for potential biases of the agent which may cause it to seemingly irrationally reject advice. To do this we introduce a novel formalization of assistance that models these biases, allowing the assistant to infer and adapt to them. We then introduce a new method for planning the assistant's actions which can scale to large decision making problems. We show experimentally that our approach adapts to these agent biases, and results in higher cumulative reward for the agent than automation-based alternatives. Lastly, we show that an approach combining advice and automation outperforms advice alone at the cost of losing some safety guarantees.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Multi-Unit Auctions for Allocating Chance-Constrained Resources | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26366), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26366/26138), [keywords](MAS: Multiagent Planning, MAS: Multiagent Systems Under Uncertainty, GTEP: Auctions and Market-Based Systems, PRS: Planning Under Uncertainty, PRS: Planning With Markov Models (MDPs, POMDPs)), [abstract](Abstract
Sharing scarce resources is a key challenge in multi-agent interaction, especially when individual agents are uncertain about their future consumption.  We present a new auction mechanism for preallocating multi-unit resources among agents, while limiting the chance of resource violations. By planning for a chance constraint, we strike a balance between worst-case approaches, which under-utilise resources, and expected-case approaches, which lack formal guarantees. We also present an algorithm that allows agents to generate bids via multi-objective reasoning, which are then submitted to the auction. We then discuss how the auction can be extended to non-cooperative scenarios. Finally, we demonstrate empirically that our auction outperforms state-of-the-art  techniques for chance-constrained multi-agent resource allocation in complex settings with up to hundreds of agents.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Reward-Based Negotiating Agent Strategies | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26367), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26367/26139), [keywords](MAS: Agreement, Argumentation & Negotiation, GTEP: Negotiation and Contract-Based Systems, ML: Applications, ML: Reinforcement Learning Algorithms, MAS: Agent/AI Theories and Architectures, MAS: Coordination and Collaboration), [abstract](Abstract
This study proposed a novel reward-based negotiating agent strategy using an issue-based represented deep policy network. We compared the negotiation strategies with reinforcement learning (RL) by the tournaments toward heuristics-based champion agents in multi-issue negotiation. A bilateral multi-issue negotiation in which the two agents exchange offers in turn was considered. Existing RL architectures for a negotiation strategy incorporate rich utility function that provides concrete information even though the rewards of RL are considered as generalized signals in practice. Additionally, in existing reinforcement learning architectures for negotiation strategies, both the issue-based representations of the negotiation problems and the policy network to improve the scalability of negotiation domains are yet to be considered. This study proposed a novel reward-based negotiation strategy through deep RL by considering an issue-based represented deep policy network for multi-issue negotiation. Comparative studies analyzed the significant properties of negotiation strategies with RL. The results revealed that the policy-based learning agents with issue-based representations achieved comparable or higher utility than the state-of-the-art baselines with RL and heuristics, especially in the large-sized domains. Additionally, negotiation strategies with RL based on the policy network can achieve agreements by effectively using each step.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Intersection Coordination with Priority-Based Search for Autonomous Vehicles | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26368), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26368/26140), [keywords](MAS: Multiagent Planning, APP: Transportation, ROB: Motion and Path Planning, ROB: Multi-Robot Systems, MAS: Applications, SO: Heuristic Search), [abstract](Abstract
The development of connected and autonomous vehicles opens an opportunity to manage intersections without signals. One promising approach is to use a central autonomous intersection manager to optimize the movement of the vehicles in the intersection. Existing work uses Mixed Integer Linear Programming (MILP) to find optimal solutions for this problem but is time-consuming and cannot be applied in real-time. On the other hand, the coordination of the vehicles is essentially a Multi-Agent Path Finding (MAPF) problem, for which dozens of efficient algorithms have been proposed in recent years. Inspired by these MAPF algorithms, we propose a three-level algorithm called PSL to solve the intersection coordination problem. Theoretically, PSL is complete and polynomial-time in the number of vehicles. Empirically, PSL runs significantly faster with only a slight compromise in the solution quality than the optimal MILP method. It also generates significantly better solutions with a slightly larger runtime than the traditional First-Come-First-Served strategy.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Solving Large-Scale Pursuit-Evasion Games Using Pre-trained Strategies | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26369), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26369/26141), [keywords](MAS: Multiagent Learning, APP: Energy, Environment & Sustainability, APP: Security, ML: Representation Learning), [abstract](Abstract
Pursuit-evasion games on graphs model the coordination of police forces chasing a fleeing felon in real-world urban settings, using the standard framework of imperfect-information extensive-form games (EFGs). In recent years, solving EFGs has been largely dominated by the Policy-Space Response Oracle (PSRO) methods due to their modularity, scalability, and favorable convergence properties. However, even these methods quickly reach their limits when facing large combinatorial strategy spaces of the pursuit-evasion games. To improve their efficiency, we integrate the pre-training and fine-tuning paradigm into the core module of PSRO -- the repeated computation of the best response. First, we pre-train the pursuer's policy base model against many different strategies of the evader. Then we proceed with the PSRO loop and fine-tune the pre-trained policy to attain the pursuer's best responses. The empirical evaluation shows that our approach significantly outperforms the baselines in terms of speed and scalability, and can solve even games on street maps of megalopolises with tens of thousands of crossroads -- a scale beyond the effective reach of previous methods.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26370), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26370/26142), [keywords](MAS: Multiagent Learning, ML: Reinforcement Learning Algorithms, MAS: Agent-Based Simulation and Emergent Behavior, MAS: Coordination and Collaboration), [abstract](Abstract
Value Decomposition (VD) aims to deduce the contributions of agents for decentralized policies in the presence of only global rewards, and has recently emerged as a powerful credit assignment paradigm for tackling cooperative Multi-Agent Reinforcement Learning (MARL) problems. One of the main challenges in VD is to promote diverse behaviors among agents, while existing methods directly encourage the diversity of learned agent networks with various strategies. However, we argue that these dedicated designs for agent networks are still limited by the indistinguishable VD network, leading to homogeneous agent behaviors and thus downgrading the cooperation capability. In this paper, we propose a novel Contrastive Identity-Aware learning (CIA) method, explicitly boosting the credit-level distinguishability of the VD network to break the bottleneck of multi-agent diversity. Specifically, our approach leverages contrastive learning to maximize the mutual information between the temporal credits and identity representations of different agents, encouraging the full expressiveness of credit assignment and further the emergence of individualities. The algorithm implementation of the proposed CIA module is simple yet effective that can be readily incorporated into various VD architectures. Experiments on the SMAC benchmarks and across different VD backbones demonstrate that the proposed method yields results superior to the state-of-the-art counterparts. Our code is available at https://github.com/liushunyu/CIA.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Learning to Shape Rewards Using a Game of Two Partners | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26371), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26371/26143), [keywords](MAS: Multiagent Learning, MAS: Coordination and Collaboration, MAS: Distributed Problem Solving), [abstract](Abstract
Reward shaping (RS) is a powerful method in reinforcement learning (RL) for overcoming the problem of sparse or uninformative rewards. However, RS typically relies on manually engineered shaping-reward functions whose construc- tion is time-consuming and error-prone. It also requires domain knowledge which runs contrary to the goal of autonomous learning. We introduce Reinforcement Learning Optimising Shaping Algorithm (ROSA), an automated reward shaping framework in which the shaping-reward function is constructed in a Markov game between two agents. A reward-shaping agent (Shaper) uses switching controls to determine which states to add shaping rewards for more efficient learning while the other agent (Controller) learns the optimal policy for the task using these shaped rewards. We prove that ROSA, which adopts existing RL algorithms, learns to construct a shaping-reward function that is beneficial to the task thus ensuring efficient convergence to high performance policies. We demonstrate ROSA’s properties in three didactic experiments and show its superior performance against state-of-the-art RS algorithms in challenging sparse reward environments.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Reconstructing an Epidemic Outbreak Using Steiner Connectivity | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26372), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26372/26144), [keywords](MAS: Agent-Based Simulation and Emergent Behavior, DMKM: Graph Mining, Social Network Analysis & Community Mining), [abstract](Abstract
Only a subset of infections is actually observed in an outbreak, due to multiple reasons such as asymptomatic cases and under-reporting. Therefore, reconstructing an epidemic cascade given some observed cases is an important step in responding to such an outbreak. A maximum likelihood solution to this problem ( referred to as CascadeMLE ) can be shown to be a variation of the classical Steiner subgraph problem, which connects a subset of observed infections. In contrast to prior works on epidemic reconstruction, which consider the standard Steiner tree objective, we show that a solution to CascadeMLE, based on the actual MLE objective, has a very different structure. We design a logarithmic approximation algorithm for CascadeMLE, and evaluate it on multiple synthetic and social contact networks, including a contact network constructed for a hospital. Our algorithm has significantly better performance compared to a prior baseline.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Formal Verification of Bayesian Mechanisms | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26373), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26373/26145), [keywords](MAS: Multiagent Systems Under Uncertainty, KRR: Applications, MAS: Mechanism Design), [abstract](Abstract
In this paper, for the first time, we study the formal verification of Bayesian mechanisms through strategic reasoning. We rely on the framework of Probabilistic Strategy Logic (PSL), which is well-suited for representing and verifying multi-agent systems with incomplete information. We take advantage of the recent results on the decidability of PSL model checking under memoryless strategies, and reduce the problem of formally verifying Bayesian mechanisms to PSL model checking. We show how to encode Bayesian-Nash equilibrium and economical properties, and illustrate our approach with different kinds of mechanisms.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Memory-Augmented Theory of Mind Network | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26374), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26374/26146), [keywords](MAS: Modeling Other Agents, ML: Deep Neural Architectures, CMS: Memory Storage and Retrieval, CMS: Social Cognition and Interaction), [abstract](Abstract
Social reasoning necessitates the capacity of theory of mind (ToM), the ability to contextualise and attribute mental states to others without having access to their internal cognitive structure. Recent machine learning approaches to ToM have demonstrated that we can train the observer to read the past and present behaviours of other agents and infer their beliefs (including false beliefs about things that no longer exist), goals, intentions and future actions. The challenges arise when the behavioural space is complex, demanding skilful space navigation for rapidly changing contexts for an extended period. We tackle the challenges by equipping the observer with novel neural memory mechanisms to encode, and hierarchical attention to selectively retrieve information about others. The memories allow rapid, selective querying of distal related past behaviours of others to deliberatively reason about their current mental state, beliefs and future behaviours. This results in ToMMY, a theory of mind model that learns to reason while making little assumptions about the underlying mental processes. We also construct a new suite of experiments to demonstrate that memories facilitate the learning process and achieve better theory of mind performance, especially for high-demand false-belief tasks that require inferring through multiple steps of changes.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Socially Optimal Non-discriminatory Restrictions for Continuous-Action Games | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26375), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26375/26147), [keywords](MAS: Mechanism Design, ML: Bias and Fairness, MAS: Adversarial Agents, MAS: Agent-Based Simulation and Emergent Behavior, MAS: Applications, MAS: Coordination and Collaboration, PEAI: Bias, Fairness & Equity), [abstract](Abstract
We address the following mechanism design problem: Given a multi-player Normal-Form Game (NFG) with a continuous action space, find a non-discriminatory (i.e., identical for all players) restriction of the action space which maximizes the resulting Nash Equilibrium with respect to a fixed social utility function. First, we propose a formal model of a Restricted Game and the corresponding restriction optimization problem. We then present an algorithm to find optimal non-discriminatory restrictions under some assumptions. Our experimental results with Braess' Paradox and the Cournot Game show that this method leads to an optimized social utility of the Nash Equilibria, even when the assumptions are not guaranteed to hold. Finally, we outline a generalization of our approach to the much wider scope of Stochastic Games.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Fault-Tolerant Offline Multi-Agent Path Planning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26376), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26376/26148), [keywords](MAS: Multiagent Planning, ROB: Motion and Path Planning, ROB: Multi-Robot Systems, MAS: Coordination and Collaboration, PRS: Plan Execution and Monitoring, SO: Heuristic Search), [abstract](Abstract
We study a novel graph path planning problem for multiple agents that may crash at runtime, and block part of the workspace. In our setting, agents can detect neighboring crashed agents, and change followed paths at runtime. The objective is then to prepare a set of paths and switching rules for each agent, ensuring that all correct agents reach their destinations without collisions or deadlocks, despite unforeseen crashes of other agents. Such planning is attractive to build reliable multi-robot systems. We present problem formalization, theoretical analysis such as computational complexities, and how to solve this offline planning problem.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
LaCAM- Search-Based Algorithm for Quick Multi-Agent Pathfinding | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26377), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26377/26149), [keywords](MAS: Multiagent Planning, ROB: Motion and Path Planning, ROB: Multi-Robot Systems, PRS: Deterministic Planning, SO: Heuristic Search), [abstract](Abstract
We propose a novel complete algorithm for multi-agent pathfinding (MAPF) called lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of finding collision-free paths for multiple agents on graphs and is the foundation of multi-robot coordination. LaCAM uses a two-level search to find solutions quickly, even with hundreds of agents or more. At the low-level, it searches constraints about agents' locations. At the high-level, it searches a sequence of all agents' locations, following the constraints specified by the low-level. Our exhaustive experiments reveal that LaCAM is comparable to or outperforms state-of-the-art sub-optimal MAPF algorithms in a variety of scenarios, regarding success rate, planning time, and solution quality of sum-of-costs.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Networked Anti-coordination Games Meet Graphical Dynamical Systems- Equilibria and Convergence | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26378), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26378/26150), [keywords](MAS: Agent/AI Theories and Architectures, MAS: Coordination and Collaboration, MAS: Other Foundations of Multiagent Systems), [abstract](Abstract
Evolutionary anti-coordination games on networks capture real-world strategic situations such as traffic routing and market competition. Two key problems concerning evolutionary games are the existence of a pure Nash equilibrium (NE) and the convergence time. In this work, we study these two problems for anti-coordination games under sequential and synchronous update schemes. For each update scheme, we examine two decision modes based on whether an agent considers its own previous action (self essential) or not (self non-essential) in choosing its next action. Using a relationship between games and dynamical systems, we show that for both update schemes, finding an NE can be done efficiently under the self non-essential mode but is computationally intractable under the self essential mode. We then identify special cases for which an NE can be obtained efficiently. For convergence time, we show that the dynamics converges in a polynomial number of steps under the synchronous scheme; for the sequential scheme, the convergence time is polynomial only under the self non-essential mode. Through experiments, we empirically examine the convergence time and the equilibria for both synthetic and real-world networks.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Learning from Good Trajectories in Offline Multi-Agent Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26379), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26379/26151), [keywords](MAS: Multiagent Learning, MAS: Coordination and Collaboration), [abstract](Abstract
Offline multi-agent reinforcement learning (MARL) aims to learn effective multi-agent policies from pre-collected datasets, which is an important step toward the deployment of multi-agent systems in real-world applications. However, in practice, each individual behavior policy that generates multi-agent joint trajectories usually has a different level of how well it performs. e.g., an agent is a random policy while other agents are medium policies. In the cooperative game with global reward, one agent learned by existing offline MARL often inherits this random policy, jeopardizing the utility of the entire team. In this paper, we investigate offline MARL with explicit consideration on the diversity of agent-wise trajectories and propose a novel framework called Shared Individual Trajectories (SIT) to address this problem. Specifically, an attention-based reward decomposition network assigns the credit to each agent through a differentiable key-value memory mechanism in an offline manner. These decomposed credits are then used to reconstruct the joint offline datasets into prioritized experience replay with individual trajectories, thereafter agents can share their good trajectories and conservatively train their policies with a graph attention network (GAT) based critic. We evaluate our method in both discrete control (i.e., StarCraft II and multi-agent particle environment) and continuous control (i.e., multi-agent mujoco). The results indicate that our method achieves significantly better results in complex and mixed offline multi-agent datasets, especially when the difference of data quality between individual trajectories is large.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Resource Sharing through Multi-Round Matchings | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26380), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26380/26152), [keywords](MAS: Other Foundations of Multiagent Systems, MAS: Coordination and Collaboration), [abstract](Abstract
Applications such as employees sharing office spaces over a workweek
can be modeled as problems where agents are matched to resources
over multiple rounds. Agents' requirements limit the set of compatible
resources and the rounds in which they want to be matched.  Viewing such an
application as a multi-round matching problem on a bipartite compatibility
graph between agents and resources, we show that a  solution 
(i.e., a set of matchings, with one matching per round) can be found
efficiently if one exists.  To cope with situations where a solution does not exist, we consider two extensions. In
the first extension, a benefit function is defined for each agent and the
objective is to find a multi-round matching to maximize the total benefit.  For a
general class of benefit functions satisfying certain properties (including
diminishing returns), we show that this multi-round matching problem is
efficiently solvable.  This class includes utilitarian and Rawlsian welfare
functions.  
For another benefit function, we show that the maximization
problem is NP-hard.  
In the second extension, the objective is to generate advice to
each agent (i.e., a subset of requirements to be relaxed) subject to a
budget constraint so that the agent can be matched.
We show that this budget-constrained advice generation problem is NP-hard.
For this problem, we develop an integer linear programming formulation  as well
as a heuristic based on local search.
 We experimentally evaluate our algorithms on
synthetic networks and apply them to two real-world situations: shared
office spaces and matching courses to classrooms.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Effective Integration of Weighted Cost-to-Go and Conflict Heuristic within Suboptimal CBS | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26381), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26381/26153), [keywords](MAS: Multiagent Planning, ROB: Motion and Path Planning, ROB: Multi-Robot Systems, SO: Heuristic Search), [abstract](Abstract
Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF) solver that employs a low-level single agent planner and a high-level constraint tree to resolve conflicts. The vast majority of modern MAPF solvers focus on improving CBS by reducing the size of this tree through various strategies with few methods modifying the low level planner. Typically low level planners in existing CBS methods use an unweighted cost-to-go heuristic, with suboptimal CBS methods also using a conflict heuristic to help the high level search. In this paper, we show that, contrary to prevailing CBS beliefs, a weighted cost-to-go heuristic can be used effectively alongside the conflict heuristic in two possible variants. In particular, one of these variants can obtain large speedups, 2-100x, across several  scenarios and suboptimal CBS methods. Importantly, we discover that performance is related not to the weighted cost-to-go heuristic but rather to the relative conflict heuristic weight's ability to effectively balance low-level and high-level work. Additionally, to the best of our knowledge, we show the first theoretical relation of prioritized planning and bounded suboptimal CBS and demonstrate that our methods are their natural generalization.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
DM²- Decentralized Multi-Agent Reinforcement Learning via Distribution Matching | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26382), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26382/26154), [keywords](MAS: Coordination and Collaboration, MAS: Multiagent Learning, MAS: Distributed Problem Solving, ML: Reinforcement Learning Algorithms, ML: Imitation Learning & Inverse Reinforcement Learning), [abstract](Abstract
Current approaches to multi-agent cooperation rely heavily on centralized mechanisms or explicit communication protocols to ensure convergence. This paper studies the problem of distributed multi-agent learning without resorting to centralized components or explicit communication. It examines the use of distribution matching to facilitate the coordination of independent agents. In the proposed scheme, each agent independently minimizes the distribution mismatch to the corresponding component of a target visitation distribution. The theoretical  analysis shows that under certain conditions, each agent minimizing its individual  distribution mismatch allows the convergence to the joint policy that generated the target distribution. Further, if the target distribution is from a joint policy that optimizes a cooperative task, the optimal policy for a combination of this task reward and the distribution matching reward is the same joint policy. This insight is used to formulate a practical algorithm (DM^2), in which each individual agent matches a target distribution derived from concurrently sampled trajectories from a joint expert policy. Experimental validation on the StarCraft domain shows that combining (1) a task reward, and (2) a distribution matching reward for expert demonstrations for the same task, allows agents to outperform a naive distributed baseline. Additional experiments probe the conditions under which expert demonstrations need to be sampled to obtain the learning benefits.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Emergence of Punishment in Social Dilemma with Environmental Feedback | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26383), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26383/26155), [keywords](MAS: Agent-Based Simulation and Emergent Behavior, GTEP: Game Theory, MAS: Mechanism Design), [abstract](Abstract
Altruistic punishment (or punishment) has been extensively shown as an important mechanism for promoting cooperation in human societies. In AI, the emergence of punishment has received much recent interest. In this paper, we contribute with a novel evolutionary game theoretic model to study the impacts of environmental feedback. Whereas a population of agents plays public goods games, there exists a third-party population whose payoffs depend not only on whether to punish or not, but also on the state of the environment (e.g., how cooperative the agents in a social dilemma are). Focusing on one-shot public goods games, we show that environmental feedback, by itself, can lead to the emergence of punishment. We analyze the co-evolution of punishment and cooperation, and derive conditions for their co-presence, co-dominance and co-extinction. Moreover, we show that the system can exhibit bistability as well as cyclic dynamics. Our findings provide a new explanation for the emergence of punishment.  On the other hand, our results also alert the need for careful design of implementing punishment in multi-agent systems, as the resulting evolutionary dynamics can be somewhat complex.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Subspace-Aware Exploration for Sparse-Reward Multi-Agent Tasks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26384), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26384/26156), [keywords](MAS: Multiagent Learning, ML: Reinforcement Learning Algorithms), [abstract](Abstract
Exploration under sparse rewards is a key challenge for multi-agent reinforcement learning problems. One possible solution to this issue is to exploit inherent task structures for an acceleration of exploration. In this paper, we present a novel exploration approach, which encodes a special structural prior on the reward function into exploration, for sparse-reward multi-agent tasks. Specifically, a novel entropic exploration objective which encodes the structural prior is proposed to accelerate the discovery of rewards. By maximizing the lower bound of this objective, we then propose an algorithm with moderate computational cost, which can be applied to practical tasks. Under the sparse-reward setting, we show that the proposed algorithm significantly outperforms the state-of-the-art algorithms in the multiple-particle environment, the Google Research Football and StarCraft II micromanagement tasks. To the best of our knowledge, on some hard tasks (such as 27m_vs_30m}) which have relatively larger number of agents and need non-trivial strategies to defeat enemies, our method is the first to learn winning strategies under the sparse-reward setting.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Consensus Learning for Cooperative Multi-Agent Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26385), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26385/26157), [keywords](MAS: Multiagent Learning), [abstract](Abstract
Almost all multi-agent reinforcement learning algorithms without communication follow the principle of centralized training with decentralized execution. During the centralized training, agents can be guided by the same signals, such as the global state. However, agents lack the shared signal and choose actions given local observations during execution. Inspired by viewpoint invariance and contrastive learning, we propose consensus learning for cooperative multi-agent reinforcement learning in this study. Although based on local observations, different agents can infer the same consensus in discrete spaces without communication. We feed the inferred one-hot consensus to the network of agents as an explicit input in a decentralized way, thereby fostering their cooperative spirit. With minor model modifications, our suggested framework can be extended to a variety of multi-agent reinforcement learning algorithms. Moreover, we carry out these variants on some fully cooperative tasks and get convincing results.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
HAVEN- Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26386), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26386/26158), [keywords](MAS: Multiagent Learning), [abstract](Abstract
Recently, some challenging tasks in multi-agent systems have been solved by some hierarchical reinforcement learning methods. Inspired by the intra-level and inter-level coordination in the human nervous system, we propose a novel value decomposition framework HAVEN based on hierarchical reinforcement learning for fully cooperative multi-agent problems. To address the instability arising from the concurrent optimization of policies between various levels and agents, we introduce the dual coordination mechanism of inter-level and inter-agent strategies by designing reward functions in a two-level hierarchy. HAVEN does not require domain knowledge and pre-training, and can be applied to any value decomposition variant. Our method achieves desirable results on different decentralized partially observable Markov decision process domains and outperforms other popular multi-agent hierarchical reinforcement learning algorithms.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Hierarchical Mean-Field Deep Reinforcement Learning for Large-Scale Multiagent Systems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26387), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26387/26159), [keywords](MAS: Multiagent Learning, ML: Reinforcement Learning Algorithms), [abstract](Abstract
Learning for efficient coordination in large-scale multiagent systems suffers from the problem of the curse of dimensionality due to the exponential growth of agent interactions. Mean-Field (MF)-based methods address this issue by transforming the interactions within the whole system into a single agent played with the average effect of its neighbors. However, considering the neighbors merely by their average may ignore the varying influences of each neighbor, and learning with this kind of local average effect would likely lead to inferior system performance due to lack of an efficient coordination mechanism in the whole population level. In this work, we propose a Hierarchical Mean-Field (HMF) learning framework to further improve the performance of existing MF methods. The basic idea is to approximate the average effect for a sub-group of agents by considering their different influences within the sub-group, and realize population-level coordination through the interactions among different sub-groups. Empirical studies show that HMF significantly outperforms existing baselines on both challenging cooperative and mixed cooperative-competitive tasks with different scales of agent populations.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26388), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26388/26160), [keywords](MAS: Coordination and Collaboration, MAS: Adversarial Agents, MAS: Agent-Based Simulation and Emergent Behavior, MAS: Agreement, Argumentation & Negotiation, MAS: Mechanism Design, MAS: Multiagent Learning, MAS: Multiagent Planning, MAS: Multiagent Systems Under Uncertainty), [abstract](Abstract
Cooperative Multi-agent Reinforcement Learning (CMARL) has shown to be promising for many real-world applications. Previous works mainly focus on improving coordination ability via solving MARL-specific challenges (e.g., non-stationarity, credit assignment, scalability), but ignore the policy perturbation issue when testing in a different environment. This issue hasn't been considered in problem formulation or efficient algorithm design. To address this issue, we firstly model the problem as a Limited Policy Adversary Dec-POMDP (LPA-Dec-POMDP), where some coordinators from a team might accidentally and unpredictably encounter a limited number of malicious action attacks, but the regular coordinators still strive for the intended goal. Then, we propose Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers (ROMANCE), which enables the trained policy to encounter diversified and strong auxiliary adversarial attacks during training, thus achieving high robustness under various 
policy perturbations. Concretely, to avoid the ego-system overfitting to a specific attacker, we maintain a set of attackers, which is optimized to guarantee the attackers high attacking quality and behavior diversity. The goal of quality is to minimize the ego-system coordination effect, and a novel diversity regularizer based on sparse action is applied to diversify the behaviors among attackers. The ego-system is then paired with a population of attackers selected from the maintained attacker set, and alternately trained against the constantly evolving attackers. Extensive experiments on multiple scenarios from SMAC indicate our ROMANCE provides comparable or better robustness and generalization ability than other baselines.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
DACOM- Learning Delay-Aware Communication for Multi-Agent Reinforcement Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26389), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26389/26161), [keywords](MAS: Agent Communication, ML: Reinforcement Learning Algorithms, ML: Reinforcement Learning Theory, MAS: Multiagent Learning), [abstract](Abstract
Communication is supposed to improve multi-agent collaboration and overall performance in cooperative Multi-agent reinforcement learning (MARL). However, such improvements are prevalently limited in practice since most existing communication schemes ignore communication overheads (e.g., communication delays). In this paper, we demonstrate that ignoring communication delays has detrimental effects on collaborations, especially in delay-sensitive tasks such as autonomous driving. To mitigate this impact, we design a delay-aware multi-agent communication model (DACOM) to adapt communication to delays. Specifically, DACOM introduces a component, TimeNet, that is responsible for adjusting the waiting time of an agent to receive messages from other agents such that the uncertainty associated with delay can be addressed. Our experiments reveal that DACOM has a non-negligible performance improvement over other mechanisms by making a better trade-off between the benefits of communication and the costs of waiting for messages.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26390), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26390/26162), [keywords](MAS: Multiagent Learning, ML: Reinforcement Learning Algorithms), [abstract](Abstract
Role-based learning is a promising approach to improving the performance of Multi-Agent Reinforcement Learning (MARL). Nevertheless, without manual assistance, current role-based methods cannot guarantee stably discovering a set of roles to effectively decompose a complex task, as they assume either a predefined role structure or practical experience for selecting hyperparameters. In this article, we propose a mathematical Structural Information principles-based Role Discovery method, namely SIRD, and then present a SIRD optimizing MARL framework, namely SR-MARL, for multi-agent collaboration. The SIRD transforms role discovery into a hierarchical action space clustering. Specifically, the SIRD consists of structuralization, sparsification, and optimization modules, where an optimal encoding tree is generated to perform abstracting to discover roles. The SIRD is agnostic to specific MARL algorithms and flexibly integrated with various value function factorization approaches. Empirical evaluations on the StarCraft II micromanagement benchmark demonstrate that, compared with state-of-the-art MARL algorithms, the SR-MARL framework improves the average test win rate by 0.17%, 6.08%, and 3.24%, and reduces the deviation by 16.67%, 30.80%, and 66.30%, under easy, hard, and super hard scenarios.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Learning to Play General-Sum Games against Multiple Boundedly Rational Agents | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26391), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26391/26163), [keywords](MAS: Multiagent Learning, MAS: Mechanism Design), [abstract](Abstract
We study the problem of training a principal in a multi-agent general-sum game using reinforcement learning (RL). Learning a robust principal policy requires anticipating the worst possible strategic responses of other agents, which is generally NP-hard. However, we show that no-regret dynamics can identify these worst-case responses in poly-time in smooth games. We propose a framework that uses this policy evaluation method for efficiently learning a robust principal policy using RL. This framework can be extended to provide robustness to boundedly rational agents too. Our motivating application is automated mechanism design: we empirically demonstrate our framework learns robust mechanisms in both matrix games and complex spatiotemporal games. In particular, we learn a dynamic tax policy that improves the welfare of a simulated trade-and-barter economy by 15%, even when facing previously unseen boundedly rational RL taxpayers.), [group](Technical Tracks 10: AAAI Technical Track on Multiagent Systems)
Towards Robust Metrics for Concept Representation Evaluation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26392), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26392/26164), [keywords](PEAI: Interpretability and Explainability, PEAI: Safety, Robustness & Trustworthiness, ML: Representation Learning, ML: Deep Generative Models & Autoencoders), [abstract](Abstract
Recent work on interpretability has focused on concept-based explanations, where deep learning models are explained in terms of high-level units of information, referred to as concepts. Concept learning models, however, have been shown to be prone to encoding impurities in their representations, failing to fully capture meaningful features of their inputs. While concept learning lacks metrics to measure such phenomena, the field of disentanglement learning has explored the related notion of underlying factors of variation in the data, with plenty of metrics to measure the purity of such factors. In this paper, we show that such metrics are not appropriate for concept learning and propose novel metrics for evaluating the purity of concept representations in both approaches. We show the advantage of these metrics over existing ones and demonstrate their utility in evaluating the robustness of concept representations and interventions performed on them. In addition, we show their utility for benchmarking state-of-the-art methods from both families and find that, contrary to common assumptions, supervision alone may not be sufficient for pure concept representations.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
On the Vulnerability of Backdoor Defenses for Federated Learning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26393), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26393/26165), [keywords](PEAI: Safety, Robustness & Trustworthiness, ML: Adversarial Learning & Robustness), [abstract](Abstract
Federated learning (FL) is a popular distributed machine learning paradigm which enables jointly training a global model without sharing clients' data. However, its repetitive server-client communication gives room for possible backdoor attacks which aims to mislead the global model into a targeted misprediction when a specific trigger pattern is presented. In response to such backdoor threats on federated learning, various defense measures have been proposed. In this paper, we study whether the current defense mechanisms truly neutralize the backdoor threats from federated learning in a practical setting by proposing a new federated backdoor attack framework for possible countermeasures. Different from traditional training (on triggered data) and rescaling (the malicious client model) based backdoor injection, the proposed backdoor attack framework (1) directly modifies (a small proportion of) local model weights to inject the backdoor trigger via sign flips; (2) jointly optimize the trigger pattern with the client model,  thus is more persistent and stealthy for circumventing existing defenses. In a case study, we examine the strength and weaknesses of several recent federated backdoor defenses from three major categories and provide suggestions to the practitioners when training federated models in practice.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Distributionally Robust Optimization with Probabilistic Group | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26394), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26394/26166), [keywords](PEAI: Safety, Robustness & Trustworthiness), [abstract](Abstract
Modern machine learning models may be susceptible to learning spurious correlations that hold on average but not for the atypical group of samples. To address the problem, previous approaches minimize the empirical worst-group risk. Despite the promise, they often assume that each sample belongs to one and only one group, which does not allow expressing the uncertainty in group labeling. In this paper, we propose a novel framework PG-DRO, which explores the idea of probabilistic group membership for distributionally robust optimization. Key to our framework, we consider soft group membership instead of hard group annotations. The group probabilities can be flexibly generated using either supervised learning or zero-shot approaches. Our framework accommodates samples with group membership ambiguity, offering stronger flexibility and generality than the prior art. We comprehensively evaluate PG-DRO on both image classification and natural language processing benchmarks, establishing superior performance.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Correct for Whom- Subjectivity and the Evaluation of Personalized Image Aesthetics Assessment Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26395), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26395/26167), [keywords](PEAI: Philosophical Foundations of AI, CV: Image and Video Retrieval, APP: Art/Music/Creativity, APP: Humanities & Computational Social Science, PEAI: Morality and Value-Based AI, PEAI: Societal Impact of AI), [abstract](Abstract
The problem of image aesthetic quality assessment is surprisingly difficult to define precisely. Most early work attempted to estimate the average aesthetic rating of a group of observers, while some recent work has shifted to an approach based on few-shot personalization. In this paper, we connect few-shot personalization, via Immanuel Kant's concept of disinterested judgment, to an argument from feminist aesthetics about the biased tendencies of objective standards for subjective pleasures. To empirically investigate this philosophical debate, we introduce PR-AADB, a relabeling of the existing AADB dataset with labels for pairs of images, and measure how well the existing groundtruth predicts our new pairwise labels. We find, consistent with the feminist critique, that both the existing groundtruth and few-shot personalized predictions represent some users' preferences significantly better than others, but that it is difficult to predict when and for whom the existing groundtruth will be correct. We thus advise against using benchmark datasets to evaluate models for personalized IAQA, and recommend caution when attempting to account for subjective difference using machine learning more generally.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Covariate-Shift Generalization via Random Sample Weighting | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26396), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26396/26168), [keywords](PEAI: Safety, Robustness & Trustworthiness, ML: Bias and Fairness), [abstract](Abstract
Shifts in the marginal distribution of covariates from training to the test phase, named covariate-shifts, often lead to unstable prediction performance across agnostic testing data, especially under model misspecification. Recent literature on invariant learning attempts to learn an invariant predictor from heterogeneous environments. However, the performance of the learned predictor depends heavily on the availability and quality of provided environments. In this paper, we propose a simple and effective non-parametric method for generating heterogeneous environments via Random Sample Weighting (RSW). Given the training dataset from a single source environment, we randomly generate a set of covariate-determining sample weights and use each weighted training distribution to simulate an environment. We theoretically show that under appropriate conditions, such random sample weighting can produce sufficient heterogeneity to be exploited by common invariance constraints to find the invariant variables for stable prediction under covariate shifts. Extensive experiments on both simulated and real-world datasets clearly validate the effectiveness of our method.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Fairness in Contextual Resource Allocation Systems- Metrics and Incompatibility Results | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26397), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26397/26169), [keywords](PEAI: Bias, Fairness & Equity, PEAI: Societal Impact of AI), [abstract](Abstract
We study critical systems that allocate scarce resources to satisfy basic needs, such as homeless services that provide housing. These systems often support communities disproportionately affected by systemic racial, gender, or other injustices, so it is crucial to design these systems with fairness considerations in mind. To address this problem, we propose a framework for evaluating fairness in contextual resource allocation systems that is inspired by fairness metrics in machine learning. This framework can be applied to evaluate the fairness properties of a historical policy, as well as to impose constraints in the design of new (counterfactual) allocation policies. Our work culminates with a set of incompatibility results that investigate the interplay between the different fairness metrics we propose. Notably, we demonstrate that: 1) fairness in allocation and fairness in outcomes are usually incompatible; 2) policies that prioritize based on a vulnerability score will usually result in unequal outcomes across groups, even if the score is perfectly calibrated; 3) policies using contextual information beyond what is needed to characterize baseline risk and treatment effects can be fairer in their outcomes than those using just baseline risk and treatment effects; and 4) policies using group status in addition to baseline risk and treatment effects are as fair as possible given all available information. Our framework can help guide the discussion among stakeholders in deciding which fairness metrics to impose when allocating scarce resources.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Improvement-Focused Causal Recourse (ICR) | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26398), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26398/26170), [keywords](PEAI: Interpretability and Explainability, ML: Causal Learning, PEAI: Philosophical Foundations of AI, RU: Causality, RU: Graphical Model), [abstract](Abstract
Algorithmic recourse recommendations inform stakeholders of how to act to revert unfavorable decisions. However, existing methods may recommend actions that lead to acceptance (i.e., revert the model's decision) but do not lead to improvement (i.e., may not revert the underlying real-world state). To recommend such actions is to recommend fooling the predictor. We introduce a novel method, Improvement-Focused Causal Recourse (ICR), which involves a conceptual shift: Firstly, we require ICR recommendations to guide toward improvement. Secondly, we do not tailor the recommendations to be accepted by a specific predictor.  Instead, we leverage causal knowledge to design decision systems that predict accurately pre- and post-recourse, such that improvement guarantees translate into acceptance guarantees. Curiously, optimal pre-recourse classifiers are robust to ICR actions and thus suitable post-recourse. In semi-synthetic experiments, we demonstrate that given correct causal knowledge ICR, in contrast to existing approaches, guides toward both acceptance and improvement.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Explaining Model Confidence Using Counterfactuals | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26399), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26399/26171), [keywords](PEAI: Interpretability and Explainability, HAI: Human-Computer Interaction), [abstract](Abstract
Displaying confidence scores in human-AI interaction has been shown to help build trust between humans and AI systems. However, most existing research uses only the confidence score as a form of communication. As confidence scores are just another model output, users may want to understand why the algorithm is confident to determine whether to accept the confidence score. In this paper, we show that counterfactual explanations of confidence scores help study participants to better understand and better trust a machine learning model's prediction. We present two methods for understanding model confidence using counterfactual explanation: (1) based on counterfactual examples; and (2) based on visualisation of the counterfactual space. Both increase understanding and trust for study participants over a baseline of no explanation, but qualitative results show that they are used quite differently, leading to recommendations of when to use each one and directions of designing better explanations.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Echo of Neighbors- Privacy Amplification for Personalized Private Federated Learning with Shuffle Model | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26400), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26400/26172), [keywords](PEAI: Privacy and Security, ML: Distributed Machine Learning & Federated Learning, ML: Privacy-Aware ML), [abstract](Abstract
Federated Learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. Different privacy levels regarding users' attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. Personalized Local Differential Privacy (PLDP) is suitable for preserving users' varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. Thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. In this work, a general framework (APES) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model.  To tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. The contributions are characterized by the ability of generating “echos” from the perturbation of each user,  which is carefully measured by proposed methods Neighbor Divergence and Clip-Laplace Mechanism. Furthermore, we propose a refined framework (S-APES) with the post-sparsification technique to reduce privacy loss in high-dimension scenarios. To the best of our knowledge, the impact of shuffling on personalized local privacy is considered for the first time. We provide a strong privacy amplification effect, and the bound is tighter than the baseline result based on existing methods for uniform local privacy. Experiments demonstrate that our frameworks ensure comparable or higher accuracy for the global model.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
XRand- Differentially Private Defense against Explanation-Guided Attacks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26401), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26401/26173), [keywords](PEAI: Privacy and Security, PEAI: Safety, Robustness & Trustworthiness), [abstract](Abstract
Recent development in the field of explainable artificial intelligence (XAI) has helped improve trust in Machine-Learning-as-a-Service (MLaaS) systems, in which an explanation is provided together with the model prediction in response to each query. However, XAI also opens a door for adversaries to gain insights into the black-box models in MLaaS, thereby making the models more vulnerable to several attacks. For example, feature-based explanations (e.g., SHAP) could expose the top important features that a black-box model focuses on. Such disclosure has been exploited to craft effective backdoor triggers against malware classifiers. To address this trade-off, we introduce a new concept of achieving local differential privacy (LDP) in the explanations, and from that we establish a defense, called XRand, against such attacks. We show that our mechanism restricts the information that the adversary can learn about the top important features, while maintaining the faithfulness of the explanations.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Mitigating Adversarial Norm Training with Moral Axioms | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26402), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26402/26174), [keywords](PEAI: Morality and Value-Based AI, ML: Adversarial Learning & Robustness, PEAI: Safety, Robustness & Trustworthiness, KRR: Reasoning with Beliefs, PEAI: AI and Epistemology, KRR: Belief Change, CMS: Social Cognition and Interaction, RU: Uncertainty Representations), [abstract](Abstract
This paper addresses the issue of adversarial attacks on ethical AI systems. We investigate using moral axioms and rules of deontic logic in a norm learning framework to mitigate adversarial norm training. This model of moral intuition and construction provides AI systems with moral guard rails yet still allows for learning conventions. We evaluate our approach by drawing inspiration from a study commonly used in moral development research. This questionnaire aims to test an agent's ability to reason to moral conclusions despite opposed testimony. Our findings suggest that our model can still correctly evaluate moral situations and learn conventions in an adversarial training environment. We conclude that adding axiomatic moral prohibitions and deontic inference rules to a norm learning model makes it less vulnerable to adversarial attacks.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Equity Promotion in Public Transportation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26403), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26403/26175), [keywords](PEAI: Bias, Fairness & Equity, APP: Transportation, PRS: Optimization of Spatio-Temporal Systems, PRS: Scheduling), [abstract](Abstract
There are many news articles reporting the obstacles confronting poverty-stricken households in access to public transits. These barriers create a great deal of inconveniences for these impoverished families and more importantly, they contribute a lot of social inequalities. A typical approach addressing the issue is to build more transport infrastructure to offer more opportunities to access the public transits especially for those deprived communities. Examples include adding more bus lines connecting needy residents to railways systems and extending existing bus lines to areas with low socioeconomic status. Recently, a new strategy is proposed, which is to harness the ubiquitous ride-hailing services to connect disadvantaged households with the nearest public transportations. Compared with the former infrastructure-based solution, the ride-hailing-based strategy enjoys a few exclusive benefits such as higher effectiveness and more flexibility.

In this paper, we propose an optimization model to study how to integrate the two approaches together for equity-promotion purposes. Specifically, we aim to design a strategy of allocating a given limited budget to different candidate programs such that the overall social equity is maximized, which is defined as the minimum covering ratio among all pre-specified protected groups of households (based on race, income, etc.). We have designed a linear-programming (LP) based rounding algorithm, which proves to achieve an optimal approximation ratio of 1-1/e. Additionally, we test our algorithm against a few baselines on real data assembled by outsourcing multiple public datasets collected in the city of Chicago. Experimental results confirm our theoretical predictions and demonstrate the effectiveness of our LP-based strategy in promoting social equity, especially when the budget is insufficient.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Online Platforms and the Fair Exposure Problem under Homophily | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26404), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26404/26176), [keywords](PEAI: Societal Impact of AI, PEAI: Bias, Fairness & Equity, GTEP: Applications, GTEP: Other Foundations of Game Theory & Economic Paradigms, MAS: Other Foundations of Multiagent Systems), [abstract](Abstract
In the wake of increasing political extremism, online platforms have been criticized for contributing to polarization. One line of criticism has focused on echo chambers and the recommended content served to users by these platforms. In this work, we introduce the fair exposure problem: given limited intervention power of the platform, the goal is to enforce balance in the spread of content (e.g., news articles) among two groups of users through constraints similar to those imposed by the Fairness Doctrine in the United States in the past. Groups are characterized by different affiliations (e.g., political views) and have different preferences for content. We develop a stylized framework that models intra- and inter-group content propagation under homophily, and we formulate the platform's decision as an optimization problem that aims at maximizing user engagement, potentially under fairness constraints. Our main notion of fairness requires that each group see a mixture of their preferred and non-preferred content, encouraging information diversity. Promoting such information diversity is often viewed as desirable and a potential means for breaking out of harmful echo chambers. We study the solutions to both the fairness-agnostic and fairness-aware problems. We prove that a fairness-agnostic approach inevitably leads to group-homogeneous targeting  by the platform. This is only partially mitigated by imposing fairness constraints: we show that there exist optimal fairness-aware solutions which target one group with different types of content and the other group with only one type that is not necessarily the group's most preferred. Finally, using simulations with real-world data, we study the system dynamics and quantify the price of fairness.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Minimax AUC Fairness- Efficient Algorithm with Provable Convergence | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26405), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26405/26177), [keywords](PEAI: Bias, Fairness & Equity, ML: Optimization), [abstract](Abstract
The use of machine learning models in consequential decision making often exacerbates societal inequity, in particular yielding disparate impact on members of marginalized groups defined by race and gender. The area under the ROC curve (AUC) is widely used to evaluate the performance of a scoring function in machine learning, but is studied in algorithmic fairness less than other performance metrics. Due to the pairwise nature of the AUC, defining an AUC-based group fairness metric is pairwise-dependent and may involve both intra-group and inter-group AUCs. Importantly, considering only one category of AUCs is not sufficient to mitigate unfairness in AUC optimization. In this paper, we propose a minimax learning and bias mitigation framework that incorporates both intra-group and inter-group AUCs while maintaining utility. Based on this Rawlsian framework, we design an efficient stochastic optimization algorithm and prove its convergence to the minimum group-level AUC. We conduct numerical experiments on both synthetic and real-world datasets to validate the effectiveness of the minimax framework and the proposed optimization algorithm.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Faster Fair Machine via Transferring Fairness Constraints to Virtual Samples | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26406), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26406/26178), [keywords](PEAI: Bias, Fairness & Equity), [abstract](Abstract
Fair classification is an emerging and important research topic in machine learning community. Existing methods usually formulate the fairness metrics as additional inequality constraints, and then embed them into the original objective. This makes fair classification problems unable to be effectively tackled by some solvers specific to unconstrained optimization. Although many new tailored algorithms have been designed to attempt to overcome this limitation, they often increase additional computation burden and cannot cope with all types of fairness metrics. To address these challenging issues, in this paper, we propose a novel method for fair classification. 
Specifically, we theoretically
demonstrate that all types of fairness with linear and non-linear covariance functions can be transferred to two virtual samples, which makes the existing state-of-the-art classification solvers be applicable to these cases. Meanwhile, we  generalize the proposed method to multiple fairness constraints. We take SVM as an example to show the effectiveness of our new idea. 
Empirically, we test the proposed method on real-world datasets and all results confirm its excellent performance.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Learning Control Policies for Stochastic Systems with Reach-Avoid Guarantees | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26407), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26407/26179), [keywords](PEAI: Safety, Robustness & Trustworthiness, ML: Adversarial Learning & Robustness, ML: Calibration & Uncertainty Quantification, ML: Probabilistic Methods, RU: Other Foundations of Reasoning Under Uncertainty), [abstract](Abstract
We study the problem of learning controllers for discrete-time non-linear stochastic dynamical systems with formal reach-avoid guarantees. This work presents the first method for providing formal reach-avoid guarantees, which combine and generalize stability and safety guarantees, with a tolerable probability threshold p in [0,1] over the infinite time horizon. Our method leverages advances in machine learning literature and it represents formal certificates as neural networks. In particular, we learn a certificate in the form of a reach-avoid supermartingale (RASM), a novel notion that we introduce in this work. Our RASMs provide reachability and avoidance guarantees by imposing constraints on what can be viewed as a stochastic extension of level sets of Lyapunov functions for deterministic systems. Our approach solves several important problems -- it can be used to learn a control policy from scratch, to verify a reach-avoid specification for a fixed control policy, or to fine-tune a pre-trained policy if it does not satisfy the reach-avoid specification. We validate our approach on 3 stochastic non-linear reinforcement learning tasks.), [group](Technical Tracks 10: AAAI Technical Track on Philosophy and Ethics of AI)
Robust Neuro-Symbolic Goal and Plan Recognition | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26408), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26408/26180), [keywords](PRS: Activity and Plan Recognition, ML: Applications), [abstract](Abstract
Goal Recognition is the task of discerning the intended goal of an agent given a sequence of observations, whereas Plan Recognition consists of identifying the plan to achieve such intended goal. Regardless of the underlying techniques, most recognition approaches are directly affected by the quality of the available observations. In this paper, we develop neuro-symbolic recognition approaches that can combine learning and planning techniques, compensating for noise and missing observations using prior data. We evaluate our approaches in standard human-designed planning domains as well as domain models automatically learned from real-world data. Empirical experimentation shows that our approaches reliably infer goals and compute correct plans in the experimental datasets. An ablation study shows that outperform approaches that rely exclusively on the domain model, or exclusively on machine learning in problems with both noisy observations and low observability.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Heuristic Search for Multi-Objective Probabilistic Planning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26409), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26409/26181), [keywords](PRS: Planning Under Uncertainty, PRS: Planning With Markov Models (MDPs, POMDPs)), [abstract](Abstract
Heuristic search is a powerful approach that has successfully been applied to a broad class of planning problems, including classical planning, multi-objective planning, and probabilistic planning modelled as a stochastic shortest path (SSP) problem. Here, we extend the reach of heuristic search to a more expressive class of problems, namely multi-objective stochastic shortest paths (MOSSPs), which require computing a coverage set of non-dominated policies. We design new heuristic search algorithms MOLAO* and MOLRTDP, which extend well-known SSP algorithms to the multi-objective case. We further construct a spectrum of domain-independent heuristic functions differing in their ability to take into account the stochastic and multi-objective features of the problem to guide the search. Our experiments demonstrate the benefits of these algorithms and the relative merits of the heuristics.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Zero-Knowledge Proofs for Classical Planning Problems | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26410), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26410/26182), [keywords](PRS: Other Foundations of Planning, Routing & Scheduling, PRS: Deterministic Planning), [abstract](Abstract
In classical planning, the aim is to find a sequence of deterministic actions leading from the initial to a goal state. In this work, we consider the scenario where a party who knows the solution to a planning task, called the prover, wants to convince a second party, the verifier, that it has the solution without revealing any information about the solution itself. This is relevant in domains where privacy is important, for example when plans contain sensitive information or when the solution should not be revealed upfront.  We achieve this by introducing a zero-knowledge protocol for plan existence. By restricting ourselves to tasks with polynomially-bounded plan length, we are able to construct a protocol that can be run efficiently by both the prover and verifier. The resulting protocol does not rely on any reduction, has a constant number of rounds, and runs in time polynomial in the size of the task.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Planning with Hidden Parameter Polynomial MDPs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26411), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26411/26183), [keywords](PRS: Planning With Markov Models (MDPs, POMDPs), PRS: Model-Based Reasoning, PRS: Planning Under Uncertainty, RU: Sequential Decision Making, RU: Stochastic Models & Probabilistic Inference), [abstract](Abstract
For many applications of Markov Decision Processes (MDPs), the transition function cannot be specified exactly. Bayes-Adaptive MDPs (BAMDPs) extend MDPs to consider transition probabilities governed by latent parameters. To act optimally in BAMDPs, one must maintain a belief distribution over the latent parameters. Typically, this distribution is described by a set of sample (particle) MDPs, and associated weights which represent the likelihood of a sample MDP being the true underlying MDP. However, as the number of dimensions of the latent parameter space increases, the number of sample MDPs required to sufficiently represent the belief distribution grows exponentially. Thus, maintaining an accurate belief in the form of a set of sample MDPs over complex latent spaces is computationally intensive, which in turn affects the performance of planning for these models. In this paper, we propose an alternative approach for maintaining the belief over the latent parameters. We consider a class of BAMDPs where the transition probabilities can be expressed in closed form as a polynomial of the latent parameters, and outline a method to maintain a closed-form belief distribution for the latent parameters which results in an accurate belief representation. Furthermore, the closed-form representation does away with the need to tune the number of sample MDPs required to represent the belief. We evaluate two domains and empirically show that the polynomial, closed-form, belief representation results in better plans than a sampling-based belief representation.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Privacy Attacks on Schedule-Driven Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26412), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26412/26184), [keywords](PRS: Scheduling, PRS: Applications, PRS: Planning/Scheduling and Learning), [abstract](Abstract
Schedules define how resources process jobs in diverse domains, reaching from healthcare to transportation, and, therefore, denote a valuable starting point for analysis of the underlying system. However, publishing a schedule may disclose private information on the considered jobs. In this paper, we provide a first threat model for published schedules, thereby defining a completely new class of data privacy problems. We then propose distance-based measures to assess the privacy loss incurred by a published schedule, and show their theoretical properties for an uninformed adversary, which can be used as a benchmark for informed attacks. We show how an informed attack on a published schedule can be phrased as an inverse scheduling problem. We instantiate this idea by formulating the inverse of a well-studied single-machine scheduling problem, namely minimizing the total weighted completion times. An empirical evaluation for synthetic scheduling problems shows the effectiveness of informed privacy attacks and compares the results to theoretical bounds on uninformed attacks.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Markov Decision Processes with Time-Varying Geometric Discounting | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26413), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26413/26185), [keywords](PRS: Planning With Markov Models (MDPs, POMDPs), GTEP: Game Theory, RU: Sequential Decision Making), [abstract](Abstract
Canonical models of Markov decision processes (MDPs) usually consider geometric discounting based on a constant discount factor. While this standard modeling approach has led to many elegant results, some recent studies indicate the necessity of modeling time-varying discounting in certain applications. This paper studies a model of infinite-horizon MDPs with time-varying discount factors. We take a game-theoretic perspective – whereby each time step is treated as an independent decision maker with their own (fixed) discount factor – and we study the subgame perfect equilibrium (SPE) of the resulting game as well as the related algorithmic problems. We present a constructive proof of the existence of an SPE and demonstrate the EXPTIME-hardness of computing an SPE. We also turn to the approximate notion of epsilon-SPE and show that an epsilon-SPE exists under milder assumptions. An algorithm is presented to compute an epsilon-SPE, of which an upper bound of the time complexity, as a function of the convergence property of the time-varying discount factor, is provided.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Learning-Augmented Algorithms for Online TSP on the Line | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26414), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26414/26186), [keywords](PRS: Routing, PRS: Optimization of Spatio-Temporal Systems, PRS: Planning Under Uncertainty, PRS: Temporal Planning, RU: Sequential Decision Making), [abstract](Abstract
We study the online Traveling Salesman Problem (TSP) on the line augmented with machine-learned predictions. In the classical problem, there is a stream of requests released over time along the real line. The goal is to minimize the makespan of the algorithm. We distinguish between the open variant and the closed one, in which we additionally require the algorithm to return to the origin after serving all requests. The state of the art is a 1.64-competitive algorithm and a 2.04-competitive algorithm for the closed and open variants, respectively. In both cases, a tight lower bound is known.

In both variants, our primary prediction model involves predicted positions of the requests. We introduce algorithms that (i) obtain a tight 1.5 competitive ratio for the closed variant and a 1.66 competitive ratio for the open variant in the case of perfect predictions, (ii) are robust against unbounded prediction error, and (iii) are smooth, i.e., their performance degrades gracefully as the prediction error increases.

Moreover, we further investigate the learning-augmented setting in the open variant by additionally considering a prediction for the last request served by the optimal offline algorithm. Our algorithm for this enhanced setting obtains a 1.33 competitive ratio with perfect predictions while also being smooth and robust, beating the lower bound of 1.44 we show for our original prediction setting for the open variant. Also, we provide a lower bound of 1.25 for this enhanced setting.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Networked Restless Bandits with Positive Externalities | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26415), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26415/26187), [keywords](PRS: Planning With Markov Models (MDPs, POMDPs), PRS: Planning Under Uncertainty), [abstract](Abstract
Restless multi-armed bandits are often used to model budget-constrained resource allocation tasks where receipt of the resource is associated with an increased probability of a favorable state transition. Prior work assumes that individual arms only benefit if they receive the resource directly. However, many allocation tasks occur within communities and can be characterized by positive externalities that allow arms to derive partial benefit when their neighbor(s) receive the resource. We thus introduce networked restless bandits, a novel multi-armed bandit setting in which arms are both restless and embedded within a directed graph. We then present Greta, a graph-aware, Whittle index-based heuristic algorithm that can be used to efficiently construct a constrained reward-maximizing action vector at each timestep. Our empirical results demonstrate that Greta outperforms comparison policies across a range of hyperparameter values and graph topologies. Code and appendices are available at https://github.com/crherlihy/networked_restless_bandits.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Planning for Learning Object Properties | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26416), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26416/26188), [keywords](PRS: Planning/Scheduling and Learning, ROB: Cognitive Robotics, KRR: Knowledge Acquisition, PRS: Applications), [abstract](Abstract
Autonomous agents embedded in a physical environment need the ability to recognize objects and their properties from sensory data. Such a perceptual ability is often implemented by supervised machine learning models, which are pre-trained using a set of labelled data. In real-world, open-ended deployments, however, it is unrealistic to assume to have a pre-trained model for all possible environments. Therefore, agents need to dynamically learn/adapt/extend their perceptual abilities online, in an autonomous way, by exploring and interacting with the environment where they operate. This paper describes a way to do so, by exploiting symbolic planning. Specifically, we formalize the problem of automatically training a neural network to recognize object properties as a symbolic planning problem (using PDDL). We use planning techniques to produce a strategy for automating the training dataset creation and the learning process. Finally, we provide an experimental evaluation in both a simulated and a real environment, which shows that the proposed approach is able to successfully learn how to recognize new object properties.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Fully Online Matching with Stochastic Arrivals and Departures | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26417), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26417/26189), [keywords](PRS: Applications, CSO: Applications, ML: Applications, ML: Online Learning & Bandits, ML: Optimization, PRS: Planning Under Uncertainty, PRS: Planning/Scheduling and Learning, PRS: Scheduling), [abstract](Abstract
We study a fully online matching problem with stochastic arrivals and departures. In this model, each online arrival follows a known identical and independent distribution over a fixed set of agent types. Its sojourn time is unknown in advance and follows type-specific distributions with known expectations. The goal is to maximize the weighted reward from successful matches. To solve this problem, we first propose a linear program (LP)-based algorithm whose competitive ratio is lower bounded by 0.155 under mild conditions. We further achieve better ratios in some special cases. To demonstrate the challenges of the problem, we further establish several hardness results. In particular, we show that no online algorithm can achieve a competitive ratio better than 2/3 in this model and there is no LP-based algorithm (with respect to our proposed LP) with a competitive ratio better than 1/3. Finally, we demonstrate the effectiveness and efficiency of our algorithm numerically.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Towards Automated Modeling Assistance- An Efficient Approach for Repairing Flawed Planning Domains | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26418), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26418/26190), [keywords](PRS: Deterministic Planning, HAI: Human-Computer Interaction, PRS: Planning/Scheduling and Learning), [abstract](Abstract
Designing a planning domain is a difficult task in AI planning. Assisting tools are thus required if we want planning to be used more broadly. In this paper, we are interested in automatically correcting a flawed domain. In particular, we are concerned with the scenario where a domain contradicts a plan that is known to be valid. Our goal is to repair the domain so as to turn the plan into a solution. Specifically, we consider both grounded and lifted representations support for negative preconditions and show how to explore the space of repairs to find the optimal one efficiently. As an evidence of the efficiency of our approach, the experiment results show that all flawed domains except one in the benchmark set can be repaired optimally by our approach within one second.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Was Fixing This Really That Hard- On the Complexity of Correcting HTN Domains | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26419), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26419/26191), [keywords](PRS: Deterministic Planning, HAI: Human-Computer Interaction, PRS: Other Foundations of Planning, Routing & Scheduling), [abstract](Abstract
Automated modeling assistance is indispensable to the AI planning being deployed in practice, notably in industry and other non-academic contexts. Yet, little progress has been made that goes beyond smart interfaces like programming environments. They focus on autocompletion, but lack intelligent support for guiding the modeler. As a theoretical foundation of a first step towards this direction, we study the computational complexity of correcting a flawed Hierarchical Task Network (HTN) planning domain. Specifically, a modeler provides a (white) list of plans that are supposed to be solutions, and likewise a (black) list of plans that shall not be solutions. We investigate the complexity of finding a set of (optimal or suboptimal) model corrections so that those plans are (resp. not) solutions to the corrected model. More specifically, we factor out each hardness source that contributes towards NP-hardness, including one that we deem important for many other complexity investigations that go beyond our specific context of application. All complexities range between NP and Sigma-2-p, rising the hope for efficient practical tools in the future.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
On Total-Order HTN Plan Verification with Method Preconditions – An Extension of the CYK Parsing Algorithm | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26420), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26420/26192), [keywords](PRS: Deterministic Planning), [abstract](Abstract
In this paper, we consider the plan verification problem for totally ordered (TO) HTN planning. The problem is proved to be solvable in polynomial time by recognizing its connection to the membership decision problem for context-free grammars. Currently, most HTN plan verification approaches do not have special treatments for the TO configuration, and the only one features such an optimization still relies on an exhaustive search. Hence, we will develop a new TOHTN plan verification approach in this paper by extending the standard CYK parsing algorithm which acts as the best decision procedure in general.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
A Dynamics and Task Decoupled Reinforcement Learning Architecture for High-Efficiency Dynamic Target Intercept | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26421), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26421/26193), [keywords](PRS: Applications, ROB: Motion and Path Planning, ML: Reinforcement Learning Algorithms, PRS: Optimization of Spatio-Temporal Systems, PRS: Other Foundations of Planning, Routing & Scheduling, PRS: Planning Under Uncertainty), [abstract](Abstract
Due to the flexibility and ease of control, unmanned aerial vehicles (UAVs) have been increasingly used in various scenarios and applications in recent years. Training UAVs with reinforcement learning (RL) for a specific task is often expensive in terms of time and computation. However, it is known that the main effort of the learning process is made to fit the low-level physical dynamics systems instead of the high-level task itself. In this paper, we study to apply UAVs in the dynamic target intercept (DTI) task, where the dynamics systems equipped by different UAV models are correspondingly distinct. To this end, we propose a dynamics and task decoupled RL architecture to address the inefficient learning procedure, where the RL module focuses on modeling the DTI task without involving physical dynamics, and the design of states, actions, and rewards are completely task-oriented while the dynamics control module can adaptively convert actions from the RL module to dynamics signals to control different UAVs without retraining the RL module. We show the efficiency and efficacy of our results in comparison and ablation experiments against state-of-the-art methods.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
AlphaRoute- Large-Scale Coordinated Route Planning via Monte Carlo Tree Search | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26422), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26422/26194), [keywords](PRS: Routing), [abstract](Abstract
This paper proposes AlphaRoute, an AlphaGo inspired algorithm for coordinating large-scale routes, built upon graph attention reinforcement learning and Monte Carlo Tree Search (MCTS). We first partition the road network into regions and model large-scale coordinated route planning as a Markov game, where each partitioned region is treated as a player instead of each driver. Then, AlphaRoute applies a bilevel optimization framework, consisting of several region planners and a global planner, where the region planner coordinates the route choices for vehicles located in the region and generates several strategies, and the global planner evaluates the combination of strategies. 
AlphaRoute is built on graph  attention network for evaluating each state  and MCTS algorithm for dynamically visiting and simulating the future state for narrowing down the search space. AlphaRoute is capable of 1) bridging user fairness and system efficiency, 2) achieving higher search efficiency by alleviating the curse of dimensionality problems, and 3) making an effective and informed route planning by simulating over the future to capture traffic dynamics. 
Comprehensive experiments are conducted on two real-world road networks as compared with several baselines to evaluate the performance, and results show that AlphaRoute achieves the lowest travel time, and is efficient and effective for coordinating large-scale routes and alleviating the traffic congestion problem. The code will be publicly available.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Learning Rational Subgoals from Demonstrations and Instructions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26423), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26423/26195), [keywords](PRS: Planning/Scheduling and Learning, ROB: Cognitive Robotics), [abstract](Abstract
We present a framework for learning useful subgoals that support efficient long-term planning to achieve novel goals. At the core of our framework is a collection of rational subgoals (RSGs), which are essentially binary classifiers over the environmental states. RSGs can be learned from weakly-annotated data, in the form of unsegmented demonstration trajectories, paired with abstract task descriptions, which are composed of terms initially unknown to the agent (e.g., collect-wood then craft-boat then go-across-river). Our framework also discovers dependencies between RSGs, e.g., the task collect-wood is a helpful subgoal for the task craft-boat. Given a goal description, the learned subgoals and the derived dependencies facilitate off-the-shelf planning algorithms, such as A* and RRT, by setting helpful subgoals as waypoints to the planner, which significantly improves performance-time efficiency. Project page: https://rsg.csail.mit.edu), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Learning Safe Numeric Action Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26424), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26424/26196), [keywords](PRS: Planning/Scheduling and Learning, ML: Learning Theory, PRS: Mixed Discrete/Continuous Planning), [abstract](Abstract
Powerful domain-independent planners have been developed to solve various types of planning problems. 
These planners often require a model of the acting agent's actions, given in some planning domain description language. 
Yet obtaining such an action model is a notoriously hard task. 
This task is even more challenging in mission-critical domains, where a trial-and-error approach to learning how to act is not an option. 
In such domains, the action model used to generate plans must be safe, in the sense that plans generated with it must be applicable and achieve their goals. 
Learning safe action models for planning has been recently explored for domains in which states are sufficiently described with Boolean variables. 
In this work, we go beyond this limitation and propose the NSAM algorithm. 
NSAM runs in time that is polynomial in the number of observations and, under certain conditions, is guaranteed to return safe action models. 
We analyze its worst-case sample complexity, which may be intractable for some domains. Empirically, however, NSAM can quickly learn a safe action model that can solve most problems in the domain.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Automated Verification of Social Laws in Numeric Settings | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26425), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26425/26197), [keywords](PRS: Mixed Discrete/Continuous Planning, PRS: Deterministic Planning), [abstract](Abstract
It is possible for agents operating in a shared environment to interfere with one another. One mechanism of coordination is called Social Law. Enacting such a law in a multi-agent setting restricts agents' behaviors. Robustness, in this case, ensures that the agents do not harmfully interfere with each other and that each agent achieves its goals regardless of what other agents do. Previous work on social law verification examined only the case of boolean state variables. However, many real-world problems require reasoning with numeric variables. Moreover, numeric fluents allow a more compact representation of multiple planning problems.

In this paper, we develop a method to verify whether a given social law is robust via compilation to numeric planning. A solution to this compilation constitutes a counterexample to the robustness of the problem, i.e., evidence of cross-agent conflict. Thus, the social law is robust if and only if the proposed compilation is unsolvable. We empirically verify robustness in multiple domains using state-of-the-art numeric planners. Additionally, this compilation raises a challenge by generating a set of non-trivial numeric domains where unsolvability should be either proved or disproved.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Expressive Optimal Temporal Planning via Optimization Modulo Theory | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26426), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26426/26198), [keywords](PRS: Temporal Planning, CSO: Constraint Optimization, CSO: Mixed Discrete/Continuous Optimization), [abstract](Abstract
Temporal Planning is the problem of synthesizing a course of actions given a predictive model of a system subject to temporal constraints. This kind of planning finds natural applications in the automation of industrial processes and in robotics when the timing and deadlines are important. Finding any plan in temporal planning is often not enough as it is sometimes needed to optimize a certain objective function: particularly interesting are the minimization of the makespan and the optimization of the costs of actions. Despite the importance of the problem, only few works in the literature tackled the problem of optimal temporal planning because of the complicated intermix of planning and scheduling.
In this paper, we address the problem of optimal temporal planning for a very expressive class of problems using a reduction of the bounded planning problem to Optimization Modulo Theory (OMT) a powerful discrete/continuous optimization framework. We theoretically and empirically show the expressive power of this approach and we set a baseline for future research in this area.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Flexible Budgets in Restless Bandits- A Primal-Dual Algorithm for Efficient Budget Allocation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26427), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26427/26199), [keywords](PRS: Planning With Markov Models (MDPs, POMDPs), MAS: Multiagent Planning), [abstract](Abstract
Restless multi-armed bandits (RMABs) are an important model to optimize allocation of limited resources in sequential decision-making settings. Typical RMABs assume the budget --- the number of arms pulled --- to be fixed for each step in the planning horizon. However, for realistic real-world planning, resources are not necessarily limited at each planning step; we may be able to distribute surplus resources in one round to an earlier or later round. In real-world planning settings, this flexibility in budget is often constrained to within a subset of consecutive planning steps, e.g., weekly planning of a monthly budget. In this paper we define a general class of RMABs with flexible budget, which we term F-RMABs, and provide an algorithm to optimally solve for them. We derive a min-max formulation to find optimal policies for F-RMABs and leverage gradient primal-dual algorithms to solve for reward-maximizing policies with flexible budgets. We introduce a scheme to sample expected gradients to apply primal-dual algorithms to the F-RMAB setting and make an otherwise computationally expensive approach tractable. Additionally, we provide heuristics that trade off solution quality for efficiency and present experimental comparisons of different F-RMAB solution approaches.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Structurally Restricted Fragments of Numeric Planning – a Complexity Analysis | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26428), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26428/26200), [keywords](PRS: Mixed Discrete/Continuous Planning, PRS: Deterministic Planning), [abstract](Abstract
Numeric planning is known to be undecidable even under severe restrictions. Prior work has investigated the decidability boundaries by restricting the expressiveness of the planning formalism in terms of the numeric functions allowed in conditions and effects. We study a well-known restricted form of Hoffmann's simple numeric planning, which is undecidable. We analyze the complexity by imposing restrictions on the causal structure, exploiting a novel method for bounding variable domain sizes. First, we show that plan existence for tasks where all numeric variables are root nodes in the causal graph is in PSPACE.
Second, we show that for tasks with only numeric leaf variables the problem is decidable, and that it is in PSPACE if the propositional state space has a fixed size. Our work lays a strong foundation for future investigations of structurally more complex tasks. From a practical perspective, our method allows to employ heuristics and methods that are geared towards finite variable domains (such as pattern database heuristics or decoupled search) to solve non-trivial families of numeric planning problems.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Predicate Invention for Bilevel Planning | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26429), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26429/26201), [keywords](PRS: Planning/Scheduling and Learning, ML: Relational Learning, PRS: Mixed Discrete/Continuous Planning), [abstract](Abstract
Efficient planning in continuous state and action spaces is fundamentally hard, even when the transition model is deterministic and known. One way to alleviate this challenge is to perform bilevel planning with abstractions, where a high-level search for abstract plans is used to guide planning in the original transition space. Previous work has shown that when state abstractions in the form of symbolic predicates are hand-designed, operators and samplers for bilevel planning can be learned from demonstrations. In this work, we propose an algorithm for learning predicates from demonstrations, eliminating the need for manually specified state abstractions. Our key idea is to learn predicates by optimizing a surrogate objective that is tractable but faithful to our real efficient-planning objective. We use this surrogate objective in a hill-climbing search over predicate sets drawn from a grammar. Experimentally, we show across four robotic planning environments that our learned abstractions are able to quickly solve held-out tasks, outperforming six baselines.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Smoothed Online Combinatorial Optimization Using Imperfect Predictions | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26430), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26430/26202), [keywords](PRS: Planning Under Uncertainty), [abstract](Abstract
Smoothed online combinatorial optimization considers a learner who repeatedly chooses a combinatorial decision to minimize an unknown changing cost function with a penalty on switching decisions in consecutive rounds. We study smoothed online combinatorial optimization problems when an imperfect predictive model is available, where the model can forecast the future cost functions with uncertainty. We show that using predictions to plan for a finite time horizon leads to regret dependent on the total predictive uncertainty and an additional switching cost. This observation suggests choosing a suitable planning window to balance between uncertainty and switching cost, which leads to an online algorithm with guarantees on the upper and lower bounds of the cumulative regret. Empirically, our algorithm shows a significant improvement in cumulative regret compared to other baselines in synthetic online distributed streaming problems.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26431), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26431/26203), [keywords](PRS: Planning Under Uncertainty, PEAI: Societal Impact of AI, PRS: Planning With Markov Models (MDPs, POMDPs), PRS: Scheduling Under Uncertainty), [abstract](Abstract
This paper studies restless multi-armed bandit (RMAB) problems with unknown arm transition dynamics but with known correlated arm features. The goal is to learn a model to predict transition dynamics given features, where the Whittle index policy solves the RMAB problems using predicted transitions. However, prior works often learn the model by maximizing the predictive accuracy instead of final RMAB solution quality, causing a mismatch between training and evaluation objectives. To address this shortcoming, we propose a novel approach for decision-focused learning in RMAB that directly trains the predictive model to maximize the Whittle index solution quality. We present three key contributions: (i) we establish differentiability of the Whittle index policy to support decision-focused learning; (ii) we significantly improve the scalability of decision-focused learning approaches in sequential problems, specifically RMAB problems; (iii) we apply our algorithm to a previously collected  dataset of maternal and child health to demonstrate its performance. Indeed, our algorithm is the first for decision-focused learning in RMAB that scales to real-world problem sizes.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Neural TSP Solver with Progressive Distillation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26432), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26432/26204), [keywords](PRS: Planning/Scheduling and Learning, ML: Reinforcement Learning Algorithms), [abstract](Abstract
Travelling salesman problem (TSP) is NP-Hard with exponential search space. Recently, the adoption of encoder-decoder models as neural TSP  solvers has emerged as an attractive topic because they can instantly obtain near-optimal results for small-scale instances. Nevertheless, their training efficiency and solution quality degrade dramatically when dealing with large-scale problems. To address the issue, we propose a novel progressive distillation framework, by adopting curriculum learning to train TSP samples in increasing order of their problem size and progressively distilling high-level knowledge from small models to large models via a distillation loss. In other words, the trained small models are used as the teacher network to guide action selection when training large models. To accelerate training speed, we also propose a Delaunary-graph based action mask and a new attention-based decoder to reduce decoding cost. Experimental results show that our approach  establishes clear advantages over existing encoder-decoder models in terms of training effectiveness and solution quality. In addition, we validate its usefulness as an initial solution generator for the state-of-the-art TSP solvers, whose probability of obtaining the optimal solution can be further improved in such a hybrid manner.), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
The Linear Distance Traveling Tournament Problem Allows an EPTAS | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26433), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26433/26205), [keywords](PRS: Scheduling, PRS: Other Foundations of Planning, Routing & Scheduling, PRS: Routing), [abstract](Abstract
The Traveling Tournament Problem (TTP-k) is a well-known benchmark problem in tournament timetabling and has been extensively studied in the field of AI. In this problem, we are going to design a double round-robin schedule such that each pair of teams plays one game in each other's home venue, minimizing the total distance traveled by all n teams (n is even) under the constraint that each team can have at most k-consecutive home games or away games. The Linear Distance Traveling Tournament Problem (LDTTP-k), where all teams are located on a line, was introduced by Hoshino and Kawarabayashi (AAAI 2012). For LDTTP-3, they gave a 4/3-approximation algorithm for n≡4 (mod 6) teams. In this paper, we show that for any 3≤k=o(∛n), LDTTP-k allows an efficient polynomial-time approximation scheme (EPTAS).), [group](Technical Tracks 10: AAAI Technical Track on Planning, Routing, and Scheduling)
Learning Relational Causal Models with Cycles through Relational Acyclification | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26434), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26434/26206), [keywords](RU: Relational Probabilistic Models, RU: Causality), [abstract](Abstract
In real-world phenomena which involve mutual influence or causal effects between interconnected units, equilibrium states are typically represented with cycles in graphical models. An expressive class of graphical models, relational causal models, can represent and reason about complex dynamic systems exhibiting such cycles or feedback loops. Existing cyclic causal discovery algorithms for learning causal models from observational data assume that the data instances are independent and identically distributed which makes them unsuitable for relational causal models. At the same time, causal discovery algorithms for relational causal models assume acyclicity. In this work, we examine the necessary and sufficient conditions under which a constraint-based relational causal discovery algorithm is sound and complete for cyclic relational causal models. We introduce relational acyclification, an operation specifically designed for relational models that enables reasoning about the identifiability of cyclic relational causal models. We show that under the assumptions of relational acyclification and sigma-faithfulness, the relational causal discovery algorithm RCD is sound and complete for cyclic relational models. We present experimental results to support our claim.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Causal Effect Identification in Cluster DAGs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26435), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26435/26207), [keywords](RU: Causality, RU: Graphical Model), [abstract](Abstract
Reasoning about the effect of interventions and counterfactuals is a fundamental task found throughout the data sciences. A collection of principles, algorithms, and tools has been developed for performing such tasks in the last decades.  One of the pervasive requirements found throughout this literature is the articulation of assumptions, which commonly appear in the form of causal diagrams. Despite the power of this approach, there are significant settings where the knowledge necessary to specify a causal diagram over all variables is not available, particularly in complex, high-dimensional domains. In this paper, we introduce a new graphical modeling tool called cluster DAGs (for short, C-DAGs) that allows for the partial specification of relationships among variables based on limited prior knowledge, alleviating the stringent requirement of specifying a full causal diagram. A C-DAG specifies relationships between clusters of variables, while the relationships between the variables within a cluster are left unspecified, and can be seen as a graphical representation of an equivalence class of causal diagrams that share the relationships among the clusters. We develop the foundations and machinery for valid inferences over C-DAGs about the clusters of variables at each layer of Pearl's Causal Hierarchy - L1 (probabilistic), L2 (interventional), and L3 (counterfactual).  In particular, we prove the soundness and completeness of d-separation for probabilistic inference in C-DAGs.  Further, we demonstrate the validity of Pearl's do-calculus rules over C-DAGs and show that the standard ID identification algorithm is sound and complete to systematically compute causal effects from observational data given a C-DAG. Finally, we show that C-DAGs are valid for performing counterfactual inferences about clusters of variables.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
A Simple Unified Approach to Testing High-Dimensional Conditional Independences for Categorical and Ordinal Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26436), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26436/26208), [keywords](RU: Causality, RU: Bayesian Networks), [abstract](Abstract
Conditional independence (CI) tests underlie many approaches to model testing and structure learning in causal inference. Most existing CI tests for categorical and ordinal data stratify the sample by the conditioning variables, perform simple independence tests in each stratum, and combine the results. Unfortunately, the statistical power of this approach degrades rapidly as the number of conditioning variables increases. Here we propose a simple unified CI test for ordinal and categorical data that maintains reasonable calibration and power in high dimensions. We show that our test outperforms existing baselines in model testing and structure learning for dense directed graphical models while being comparable for sparse models. Our approach could be attractive for causal model testing because it is easy to implement, can be used with non-parametric or parametric probability models, has the symmetry property, and has reasonable computational requirements.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Score-Based Learning of Graphical Event Models with Background Knowledge Augmentation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26437), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26437/26209), [keywords](RU: Graphical Model, DMKM: Mining of Spatial, Temporal or Spatio-Temporal Data, ML: Bayesian Learning, ML: Graph-based Machine Learning, ML: Time-Series/Data Streams), [abstract](Abstract
Graphical event models (GEMs) are representations of temporal point process dynamics between different event types. Many real-world applications however involve limited event stream data, making it challenging to learn GEMs from data alone. In this paper, we introduce approaches that can work together in a score-based learning paradigm, to augment data with potentially different types of background knowledge. We propose novel scores for learning an important parametric class of GEMs; in particular, we propose a Bayesian score for leveraging prior information as well as a more practical simplification that involves fewer parameters, analogous to Bayesian networks. We also introduce a framework for incorporating easily assessed qualitative background knowledge from domain experts, in the form of statements such as `event X depends on event Y' or `event Y makes event X more likely'. The proposed framework has Bayesian interpretations and can be deployed by any score-based learner. Through an extensive empirical investigation, we demonstrate the practical benefits of background knowledge augmentation while learning GEMs for applications in the low-data regime.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Entropy Regularization for Population Estimation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26438), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26438/26210), [keywords](RU: Sequential Decision Making, ML: Active Learning, ML: Online Learning & Bandits), [abstract](Abstract
Entropy regularization is known to improve exploration in sequential decision-making problems. We show that this same mechanism can also lead to nearly unbiased and lower-variance estimates of the mean reward in the optimize-and-estimate structured bandit setting. Mean reward estimation (i.e., population estimation) tasks have recently been shown to be essential for public policy settings where legal constraints often require precise estimates of population metrics. We show that leveraging entropy and KL divergence can yield a better trade-off between reward and estimator variance than existing baselines, all while remaining nearly unbiased. These properties of entropy regularization illustrate an exciting potential for bringing together the optimal exploration and estimation literature.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Principled and Efficient Motif Finding for Structure Learning of Lifted Graphical Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26439), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26439/26211), [keywords](RU: Relational Probabilistic Models, KRR: Logic Programming, RU: Graphical Model), [abstract](Abstract
Structure learning is a core problem in AI central to the fields of neuro-symbolic AI and statistical relational learning. It consists in automatically learning a logical theory from data. The basis for structure learning is mining repeating patterns in the data, known as structural motifs. Finding these patterns reduces the exponential search space and therefore guides the learning of formulas. Despite the importance of motif learning, it is still not well understood. We present the first principled approach for mining structural motifs in lifted graphical models, languages that blend first-order logic with probabilistic models,  which uses a stochastic process to measure the similarity of entities in the data. 

Our first contribution is an algorithm, which depends on two intuitive hyperparameters: one controlling the uncertainty in the entity similarity measure, and one controlling the softness of the resulting rules. Our second contribution is a preprocessing step where we perform hierarchical clustering on the data to reduce the search space to the most relevant data. Our third contribution is to introduce an O(n ln(n)) (in the size of the entities in the data) algorithm for clustering structurally-related data. We evaluate our approach using standard benchmarks and show that we outperform state-of-the-art structure learning approaches by up to 6% in terms of accuracy and up to 80% in terms of runtime.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
A Faster Practical Approximation Scheme for the Permanent | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26440), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26440/26212), [keywords](RU: Stochastic Models & Probabilistic Inference, CSO: Search, SO: Evaluation and Analysis, SO: Sampling/Simulation-Based Search), [abstract](Abstract
The permanent of a matrix has numerous applications but is notoriously hard to compute. While nonnegative matrices admit polynomial approximation schemes based on rapidly mixing Markov chains, the known practical estimators of the permanent rely on importance or rejection sampling. We advance the rejection sampling approach, which provides probabilistic accuracy guarantees, unlike importance sampling. Specifically, we give a novel class of nesting upper bounds and a simple preprocessing method that, in comparison to previous works, enable faster sampling with better acceptance rate; we demonstrate order-of-magnitude improvements with both theoretical and empirical analyses. In addition, we display instances on which our approximation scheme is competitive against state-of-the-art importance sampling based estimators.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Neural Diffeomorphic Non-uniform B-spline Flows | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26441), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26441/26213), [keywords](RU: Stochastic Models & Probabilistic Inference, ML: Probabilistic Methods, RU: Uncertainty Representations), [abstract](Abstract
Normalizing flows have been successfully modeling a complex probability distribution as an invertible transformation of a simple base distribution. However, there are often applications that require more than invertibility. For instance, the computation of energies and forces in physics requires the second derivatives of the transformation to be well-defined and continuous. Smooth normalizing flows employ infinitely differentiable transformation, but with the price of slow non-analytic inverse transforms. In this work, we propose diffeomorphic non-uniform B-spline flows that are at least twice continuously differentiable while bi-Lipschitz continuous, enabling efficient parametrization while retaining analytic inverse transforms based on a sufficient condition for diffeomorphism. Firstly, we investigate the sufficient condition for C(k-2)-diffeomorphic non-uniform kth-order B-spline transformations. Then, we derive an analytic inverse transformation of the non-uniform cubic B-spline transformation for neural diffeomorphic non-uniform B-spline flows. Lastly, we performed experiments on solving the force matching problem in Boltzmann generators, demonstrating that our C2-diffeomorphic non-uniform B-spline flows yielded solutions better than previous spline flows and faster than smooth normalizing flows. Our source code is publicly available at https://github.com/smhongok/Non-uniform-B-spline-Flow.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Identification and Estimation of the Probabilities of Potential Outcome Types Using Covariate Information in Studies with Non-compliance | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26442), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26442/26214), [keywords](RU: Causality), [abstract](Abstract
We propose novel identification conditions and a statistical estimation method for the probabilities of potential outcome types using covariate information in randomized trials in which the treatment assignment is randomized but subject compliance is not perfect. Different from existing studies, the proposed identification conditions do not require strict assumptions such as the assumption of monotonicity. When the probabilities of potential outcome types are identifiable through the proposed conditions, the problem of estimating the probabilities of potential outcome types is reduced to that of singular models. Thus, the probabilities cannot be evaluated using standard statistical likelihood-based estimation methods. Rather, the proposed identification conditions show that we can derive consistent estimators of the probabilities of potential outcome types via the method of moments, which leads to the asymptotic normality of the proposed estimators through the delta method under regular conditions. We also propose a new statistical estimation method based on the bounded constrained augmented Lagrangian method to derive more efficient estimators than can be derived through the method of moments.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Computing Divergences between Discrete Decomposable Models | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26443), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26443/26215), [keywords](RU: Graphical Model, RU: Stochastic Models & Probabilistic Inference), [abstract](Abstract
There are many applications that benefit from computing the exact divergence between 2 discrete probability measures, including machine learning. Unfortunately, in the absence of any assumptions on the structure or independencies within these distributions, computing the divergence between them is an intractable problem in high dimensions. We show that we are able to compute a wide family of functionals and divergences, such as the alpha-beta divergence, between two decomposable models, i.e. chordal Markov networks, in time exponential to the treewidth of these models. The alpha-beta divergence is a family of divergences that include popular divergences such as the Kullback-Leibler divergence, the Hellinger distance, and the chi-squared divergence. Thus, we can accurately compute the exact values of any of this broad class of divergences to the extent to which we can accurately model the two distributions using decomposable models.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Out-of-Distribution Generalization by Neural-Symbolic Joint Training | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26444), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26444/26216), [keywords](RU: Graphical Model, KRR: Automated Reasoning and Theorem Proving, KRR: Logic Programming), [abstract](Abstract
This paper develops a novel methodology to simultaneously learn a neural network and extract generalized logic rules. Different from prior neural-symbolic methods that require background knowledge and candidate logical rules to be provided, we aim to induce task semantics with minimal priors. This is achieved by a two-step learning framework that iterates between optimizing neural predictions of task labels and searching for a more accurate representation of the hidden task semantics. Notably, supervision works in both directions: (partially) induced task semantics guide the learning of the neural network and induced neural predictions admit an improved semantic representation. We demonstrate that our proposed framework is capable of achieving superior out-of-distribution generalization performance on two tasks: (i) learning multi-digit addition, where it is trained on short sequences of digits and tested on long sequences of digits; (ii) predicting the optimal action in the Tower of Hanoi, where the model is challenged to discover a policy independent of the number of disks in the puzzle.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Novel Ordering-Based Approaches for Causal Structure Learning in the Presence of Unobserved Variables | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26445), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26445/26217), [keywords](RU: Causality, ML: Causal Learning, ML: Representation Learning, RU: Graphical Model), [abstract](Abstract
We propose ordering-based approaches for learning the maximal ancestral graph (MAG) of a structural equation model (SEM) up to its Markov equivalence class (MEC) in the presence of unobserved variables. Existing ordering-based methods in the literature recover a graph through learning a causal order (c-order). We advocate for a novel order called removable order (r-order) as they are advantageous over c-orders for structure learning. This is because r-orders are the minimizers of an appropriately defined optimization problem that could be either solved exactly (using a reinforcement learning approach) or approximately (using a hill-climbing search). Moreover, the r-orders (unlike c-orders) are invariant among all the graphs in a MEC and include c-orders as a subset. Given that set of r-orders is often significantly larger than the set of c-orders, it is easier for the optimization problem to find an r-order instead of a c-order. We evaluate the performance and the scalability of our proposed approaches on both real-world and randomly generated networks.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Maximizing the Probability of Fixation in the Positional Voter Model | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26446), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26446/26218), [keywords](RU: Stochastic Optimization, CSO: Constraint Optimization, DMKM: Graph Mining, Social Network Analysis & Community Mining, APP: Bioinformatics, APP: Social Networks, MAS: Multiagent Systems Under Uncertainty, RU: Stochastic Models & Probabilistic Inference, SO: Evolutionary Computation, SO: Other Foundations of Search & Optimization), [abstract](Abstract
The Voter model is a well-studied stochastic process that models the invasion of a novel trait A (e.g., a new opinion, social meme, genetic mutation, magnetic spin) in a network of individuals (agents, people, genes, particles) carrying an existing resident trait B. Individuals change traits by occasionally sampling the trait of a neighbor, while an invasion bias δ ≥ 0 expresses the stochastic preference to adopt the novel trait A over the resident trait B. The strength of an invasion is measured by the probability that eventually the whole population adopts trait A, i.e., the fixation probability. In more realistic settings, however, the invasion bias is not ubiquitous, but rather manifested only in parts of the network. For instance, when modeling the spread of a social trait, the invasion bias represents localized incentives. In this paper, we generalize the standard biased Voter model to the positional Voter model, in which the invasion bias is effectuated only on an arbitrary subset of the network nodes, called biased nodes. We study the ensuing optimization problem, which is, given a budget k, to choose k biased nodes so as to maximize the fixation probability of a randomly occurring invasion. We show that the problem is NP-hard both for finite δ and when δ → ∞ (strong bias), while the objective function is not submodular in either setting, indicating strong computational hardness. On the other hand, we show that, when δ → 0 (weak bias), we can obtain a tight approximation in O(n^2ω ) time, where ω is the matrix-multiplication exponent. We complement our theoretical results with an experimental evaluation of some proposed heuristics.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Certifying Fairness of Probabilistic Circuits | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26447), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26447/26219), [keywords](RU: Stochastic Models & Probabilistic Inference, ML: Bias and Fairness), [abstract](Abstract
With the increased use of machine learning systems for decision making, questions about the fairness properties of such systems start to take center stage. Most existing work on algorithmic fairness assume complete observation of features at prediction time, as is the case for popular notions like statistical parity and equal opportunity. However, this is not sufficient for models that can make predictions with partial observation as we could miss patterns of bias and incorrectly certify a model to be fair. To address this, a recently introduced notion of fairness asks whether the model exhibits any discrimination pattern, in which an individual—characterized by (partial) feature observations—receives vastly different decisions merely by disclosing one or more sensitive attributes such as gender and race. By explicitly accounting for partial observations, this provides a much more fine-grained notion of fairness.

In this paper, we propose an algorithm to search for discrimination patterns in a general class of probabilistic models, namely probabilistic circuits. Previously, such algorithms were limited to naive Bayes classifiers which make strong independence assumptions; by contrast, probabilistic circuits provide a unifying framework for a wide range of tractable probabilistic models and can even be compiled from certain classes of Bayesian networks and probabilistic programs, making our method much more broadly applicable. Furthermore, for an unfair model, it may be useful to quickly find discrimination patterns and distill them for better interpretability. As such, we also propose a sampling-based approach to more efficiently mine discrimination patterns, and introduce new classes of patterns such as minimal, maximal, and Pareto optimal patterns that can effectively summarize exponentially many discrimination patterns.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Probabilities of Potential Outcome Types in Experimental Studies- Identification and Estimation Based on Proxy Covariate Information | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26448), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26448/26220), [keywords](RU: Causality), [abstract](Abstract
The concept of potential outcome types is one of the fundamental components of causal inference. However, even in randomized experiments, assumptions on the data generating process, such as monotonicity, are required to evaluate the probabilities of the potential outcome types. To solve the problem without such assumptions in experimental studies, a novel identification condition based on proxy covariate information is proposed in this paper. In addition, the estimation problem of the probabilities of the potential outcome types reduces to that of singular models when they are identifiable through the proposed condition. Thus, they cannot be evaluated by standard statistical estimation methods. To overcome this difficulty, new plug-in estimators of these probabilities are presented, and the asymptotic normality of the proposed estimators is shown.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Lifted Inference with Linear Order Axiom | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26449), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26449/26221), [keywords](RU: Relational Probabilistic Models), [abstract](Abstract
We consider the task of weighted first-order model counting (WFOMC) used for probabilistic inference in the area of statistical relational learning. Given a formula φ, domain size n and a pair of weight functions, what is the weighted sum of all models of φ over a domain of size n? It was shown that computing WFOMC of any logical sentence with at most two logical variables can be done in time polynomial in n. However, it was also shown that the task is #P1-complete once we add the third variable, which inspired the search for extensions of the two-variable fragment that would still permit a running time polynomial in n. One of such extension is the two-variable fragment with counting quantifiers. In this paper, we prove that adding a linear order axiom (which forces one of the predicates in φ to introduce a linear ordering of the domain elements in each model of φ) on top of the counting quantifiers still permits a computation time polynomial in the domain size. We present a new dynamic programming-based algorithm which can compute WFOMC with linear order in time polynomial in n, thus proving our primary claim.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Vector Causal Inference between Two Groups of Variables | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26450), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26450/26222), [keywords](RU: Causality, KRR: Action, Change, and Causality, ML: Causal Learning, RU: Graphical Model), [abstract](Abstract
Methods to identify cause-effect relationships currently mostly assume the variables to be scalar random variables. However, in many fields the objects of interest are vectors or groups of scalar variables.
We present a new constraint-based non-parametric approach for inferring the causal relationship between two vector-valued random variables from observational data. Our method employs sparsity estimates of directed and undirected graphs and is based on two new principles for groupwise causal reasoning that we justify theoretically in Pearl's graphical model-based causality framework. Our theoretical considerations are complemented by two new causal discovery algorithms for causal interactions between two random vectors which find the correct causal direction reliably in simulations even if interactions are nonlinear. We evaluate our methods empirically and compare them to other state-of-the-art techniques.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Efficient Enumeration of Markov Equivalent DAGs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26451), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26451/26223), [keywords](RU: Causality, ML: Causal Learning, RU: Bayesian Networks, RU: Graphical Model), [abstract](Abstract
Enumerating the directed acyclic graphs (DAGs) of a Markov equivalence class (MEC) is an important primitive in causal analysis. The central resource from the perspective of computational complexity is the delay, that is, the time an algorithm that lists all members of the class requires between two consecutive outputs. Commonly used algorithms for this task utilize the rules proposed by Meek (1995) or the transformational characterization by Chickering (1995), both resulting in superlinear delay. In this paper, we present the first linear-time delay algorithm. On the theoretical side, we show that our algorithm can be generalized to enumerate DAGs represented by models that incorporate background knowledge, such as MPDAGs; on the practical side, we provide an efficient implementation and evaluate it in a series of experiments. Complementary to the linear-time delay algorithm, we also provide intriguing insights into Markov equivalence itself: All members of an MEC can be enumerated such that two successive DAGs have structural Hamming distance at most three.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Differentially Private Nonlinear Causal Discovery from Numerical Data | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26452), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26452/26224), [keywords](RU: Causality, ML: Causal Learning, ML: Privacy-Aware ML), [abstract](Abstract
Recently, several methods such as private ANM, EM-PC and Priv-PC have been proposed to perform differentially private causal discovery in various scenarios including bivariate, multivariate Gaussian and categorical cases. However, there is little effort on how to conduct private nonlinear causal discovery from numerical data. This work tries to challenge this problem. To this end, we propose a method to infer nonlinear causal relations from observed numerical data by using regression-based conditional independence test (RCIT) that consists of kernel ridge regression (KRR) and Hilbert-Schmidt independence criterion (HSIC) with permutation approximation. Sensitivity analysis for RCIT is given and a private constraint-based causal discovery framework with differential privacy guarantee is developed. Extensive simulations and real-world experiments for both conditional independence test and causal discovery are conducted, which show that our method is effective in handling nonlinear numerical cases and easy to implement. The source code of our method and data are available at https://github.com/Causality-Inference/PCD.), [group](Technical Tracks 10: AAAI Technical Track on Reasoning Under Uncertainty)
Safe Interval Path Planning with Kinodynamic Constraints | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26453), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26453/26225), [keywords](SO: Heuristic Search, ROB: Motion and Path Planning), [abstract](Abstract
Safe Interval Path Planning (SIPP) is a powerful algorithm for solving a single-agent pathfinding problem where the agent is confined to a graph and certain vertices/edges of this graph are blocked at certain time intervals due to dynamic obstacles that populate the environment. The original SIPP algorithm relies on the assumption that the agent is able to stop instantaneously. However, this assumption often does not hold in practice, e.g. a mobile robot moving at a cruising speed cannot stop immediately but rather requires gradual deceleration to a full stop that takes time. In other words, the robot is subject to kinodynamic constraints. Unfortunately, as we show in this work, in such a case, the original SIPP is incomplete. To this end, we introduce a novel variant of SIPP that is provably complete and optimal for planning with acceleration/deceleration. In the experimental evaluation, we show that the key property of the original SIPP still holds for the modified version: it performs much fewer expansions compared to A* and, as a result, is notably faster.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Diversity Maximization in the Presence of Outliers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26454), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26454/26226), [keywords](SO: Other Foundations of Search & Optimization, CSO: Constraint Optimization, DMKM: Scalability, Parallel & Distributed Systems), [abstract](Abstract
Given a set X of n points in a metric space, the problem of diversity maximization is to extract a set S of k points from X so that the diversity of S is maximized. This problem is essential in AI-related fields, such as web search, databases, recommender systems, and data mining. Although there have been extensive studies of this problem, these studies assume that X is clean. This usually does not hold, because real-world datasets usually contain outliers. The state-of-the-art algorithm for the diversity maximization problem is based on furthest point retrieval, which is too sensitive to outliers. We therefore address the problem of diversity maximization with outliers and propose two algorithms with performance guarantee. The first algorithm runs in O((k+z)n) time, guarantees 1/2-approximation, and returns no outliers, where z is the number of outliers. The second algorithm runs in O(kz) time (which is independent of n), guarantees 1/6(1+epsilon)-approximation, and returns no outliers with constant probability. We conduct experiments on real datasets to demonstrate the effectiveness and efficiency of our algorithms.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Fair Short Paths in Vertex-Colored Graphs | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26455), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26455/26227), [keywords](SO: Mixed Discrete/Continuous Search, GTEP: Coordination and Collaboration), [abstract](Abstract
The computation of short paths in graphs with arc lengths is a pillar of graph algorithmics and network science. In a more diverse world, however, not every short path is equally valuable. For the setting where each vertex is assigned to a group (color), we provide a framework to model multiple natural fairness aspects. We seek to find short paths in which the number of occurrences of each color is within some given lower and upper bounds. Among other results, we prove the introduced problems to be computationally intractable (NP-hard and parameterized hard with respect to the number of colors) even in very restricted settings (such as each color should appear with exactly the same frequency), while also presenting an encouraging algorithmic result ("fixed-parameter tractability") related to the length of the sought solution path for the general problem.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
AC-Band- A Combinatorial Bandit-Based Approach to Algorithm Configuration | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26456), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26456/26228), [keywords](SO: Algorithm Configuration, ML: Online Learning & Bandits), [abstract](Abstract
We study the algorithm configuration (AC) problem, in which one seeks to find an optimal parameter configuration of a given target algorithm in an automated way. Although this field of research has experienced much progress recently regarding approaches satisfying strong theoretical guarantees, there is still a gap between the practical performance of these approaches and the heuristic state-of-the-art approaches. Recently, there has been significant progress in designing AC approaches that satisfy strong theoretical guarantees. However, a significant gap still remains between the practical performance of these approaches and state-of-the-art heuristic methods. To this end, we introduce AC-Band, a general approach for the AC problem based on multi-armed bandits that provides theoretical guarantees while exhibiting strong practical performance. We show that AC-Band requires significantly less computation time than other AC approaches providing theoretical guarantees while still yielding high-quality configurations.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
GRASMOS- Graph Signage Model Selection for Gene Regulatory Networks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26457), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26457/26229), [keywords](SO: Sampling/Simulation-Based Search, APP: Bioinformatics, ML: Graph-based Machine Learning), [abstract](Abstract
Signed networks (networks with positive and negative edges) commonly arise in various domains from molecular biology to social media. 
The edge signs -- i.e., the graph signage -- represent the interaction pattern between the vertices and can provide insights into the underlying system formation process. Generative models considering signage formation are essential for testing hypotheses about the emergence of interactions and for creating synthetic datasets for algorithm benchmarking (especially in areas where obtaining real-world datasets is difficult).

In this work, we pose a novel Maximum-Likelihood-based optimization problem for modeling signages given their topology and showcase it in the context of gene regulation. Regulatory interactions of genes play a key role in the process of organism development, and when broken can lead to serious organism abnormalities and diseases.  Our contributions are threefold: First, we design a new class of signage models for a given topology, and, based on the parameter setting, we discuss its biological interpretations for gene regulatory networks (GRNs). Second, we design algorithms computing the Maximum Likelihood -- depending on the parameter setting, our algorithms range from closed-form expressions to MCMC sampling. Third, we evaluated the results of our algorithms on synthetic datasets and real-world large GRNs. Our work can lead to the prediction of unknown gene regulations, novel biological hypotheses, and realistic benchmark datasets in the realm of gene regulation.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Optimal Pathfinding on Weighted Grid Maps | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26458), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26458/26230), [keywords](SO: Heuristic Search, ROB: Motion and Path Planning, PRS: Routing), [abstract](Abstract
In many computer games up to hundreds of agents navigate in real-time across a dynamically changing weighted grid map. Pathfinding in these situations is challenging because the grids are large, traversal costs are not uniform, and because each shortest path has many symmetric permutations, all of which must be considered by an optimal online search. In this work we introduce Weighted Jump Point Search (JPSW), a new type of pathfinding algorithm which breaks weighted grid symmetries by introducing a tiebreaking policy that allows us to apply effective pruning rules in symmetric regions. We show that these pruning rules preserve at least one optimal path to every grid cell and that their application can yield large performance improvements for optimal pathfinding. We give a complete theoretical description of the new algorithm, including pseudo-code. We also conduct a wide-ranging experimental evaluation, including data from real games. Results indicate JPSW is up to orders of magnitude faster than the nearest baseline, online search using A*.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Warm-Starting Nested Rollout Policy Adaptation with Optimal Stopping | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26459), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26459/26231), [keywords](SO: Sampling/Simulation-Based Search, PRS: Routing), [abstract](Abstract
Nested Rollout Policy Adaptation (NRPA) is an approach using online learning policies in a nested structure. It has achieved a great result in a variety of difficult combinatorial optimization problems. In this paper, we propose Meta-NRPA, which combines optimal stopping theory with NRPA for warm-starting and significantly improves the performance of NRPA. We also present several exploratory techniques for NRPA which enable it to perform better exploration. We establish this for three notoriously difficult problems ranging from telecommunication, transportation and coding theory namely Minimum Congestion Shortest Path Routing,  Traveling Salesman Problem with Time Windows and Snake-in-the-Box.
We also improve the lower bounds of the Snake-in-the-Box problem for multiple dimensions.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
A Proof That Using Crossover Can Guarantee Exponential Speed-Ups in Evolutionary Multi-Objective Optimisation | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26460), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26460/26232), [keywords](SO: Evolutionary Computation, SO: Evaluation and Analysis), [abstract](Abstract
Evolutionary algorithms are popular algorithms for multiobjective optimisation (also called Pareto optimisation) as they use a population to store trade-offs between different objectives. Despite their popularity, the theoretical foundation of multiobjective evolutionary optimisation (EMO) is still in its early development. Fundamental questions such as the benefits of the crossover operator are still not fully understood.

We provide a theoretical analysis of well-known EMO algorithms GSEMO and NSGA-II to showcase the possible advantages of crossover. We propose a class of problems on which these EMO algorithms using crossover find the Pareto set in expected polynomial time. In sharp contrast, they and many other EMO algorithms without crossover require exponential time to even find a single Pareto-optimal point. This is the first example of an exponential performance gap through the use of crossover for the widely used NSGA-II algorithm.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Runtime Analysis for the NSGA-II- Provable Speed-Ups from Crossover | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26461), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26461/26233), [keywords](SO: Evolutionary Computation, SO: Heuristic Search), [abstract](Abstract
Very recently, the first mathematical runtime analyses for the NSGA-II, the most common multi-objective evolutionary algorithm, have been conducted. Continuing this research direction, we prove that the NSGA-II optimizes the OneJumpZeroJump benchmark asymptotically faster when crossover is employed. Together with a parallel independent work by Dang, Opris, Salehi, and Sudholt, this is the first time such an advantage of crossover is proven for the NSGA-II. Our arguments can be transferred to single-objective optimization. They then prove that crossover can speed up the (mu+1) genetic algorithm in a different way and more pronounced than known before. Our experiments confirm the added value of crossover and show that the observed advantages are even larger than what our proofs can guarantee.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26462), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26462/26234), [keywords](SO: Evolutionary Computation, SO: Heuristic Search), [abstract](Abstract
Due to the more complicated population dynamics of the NSGA-II, none of the existing runtime guarantees for this algorithm is accompanied by a non-trivial lower bound. Via a first mathematical understanding of the population dynamics of the NSGA-II, that is, by estimating the expected number of individuals having a certain objective value, we prove that the NSGA-II with suitable population size needs Omega(Nn log n) function evaluations to find the Pareto front of the OneMinMax problem and Omega(Nn^k)  evaluations on the OneJumpZeroJump problem with jump size k. These bounds are asymptotically tight (that is, they match previously shown upper bounds) and show that the NSGA-II here does not even in terms of the parallel runtime (number of iterations) profit from larger population sizes. For the OneJumpZeroJump problem and when the same sorting is used for the computation of the crowding distance contributions of the two objectives, we even obtain a runtime estimate that is tight including the leading constant.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Ultrafast Euclidean Shortest Path Computation Using Hub Labeling | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26463), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26463/26235), [keywords](SO: Heuristic Search, ROB: Motion and Path Planning, PRS: Routing), [abstract](Abstract
Finding shortest paths in a Euclidean plane containing polygonal obstacles is a well-studied problem motivated by a variety of real-world applications. 
The state-of-the-art algorithms require finding obstacle corners visible to the source and target, and need to consider potentially a large number of candidate paths. This adversely affects their query processing cost. We address these limitations by proposing a novel adaptation of hub labeling which is the state-of-the-art approach for  shortest distance computation in road networks. Our experimental study conducted on the widely used benchmark maps shows that our approach is typically 1-2  orders of magnitude faster than two state-of-the-art algorithms.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
A Formal Metareasoning Model of Concurrent Planning and Execution | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26464), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26464/26236), [keywords](SO: Metareasoning and Metaheuristics, SO: Heuristic Search), [abstract](Abstract
Agents that plan and act in the real world must deal with the fact that time passes as they are planning. When timing is tight, there may be insufficient time to complete the search for a plan before it is time to act.  By commencing execution before search concludes, one gains time to search by making planning and execution concurrent. However, this incurs the risk of making incorrect action choices, especially if actions are irreversible. This tradeoff between opportunity and risk is the problem addressed in this paper. Our main contribution is to formally define this setting as an abstract metareasoning problem. We find that the abstract problem is intractable.  However, we identify special cases that are solvable in polynomial time, develop greedy solution algorithms, and, through tests on instances derived from search problems, find several methods that achieve promising practical performance.  This work lays the foundation for a principled time-aware executive that concurrently plans and executes.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
TransPath- Learning Heuristics for Grid-Based Pathfinding via Transformers | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26465), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26465/26237), [keywords](SO: Heuristic Search, ML: Deep Generative Models & Autoencoders, PRS: Planning/Scheduling and Learning), [abstract](Abstract
Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games, etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account, and thus the search led by such heuristics performs poorly in obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance-independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, learning the correction factor utilizes the knowledge of the instance-independent heuristic. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be employed in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of 4x while producing the solutions, whose costs exceed those of the optimal solutions by less than 0.3% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners.

The project web-page is: https://airi-institute.github.io/TransPath/.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Large-State Reinforcement Learning for Hyper-Heuristics | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26466), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26466/26238), [keywords](SO: Metareasoning and Metaheuristics, ML: Reinforcement Learning Algorithms, PRS: Applications, SO: Heuristic Search), [abstract](Abstract
Hyper-heuristics are a domain-independent problem solving approach where the main task is to select effective chains of problem-specific low-level heuristics on the fly for an unseen instance. This task can be seen as a reinforcement learning problem, however, the information available to the hyper-heuristic is very limited, usually leading to very limited state representations. In this work, for the first time we use the trajectory of solution changes for a larger set of features for reinforcement learning in the novel hyper-heuristic LAST-RL (Large-State Reinforcement Learning). Further, we introduce a probability distribution for the exploration case in our epsilon-greedy policy that is based on the idea of Iterated Local Search to increase the chance to sample good chains of low-level heuristics. The benefit of the collaboration of our novel components is shown on the academic benchmark of the Cross Domain Heuristic Challenge 2011 consisting of six different problem domains. Our approach can provide state-of-the-art results on this benchmark where it outperforms recent hyper-heuristics based on reinforcement learning, and also demonstrates high performance on a benchmark of complex real-life personnel scheduling domains.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Human Assisted Learning by Evolutionary Multi-Objective Optimization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26467), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26467/26239), [keywords](SO: Evolutionary Computation, ML: Evolutionary Learning, SO: Heuristic Search), [abstract](Abstract
Machine learning models have liberated manpower greatly in many real-world tasks, but their predictions are still worse than humans on some specific instances. To improve the performance, it is natural to optimize machine learning models to take decisions for most instances while delivering a few tricky instances to humans, resulting in the problem of Human Assisted Learning (HAL). Previous works mainly formulated HAL as a constrained optimization problem that tries to find a limited subset of instances for human decision such that the sum of model and human errors can be minimized; and employed the greedy algorithms, whose performance, however, may be limited due to the greedy nature. In this paper, we propose a new framework HAL-EMO based on Evolutionary Multi-objective Optimization, which reformulates HAL as a bi-objective optimization problem that minimizes the number of selected instances for human decision and the total errors simultaneously, and employs a Multi-Objective Evolutionary Algorithm (MOEA) to solve it. We implement HAL-EMO using two MOEAs, the popular NSGA-II as well as the theoretically grounded GSEMO. We also propose a specific MOEA, called BSEMO, with biased selection and balanced mutation for HAL-EMO, and prove that for human assisted regression and classification, HAL-EMO using BSEMO can achieve better and same theoretical guarantees than previous greedy algorithms, respectively. Experiments on the tasks of medical diagnosis and content moderation show the superiority of HAL-EMO (with either NSGA-II, GSEMO or BSEMO) over previous algorithms, and that using BSEMO leads to the best performance of HAL-EMO.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
OPT-GAN- A Broad-Spectrum Global Optimizer for Black-Box Problems by Learning Distribution | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26468), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26468/26240), [keywords](SO: Evolutionary Computation, ML: Adversarial Learning & Robustness, ML: Deep Generative Models & Autoencoders, ML: Optimization, SO: Heuristic Search), [abstract](Abstract
Black-box optimization (BBO) algorithms are concerned with finding the best solutions for problems with missing analytical details. Most classical methods for such problems are based on strong and fixed a priori assumptions, such as Gaussianity. However, the complex real-world problems, especially when the global optimum is desired, could be very far from the a priori assumptions because of their diversities, causing unexpected obstacles.   In this study, we propose a generative adversarial net-based broad-spectrum global optimizer (OPT-GAN) which estimates the distribution of optimum gradually, with strategies to balance exploration-exploitation trade-off. It has potential to better adapt to the regularity and structure of diversified landscapes than other methods with fixed prior, e.g., Gaussian assumption or separability. 
Experiments on diverse BBO benchmarks and high dimensional real world applications exhibit that OPT-GAN outperforms other traditional and neural net-based BBO algorithms. The code and Appendix are available at https://github.com/NBICLAB/OPT-GAN), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Analyzing and Improving the Use of the FastMap Embedding in Pathfinding Tasks | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26469), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26469/26241), [keywords](SO: Heuristic Search), [abstract](Abstract
The FastMap algorithm has been proposed as an inexpensive metric embedding which provides admissible distance estimates between all vertices in an embedding. As an embedding, it also supports additional operations such as taking the median location of two vertices, which is important in some problems. This paper studies several aspects of FastMap embeddings, showing the relationship of FastMap to general additive heuristics. As an admissible heuristic, FastMap is not as strong as previous suggested. However, by combining FastMap with the ideas of differential heuristics, we can significantly improve the performance of FastMap heuristics. We show the impact of these ideas in both single-agent pathfinding and the Multi-Agent Meeting problem, where the performance of algorithms using our improved FastMap embedding is improved by up to a factor of two.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Fully Computer-Assisted Proofs in Extremal Combinatorics | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26470), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26470/26242), [keywords](SO: Metareasoning and Metaheuristics, ML: Optimization, SO: Heuristic Search, SO: Local Search), [abstract](Abstract
We present a fully computer-assisted proof system for solving a particular family of problems in Extremal Combinatorics. Existing techniques using Flag Algebras have proven powerful in the past, but have so far lacked a computational counterpart to derive matching constructive bounds. We demonstrate that common search heuristics are capable of finding constructions far beyond the reach of human intuition. Additionally, the most obvious downside of such heuristics, namely a missing guarantee of global optimality, can often be fully eliminated in this case through lower bounds and stability results coming from the Flag Algebra approach.

To illustrate the potential of this approach, we study two related and well-known problems in Extremal Graph Theory that go back to questions of Erdős from the 60s.
Most notably, we present the first major improvement in the upper bound of the Ramsey multiplicity of K_4 in 25 years, precisely determine the first off-diagonal Ramsey multiplicity number, and settle the minimum number of independent sets of size four in graphs with clique number strictly less than five.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Electrophysiological Brain Source Imaging via Combinatorial Search with Provable Optimality | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26471), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26471/26243), [keywords](SO: Heuristic Search, CMS: Brain Modeling, APP: Healthcare, Medicine & Wellness, HAI: Brain-Sensing and Analysis), [abstract](Abstract
Electrophysiological Source Imaging (ESI) refers to reconstructing the underlying brain source activation from non-invasive Electroencephalography (EEG) and Magnetoencephalography (MEG) measurements on the scalp. Estimating the source locations and their extents is a fundamental tool in clinical and neuroscience applications. However, the estimation is challenging because of the ill-posedness and high coherence in the leadfield matrix as well as the noise in the EEG/MEG data. In this work, we proposed a combinatorial search framework to address the ESI problem with a provable optimality guarantee. Specifically, by exploiting the graph neighborhood information in the brain source space, we converted the ESI problem into a graph search problem and designed a combinatorial search algorithm under the framework of A* to solve it. The proposed algorithm is guaranteed to give an optimal solution to the ESI problem. Experimental results on both synthetic data and real epilepsy EEG data demonstrated that the proposed algorithm could faithfully reconstruct the source activation in the brain.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Improved Algorithm for Regret Ratio Minimization in Multi-Objective Submodular Maximization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26472), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26472/26244), [keywords](SO: Other Foundations of Search & Optimization, ML: Optimization, ML: Other Foundations of Machine Learning), [abstract](Abstract
Submodular maximization has attracted extensive attention due to its numerous applications in machine learning and artificial intelligence. Many real-world problems require maximizing multiple submodular objective functions at the same time. In such cases, a common approach is to select a representative subset of Pareto optimal solutions with different trade-offs among multiple objectives. To this end, in this paper, we investigate the regret ratio minimization (RRM) problem in multi-objective submodular maximization, which aims to find at most k solutions to best approximate all Pareto optimal solutions w.r.t. any linear combination of objective functions. We propose a novel HS-RRM algorithm by transforming RRM into HittingSet problems based on the notions of ε-kernel and δ-net, where any α-approximation algorithm for single-objective submodular maximization is used as an oracle. We improve upon the previous best-known bound on the maximum regret ratio (MRR) of the output of HS-RRM and show that the new bound is nearly asymptotically optimal for any fixed number d of objective functions. Experiments on real-world and synthetic data confirm that HS-RRM achieves lower MRRs than existing algorithms.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
Efficient Gradient Approximation Method for Constrained Bilevel Optimization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26473), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26473/26245), [keywords](SO: Evaluation and Analysis, SO: Applications), [abstract](Abstract
Bilevel optimization has been developed for many machine learning tasks with large-scale and high-dimensional data. This paper considers a constrained bilevel optimization problem, where the lower-level optimization problem is convex with equality and inequality constraints and the upper-level optimization problem is non-convex. The overall objective function is non-convex and non-differentiable. To solve the problem, we develop a gradient-based approach, called gradient approximation method, which determines the descent direction by computing several representative gradients of the objective function inside a neighborhood of the current estimate. We show that the algorithm asymptotically converges to the set of Clarke stationary points, and demonstrate the efficacy of the algorithm by the experiments on hyperparameter optimization and meta-learning.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)
A Generalized Scalarization Method for Evolutionary Multi-Objective Optimization | [link](https://ojs.aaai.org/index.php/AAAI/article/view/26474), [pdf](https://ojs.aaai.org/index.php/AAAI/article/view/26474/26246), [keywords](SO: Evolutionary Computation), [abstract](Abstract
The decomposition-based multi-objective evolutionary algorithm (MOEA/D) transforms a multi-objective optimization problem (MOP) into a set of single-objective subproblems for collaborative optimization. Mismatches between subproblems and solutions can lead to severe performance degradation of MOEA/D. Most existing mismatch coping strategies only work when the L∞ scalarization is used. A mismatch coping strategy that can use any Lp scalarization, even when facing MOPs with non-convex Pareto fronts, is of great significance for MOEA/D. This paper uses the global replacement (GR) as the backbone. We analyze how GR can no longer avoid mismatches when L∞ is replaced by another Lp with p ∈ [1, ∞), and find that the Lp-based (1 ≤ p < ∞) subproblems having inconsistently large preference regions. When p is set to a small value, some middle subproblems have very small preference regions so that their direction vectors cannot pass through their corresponding preference regions. Therefore, we propose a generalized Lp (GLp) scalarization to ensure that the subproblem’s direction vector passes through its preference region. Our theoretical analysis shows that GR can always avoid mismatches when using the GLp scalarization for any p ≥ 1. The experimental studies on various MOPs conform to the theoretical analysis.), [group](Technical Tracks 10: AAAI Technical Track on Search and Optimization)